{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d81c9663-7297-401d-b6d2-7709017cd13a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Library amd Module Imports\n",
    "<b>Description: </b> \n",
    "    All the required packages, modules and libraries are imported here for this notebook.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69308fda-a364-4009-aff0-d6a9d07967ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import json\n",
    "import warnings\n",
    "import netCDF4 as nc\n",
    "from typing import Callable, List, Optional\n",
    "from pathlib import Path\n",
    "from datetime import datetime as dt\n",
    "\n",
    "# Progress Visualization\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "# import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Neural Networks\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler as lr_sch\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision.transforms.functional import gaussian_blur\n",
    "# Parallel training\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import init_process_group, destroy_process_group\n",
    "\n",
    "# Image Manipulation\n",
    "import scipy\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from PIL import Image\n",
    "from torchvision.utils import save_image\n",
    "from scipy.stats import kurtosis, skew\n",
    "from scipy import ndimage, special, linalg\n",
    "\n",
    "# import imageio.v3 as iio\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "\n",
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd9437c-adaf-44f6-bff0-d550429a9b06",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00944ed6-36c7-442a-8b67-a12daceb2f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def compute_spectral_image(image, ifft=False, magnitude=False, normalize=False):\n",
    "    \"\"\"\n",
    "    Computes the spectral image using the magnitude of the 2D Fourier Transform.\n",
    "    \n",
    "    Args:\n",
    "        image (numpy array): A single CT scan patch (grayscale).\n",
    "    \n",
    "    Returns:\n",
    "        spectral_image (numpy array): The spectral representation.\n",
    "    \"\"\"\n",
    "    fft_shift = None\n",
    "    if ifft:\n",
    "        fft_shift = np.fft.ifftshift(image)  # Shift zero frequency to center\n",
    "    else:\n",
    "        fft_image = np.fft.fft2(image)  # Apply 2D Fourier Transform\n",
    "        fft_shift = np.fft.fftshift(fft_image)  # Shift zero frequency to center\n",
    "    \n",
    "    if magnitude:\n",
    "        magnitude_spectrum = np.abs(fft_shift)  # Get magnitude\n",
    "        # Normalize the spectrum for consistency\n",
    "        magnitude_spectrum = np.log1p(magnitude_spectrum)  # Log scaling\n",
    "        \n",
    "        if normalize:\n",
    "            magnitude_spectrum = (magnitude_spectrum - np.min(magnitude_spectrum)) / (np.max(magnitude_spectrum) - np.min(magnitude_spectrum))  # Normalize [0,1]\n",
    "            \n",
    "        return fft_shift.astype(np.complex64), magnitude_spectrum\n",
    "    else: \n",
    "        return fft_shift.astype(np.complex64)\n",
    "\n",
    "bernoulli_mask_cache = dict()\n",
    "poisson_mask_cache = dict()\n",
    "def corrupt_data(img, spec, corruption_type=\"bspec\", **kwargs):\n",
    "    \"\"\"\n",
    "    Corrupts the image and spectral image with the given corruption_type.\n",
    "    \n",
    "    Args:\n",
    "        img (numpy array): A single CT scan patch (grayscale).\n",
    "        spectral_image (numpy array): The spectral representation.\n",
    "    \n",
    "    Returns:\n",
    "        img (numpy array): CT scan patch after corruption (grayscale).\n",
    "        spectral_image (numpy array): The corrupted spectral representation. \n",
    "        spectral_mask (numpy array): The corruption mask of spectral image.\n",
    "    \"\"\" \n",
    "    # print(img.shape, spec.shape)\n",
    "    \n",
    "    if corruption_type == \"bspec\":\n",
    "        # print(\"Bernoulli Process\")\n",
    "        p_at_edge = kwargs[\"corruption_params\"]['p_edge']\n",
    "        global bernoulli_mask_cache\n",
    "        if bernoulli_mask_cache.get(p_at_edge) is None:\n",
    "            half = [s//2 for s in spec.shape]\n",
    "            r_dist = [np.arange(s, dtype=np.float32) - h for s, h in zip(spec.shape, half)]\n",
    "            r_dist = [x ** 2 for x in r_dist]\n",
    "            r_dist = (r_dist[0][:, np.newaxis] + r_dist[1][np.newaxis, :]) ** .5 # r_dist[0]: Horizontal Component, r_dist[1]: Vertical Component\n",
    "            bernoulli_mask_probab = (p_at_edge ** (1.0/half[1])) ** r_dist\n",
    "            bernoulli_mask_cache[p_at_edge] = bernoulli_mask_probab\n",
    "            # print('Bernoulli probability at edge = %.5f' % bernoulli_mask_probab[half[0], 0])\n",
    "            # print('Average Bernoulli probability = %.5f' % np.mean(bernoulli_mask_probab))\n",
    "        mask = bernoulli_mask_cache[p_at_edge]\n",
    "        keep = (np.random.uniform(0.0, 1.0, size=spec.shape)**2 < mask)\n",
    "        keep = keep & keep[::-1, ::-1]\n",
    "        mskd_spec = spec * keep\n",
    "        spec_msk = keep.astype(np.float32)\n",
    "        spec = compute_spectral_image(mskd_spec / (mask + ~keep + 1e-8), ifft=True)\n",
    "        img = np.real(np.fft.ifft2(spec)).astype(np.float32)\n",
    "        return img, mskd_spec, spec_msk\n",
    "        \n",
    "    elif corruption_type == \"poisson\":\n",
    "        # print(\"Poisson Process\")\n",
    "        corruption_strength = kwargs[\"corruption_params\"]['poisson_strength']\n",
    "        mask = None\n",
    "        global poisson_mask_cache\n",
    "        poisson_noise = np.random.poisson(np.abs(img) * corruption_strength)/corruption_strength\n",
    "        # poisson_noise = np.clip(poisson_noise, 0, 255)\n",
    "        \n",
    "        if kwargs[\"corruption_params\"]['distribution'] == 'uniform':\n",
    "            assert kwargs[\"corruption_params\"]['mask_ratio'] is not None\n",
    "            criterion = kwargs[\"corruption_params\"]['mask_ratio']\n",
    "            \n",
    "        elif kwargs[\"corruption_params\"]['distribution'] == 'gaussian':\n",
    "            assert kwargs[\"corruption_params\"]['sigma'] is not None\n",
    "            criterion = gaussian_mask(img.shape, kwargs[\"corruption_params\"]['sigma'])\n",
    "        \n",
    "        if poisson_mask_cache.get((kwargs[\"corruption_params\"]['distribution'], criterion)) is None:\n",
    "            mask = np.random.uniform(0, 1, size=img.shape) < criterion\n",
    "            mask = mask.astype(np.float32)\n",
    "            poisson_mask_cache[(kwargs[\"corruption_params\"]['distribution'], criterion)] = mask\n",
    "        else:\n",
    "            mask = poisson_mask_cache[(kwargs[\"corruption_params\"]['distribution'], criterion)].astype(np.float32)\n",
    "            \n",
    "        img = np.where(mask, poisson_noise, img)\n",
    "        spec = compute_spectral_image(img)\n",
    "        return img, spec, mask\n",
    "        \n",
    "    else:\n",
    "        # Not a valid corruption/No corruption\n",
    "        print(\"No Corruption\")\n",
    "        return img, spec, np.ones_like(img)\n",
    "        \n",
    "augment_translate_cache = dict()\n",
    "def augment_data(img, spec, params):\n",
    "    t = params.get('translate', 0)\n",
    "    if t > 0:\n",
    "        global augment_translate_cache\n",
    "        trans = np.random.randint(-t, t + 1, size=(2,))\n",
    "        key = (trans[0], trans[1])\n",
    "        if key not in augment_translate_cache:\n",
    "            x = np.zeros_like(img)\n",
    "            x[trans[0], trans[1]] = 1.0\n",
    "            augment_translate_cache[key] = compute_spectral_image(x)\n",
    "        img = np.roll(img, trans, axis=(0, 1))\n",
    "        spec = spec * augment_translate_cache[key]\n",
    "    return img.astype(np.float32), spec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbf9c9d-15e6-476c-bba6-bb8843ed5cea",
   "metadata": {},
   "source": [
    "# Dataset Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b7ee0d-824d-439a-91e3-b1f3b79cc193",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Dataset Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d425583-800a-4b11-a405-f45225283278",
   "metadata": {},
   "outputs": [],
   "source": [
    "isHQ = 1 # 0:LQ ; 1:HQ ; 2:Bio\n",
    "fullDataset=False  # If False, provide the custom dir name. \"TrainScans\" - Placeholder\n",
    "\n",
    "if isHQ == 0:\n",
    "    active_dataset = \"LQ_Mphase\"\n",
    "elif isHQ == 1:\n",
    "    active_dataset = \"HQ_Mphase\"\n",
    "elif isHQ == 2:\n",
    "    active_dataset = \"Biofilm\"\n",
    "else:\n",
    "    raise ValueError(\"Invalid dataset selection.\")\n",
    "    \n",
    "dataset_root_dir = Path(\"../Datasets\") / active_dataset\n",
    "ds_dir = Path(\"datasets\")\n",
    "\n",
    "\n",
    "dataset_scans_folder = dataset_root_dir / (\"tomo_RMG_nc\" if fullDataset else \"TrainScans\")\n",
    "print(f\"Original Dataset Root: [ {dataset_root_dir} ]\")\n",
    "print(f\"Dataset .nc Scans: [ {dataset_scans_folder} ]\")\n",
    "print(f\"Dataset .pth Files: [ {ds_dir} ]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f45ce0-f246-4a12-a1f9-6117c1e25760",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Dataset Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1d002b-78c7-4805-92e1-3de74f2c57aa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Scan files to Images\n",
    "\n",
    "<b>Description:</b> The following code block reads x-ray scans(.nc files) and generates grayscale images for each vertical resolution/slice(.png Images).\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c629f-13ef-474c-9ce1-84866d4e9ba3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def nc_to_img(dataset_path, output_path, crop=False, **kwargs):\n",
    "    \n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    global_slice_idx = 0\n",
    "    block_pths = dataset_path.glob(\"*.nc\")\n",
    "\n",
    "    # Set min and max thresholds for the range of important values. [Clamping values to rescale the spectrum]\n",
    "    # For Phase3 dataset: [9083, 16500]\n",
    "    # For Biofilm dataset: [10750, 21800] \n",
    "    min_val = 10750 #np.iinfo(np.uint16).min # -24368\n",
    "    max_val = 21800 #np.iinfo(np.uint16).max # -14468 \n",
    "    diff = float(max_val - min_val)\n",
    "\n",
    "    for block_pth in tqdm(sorted(block_pths), desc=\"Blocks\", leave=True, position=0):\n",
    "        scan_data = None\n",
    "        \n",
    "        with nc.Dataset(block_pth, 'r') as block:\n",
    "            scan_data = block.variables['tomo'][:]\n",
    "            \n",
    "        # print(f\"Scan Data Shape: {scan_data.shape}\")\n",
    "        n_slices, H, W = scan_data.shape\n",
    "        \n",
    "        for slice_idx in tqdm(range(n_slices), desc=f'Slices [Block: {block_pth.name}]', leave=False, position=1):\n",
    "            # Extract the slice\n",
    "            if crop:\n",
    "                img_size = kwargs.get(\"imgsize\", 1352)\n",
    "                left_col, top_row = kwargs.get(\"origin\", (635, 522))\n",
    "                slice_data = scan_data[slice_idx, top_row:top_row + img_size + 1, left_col:left_col + img_size + 1]\n",
    "            else:\n",
    "                slice_data = scan_data[slice_idx, :, :]\n",
    "            \n",
    "            # Normalize all data values to the range [0, 255].\n",
    "            slice_data = slice_data.astype('uint16')\n",
    "            slice_data = slice_data.astype('float64')\n",
    "            slice_data = np.clip(slice_data, min_val, max_val)\n",
    "            slice_data = ((slice_data - min_val)/diff) * 255.0\n",
    "            slice_data = slice_data.astype(np.uint8)  # Ensure the data is in uint8 format (0-255)\n",
    "            \n",
    "            img = Image.fromarray(slice_data)\n",
    "            \n",
    "            # Ensure Grayscale\n",
    "            img = img.convert('L')\n",
    "\n",
    "            # Rescale the image dims (Not required)\n",
    "            # img = img.resize((1024, 1024), Image.LANCZOS)\n",
    "            # img = img.resize((512, 512), Image.LANCZOS)\n",
    "            # img = img.resize((256, 256), Image.LANCZOS)\n",
    "\n",
    "            # Generate the image name and save it\n",
    "            save_path = output_path / f\"{global_slice_idx :06d}.png\"\n",
    "            img.save(save_path)\n",
    "            \n",
    "            global_slice_idx += 1\n",
    "    \n",
    "            # print(f\"Saved {slice_filename} from {block_filename}\")\n",
    "        print(f\"Saved All Slices from {block_pth.name}\")\n",
    "            \n",
    "    print(\"All slices have been saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ae7b55-1082-45db-bb80-b00a18c6748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pth = dataset_root_dir / \"Images\"\n",
    "# print(output_pth)\n",
    "\n",
    "# nc_to_img(dataset_scans_folder, output_pth, crop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff3fdbc-421c-4154-acd9-401da541d33b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Images to Patches\n",
    "\n",
    "<b>Description:</b> This code block creates patches from a larger image in sequential order.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70b92d8-a83f-4612-8975-20097c238934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches(img, patch_size=255, overlap=0.5, threshold=0):\n",
    "    step = int(patch_size * (1 - overlap))\n",
    "    patches = []\n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    for i in range(0, h - patch_size + 1, step):\n",
    "        for j in range(0, w - patch_size + 1, step):\n",
    "            patch = img[i:i + patch_size, j:j + patch_size]\n",
    "            variance = np.var(patch)\n",
    "            if variance >= threshold:\n",
    "                patches.append(patch)\n",
    "\n",
    "        if (w - patch_size) % step != 0:\n",
    "            j = w - patch_size\n",
    "            patch = img[i:i + patch_size, j:j + patch_size]\n",
    "            variance = np.var(patch)\n",
    "            if variance >= threshold:\n",
    "                patches.append(patch)\n",
    "    \n",
    "    # Add bottom row patches (bottom edge)\n",
    "    if (h - patch_size) % step != 0:\n",
    "        i = h - patch_size\n",
    "        for j in range(0, w - patch_size + 1, step):\n",
    "            patch = img[i:i + patch_size, j:j + patch_size]\n",
    "            variance = np.var(patch)\n",
    "            if variance >= threshold:\n",
    "                patches.append(patch)\n",
    "\n",
    "        # Also add the bottom-right corner patch\n",
    "        if (w - patch_size) % step != 0:\n",
    "            j = w - patch_size\n",
    "            patch = img[i:i + patch_size, j:j + patch_size]\n",
    "            variance = np.var(patch)\n",
    "            if variance >= threshold:\n",
    "                patches.append(patch)\n",
    "       \n",
    "    return patches\n",
    "\n",
    "def load_images_for_patching(src_path:Path, dst_path:Path, patch_size=255, overlap=0.5, threshold=0):\n",
    "    \n",
    "    dst_path.mkdir(parents=True, exist_ok=True)\n",
    "    imgs_pths = src_path.glob(\"*.png\")\n",
    "    \n",
    "    global_patch_idx = 0\n",
    "    img_idx = 0\n",
    "\n",
    "    for img_pth in tqdm(sorted(imgs_pths), desc=\"Images\", leave=True, position=0):\n",
    "        img = None\n",
    "        try:\n",
    "            img = Image.open(img_pth).convert('L')\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: Image file not found at {img_pth}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "        patches = extract_patches(np.array(img), patch_size=patch_size, overlap=overlap, threshold=threshold)\n",
    "        \n",
    "        # Save Patches\n",
    "        for patch in tqdm(patches, desc=\"Patches\", leave=False, position=1):\n",
    "            save_path = dst_path / f\"{global_patch_idx :08d}.png\"\n",
    "            p = Image.fromarray(patch)\n",
    "            p.save(save_path)\n",
    "            global_patch_idx += 1\n",
    "\n",
    "        img_idx += 1\n",
    "\n",
    "    print(f\"Total Patches: {global_patch_idx}\")\n",
    "    print(f\"All patches saved to - {dst_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f887536e-4ffc-44bb-ab86-cb536ba9630c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "patch_size = 255\n",
    "overlap = 0.5\n",
    "threshold = 0\n",
    "\n",
    "src_image_folder = \"evalImgs\"\n",
    "dst_patch_folder = \"eval\" \n",
    "src_pth = dataset_root_dir / src_image_folder\n",
    "dst_pth = dataset_root_dir / (dst_patch_folder + f\"_patches_{str(patch_size)}\")\n",
    "print(f\"Source: [ {src_pth} ]\")\n",
    "print(f\"Destination: [ {dst_pth} ]\")\n",
    "\n",
    "# load_images_for_patching(src_path=src_pth, dst_path=dst_pth, patch_size=patch_size, overlap=overlap, threshold=threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48ef79c-d4fe-454f-8081-eb8ae26888f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df7ff4f-85a6-4ff4-935d-430d9df5220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with just img and spec\n",
    "class CTScans(Dataset):\n",
    "    def __init__(self, images, spectrals):    \n",
    "        self.images = images.astype(np.float32)\n",
    "        self.spectrals = spectrals.astype(np.complex64)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.spectrals[idx]\n",
    "        \n",
    "def create_dataset(images_path=Path(\"\")):\n",
    "    file_paths = sorted([f for f in images_path.iterdir() if f.suffix == \".png\"])\n",
    "    if not file_paths:\n",
    "        raise ValueError(f\"No PNG files found at - {str(images_path)}\")\n",
    "\n",
    "    print(f\"Source Images Path - {images_path}\")\n",
    "    temp_img = np.array(Image.open(file_paths[0]).convert(\"L\"))\n",
    "    H, W = temp_img.shape\n",
    "    L = len(file_paths)\n",
    "    \n",
    "    imgs = np.zeros((L, H, W), dtype=np.float32)\n",
    "    specs = np.zeros((L, H, W), dtype=np.complex64)\n",
    "    \n",
    "    for idx, file_path in tqdm(enumerate(file_paths), total=len(file_paths), desc=\"Images\"):\n",
    "        imgs[idx] = (np.array(Image.open(file_path).convert(\"L\"), dtype=np.float32) / 255.0) - 0.5\n",
    "        specs[idx] = compute_spectral_image(imgs[idx])\n",
    "\n",
    "    return CTScans(imgs, specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ed1abc-9a3c-4727-b44e-d07e44268ab4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef73db2-b555-4971-aa6d-67701dba4855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating datasets\n",
    "patches = True\n",
    "dataset_create = False\n",
    "save_dataset = False\n",
    "\n",
    "train_dataset = None\n",
    "valid_dataset = None\n",
    "eval_dataset = None\n",
    "\n",
    "if dataset_create:\n",
    "    if patches:\n",
    "        # Create Patch Datasets\n",
    "        train_dataset = create_dataset(images_path=dataset_root_dir / \"train_patches_255\")\n",
    "        valid_dataset = create_dataset(images_path=dataset_root_dir / \"valid_patches_255\")\n",
    "        eval_dataset = create_dataset(images_path=dataset_root_dir / \"eval_patches_255\")\n",
    "    \n",
    "        if save_dataset:\n",
    "            torch.save(train_dataset, ds_dir / \"LQ_train_dataset_20.pth\", pickle_protocol=4)\n",
    "            torch.save(valid_dataset, ds_dir / \"LQ_valid_dataset_5.pth\", pickle_protocol=4)\n",
    "            torch.save(eval_dataset, ds_dir / \"LQ_eval_dataset_10.pth\", pickle_protocol=4)\n",
    "    else:\n",
    "        # Create Full Image Datasets\n",
    "        train_dataset = create_dataset(images_path=dataset_root_dir / \"trainImgs\")\n",
    "        valid_dataset = create_dataset(images_path=dataset_root_dir / \"validImgs\")\n",
    "        eval_dataset = create_dataset(images_path=dataset_root_dir / \"evalImgs\")\n",
    "        if save_dataset:\n",
    "            torch.save(train_dataset, ds_dir / \"HQ_train_full_img.pth\", pickle_protocol=4)\n",
    "            torch.save(valid_dataset, ds_dir / \"HQ_valid_full_img.pth\", pickle_protocol=4)\n",
    "            torch.save(eval_dataset, ds_dir / \"HQ_eval_full_img.pth\", pickle_protocol=4)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2582dcef-b977-42fa-8452-0388602715c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be2c2ba-5207-46dd-91f6-d567b790face",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = True\n",
    "if train_dataset is None or valid_dataset is None or eval_dataset is None: \n",
    "    if patches:\n",
    "        # Patch Dataset\n",
    "        train_dataset = torch.load(ds_dir / \"HQ_train_dataset_20.pth\", weights_only=False)\n",
    "        valid_dataset = torch.load(ds_dir / \"HQ_valid_dataset_5.pth\", weights_only=False)\n",
    "        eval_dataset = torch.load(ds_dir / \"HQ_eval_dataset_10.pth\", weights_only=False)\n",
    "    else:    \n",
    "        # Full sized Image Datasets\n",
    "        train_dataset = torch.load(ds_dir / \"HQ_eval_full_img.pth\", weights_only=False)\n",
    "        valid_dataset = torch.load(ds_dir / \"HQ_valid_full_img.pth\", weights_only=False)\n",
    "        eval_dataset = torch.load(ds_dir / \"HQ_eval_full_img.pth\", weights_only=False)\n",
    "        # valid_dataset = train_dataset # For testing only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81932053-af93-4ec8-b8fc-7655977e9857",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Visualize Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff723ce-4777-4d81-b914-0573ff1a52af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs an Update\n",
    "#                                                            Visualize a Sample from the Dataset\n",
    "#\n",
    "def visualize_dataset(train_dataset, valid_dataset):\n",
    "    tr_inp, tr_targ, tr_sp, tr_msk, tr_orig = next(iter(train_dataset))\n",
    "    va_inp, va_targ, va_sp, va_msk, va_orig = next(iter(valid_dataset))\n",
    "    \n",
    "    # print(tr_inp.dtype, tr_targ.dtype, tr_sp.dtype, tr_msk.dtype, tr_orig.dtype)\n",
    "    # print(va_inp.dtype, va_targ.dtype, va_sp.dtype, va_msk.dtype, va_orig.dtype)\n",
    "    \n",
    "    fig, axes = plt.subplots(2,5, figsize=(25,10))\n",
    "    \n",
    "    # Training Dataset\n",
    "    axes[0][0].imshow(tr_orig, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[0][0].set_title(\"Original\")\n",
    "    \n",
    "    axes[0][1].imshow(tr_inp, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[0][1].set_title(\"Input\")\n",
    "    \n",
    "    axes[0][2].imshow(tr_targ, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[0][2].set_title(\"Target\")\n",
    "    \n",
    "    axes[0][3].imshow(np.log1p(np.abs(tr_sp)), cmap='inferno')\n",
    "    axes[0][3].set_title(\"Input's Spectral\")\n",
    "    \n",
    "    axes[0][4].imshow(tr_msk, cmap='gray')\n",
    "    axes[0][4].set_title(\"Spectral Mask\")\n",
    "    \n",
    "    # Validation Dataset\n",
    "    axes[1][0].imshow(va_orig, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[1][0].set_title(\"Original\")\n",
    "    \n",
    "    axes[1][1].imshow(va_inp, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[1][1].set_title(\"Input\")\n",
    "    \n",
    "    axes[1][2].imshow(va_targ, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[1][2].set_title(\"Target\")\n",
    "    \n",
    "    axes[1][3].imshow(np.log1p(np.abs(va_sp)), cmap='inferno')\n",
    "    axes[1][3].set_title(\"Inputs's Spectral\")\n",
    "    \n",
    "    axes[1][4].imshow(va_msk, cmap='gray')\n",
    "    axes[1][4].set_title(\"Spectral Mask\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "assert train_dataset is not None and valid_dataset is not None, \"Training Dataset and Validation Dataset should not be None\"\n",
    "# visualize_dataset(train_dataset, valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b8b13d-e00d-46dc-bc9c-6f47ca773167",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# NIQE Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958b15d7-db3a-4684-a468-fb6e0d0c3b35",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "src_dir = Path(\"./Datasets/HQ_Mphase/Full_Dataset_Images\")\n",
    "dst_dir = Path(\"PyTorchDatasets\")\n",
    "# This version actually worked.\n",
    "class NIQE:\n",
    "    def __init__(self, src_pth:Path=Path(\"\"), dst_pth:Path=Path(\"\"), sigma:float=7/6):\n",
    "        self.mean_vector=None\n",
    "        self.covariance_matrix=None\n",
    "        self.sigma=sigma\n",
    "        self.src_pth=src_pth\n",
    "        self.dst_pth=dst_pth\n",
    "        \n",
    "    def _compute_mscn_coefficients(self, image: np.ndarray) -> np.ndarray:\n",
    "        # print(\"Compute MSCN\")\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        mu = gaussian_filter(image, sigma=self.sigma)\n",
    "        # print(\"gaussian filter 1\")\n",
    "        mu_sq = mu * mu\n",
    "        sigma = np.sqrt(np.abs(gaussian_filter(image * image, sigma=self.sigma) - mu_sq))\n",
    "        # print(\"Gaussian filter 2\")\n",
    "        mscn = (image - mu) / (sigma + 1e-8)\n",
    "        return mscn\n",
    "\n",
    "    def _extract_features(self, image: np.ndarray) -> np.ndarray:\n",
    "        # print(\"Extract features\")\n",
    "        mscn = self._compute_mscn_coefficients(image)\n",
    "        mscn_flat = mscn.flatten()\n",
    "        features = [\n",
    "            np.mean(mscn_flat),\n",
    "            np.var(mscn_flat),\n",
    "            skew(mscn_flat),\n",
    "            kurtosis(mscn_flat)\n",
    "        ]\n",
    "        # Compute features on shifted versions\n",
    "        shifts = [(0, 1), (1, 0), (1, 1), (1, -1)]\n",
    "        for dx, dy in shifts:\n",
    "            shifted = np.roll(mscn, shift=dx, axis=0)\n",
    "            shifted = np.roll(shifted, shift=dy, axis=1)\n",
    "            product = mscn * shifted\n",
    "            product_flat = product.flatten()\n",
    "            features += [\n",
    "                np.mean(product_flat),\n",
    "                np.var(product_flat),\n",
    "                skew(product_flat),\n",
    "                kurtosis(product_flat)\n",
    "            ]\n",
    "        return np.array(features, dtype=np.float32)\n",
    "\n",
    "    def train(self, src_dir: Path=None, dst_dir: Path=None, file_name:str=\"NIQE\"):\n",
    "        \"\"\"\n",
    "        src_dir: Path to the directory containing training images (8-bit grayscale PNGs).\n",
    "        The function will load all images, convert them to tensors, and use them for training.\n",
    "        \"\"\"\n",
    "        src_dir = src_dir or self.src_pth\n",
    "        dst_dir = dst_dir or self.dst_pth\n",
    "        \n",
    "        images = []\n",
    "        features = []\n",
    "        for image_path in tqdm(list(src_dir.glob('*.png')), desc=f'Loading images from {src_dir}'):\n",
    "            images.append()\n",
    "            image = np.array(Image.open(image_path).convert('L')).astype(np.uint8)\n",
    "            feats = self._extract_features(image)\n",
    "            if feats.size > 0:\n",
    "                features.append(feats)\n",
    "        \n",
    "        if not features:\n",
    "            raise ValueError(\"No valid features extracted from images.\")\n",
    "        \n",
    "        features = np.vstack(features)\n",
    "        self.mean_vector = np.mean(features, axis=0)\n",
    "        self.covariance_matrix = np.cov(features, rowvar=False)\n",
    "\n",
    "        # self.save(path=dst_dir, file_name=file_name)\n",
    "    \n",
    "    def save(self, path:Path=None, file_name:str=\"NIQE\"):\n",
    "        if self.mean_vector is None or self.covariance_matrix is None:\n",
    "            raise ValueError(\"NIQE model not trained yet.\")\n",
    "            \n",
    "        if path is None:\n",
    "            path = self.dst_pth\n",
    "            warnings.warn(f\"Empty Path Warning! Saving to current active directory: {path}\")\n",
    "        print(f\"Saving model to: [ {path} ] as - [ {(file_name + '_mu.npz')} ] and [ {(file_name + '_cov.npz')} ]\")\n",
    "        \n",
    "        temp_path = path / (file_name + \"_mu\")\n",
    "        np.savez(temp_path.with_suffix(\".npz\"), mu=self.mean_vector.astype(np.float32))\n",
    "        \n",
    "        temp_path = path / (file_name + \"_cov\")\n",
    "        np.savez(temp_path.with_suffix(\".npz\"), cov=self.covariance_matrix.astype(np.float32))\n",
    "        \n",
    "        print(f\"mu shape: {self.mean_vector.shape}, dtype: {self.mean_vector.dtype}\")\n",
    "        print(f\"cov shape: {self.covariance_matrix.shape}, dtype: {self.covariance_matrix.dtype}\")\n",
    "    \n",
    "    def load(self, path: Path=None, file_name:str=\"NIQE\"):\n",
    "        if path is None:\n",
    "            path = self.dst_pth\n",
    "            warnings.warn(f\"Empty Path Warning! Loading from current active directory: {path}\")\n",
    "        print(\"Loading params for NIQE\")\n",
    "        \n",
    "        temp_path = path / (file_name + \"_mu\")\n",
    "        self.mean_vector = np.load(temp_path.with_suffix(\".npz\"))['mu']\n",
    "        \n",
    "        temp_path = path / (file_name + \"_cov\")\n",
    "        self.covariance_matrix = np.load(temp_path.with_suffix(\".npz\"))['cov']\n",
    "        \n",
    "        print(self.mean_vector.shape)\n",
    "        print(self.covariance_matrix.shape)\n",
    "\n",
    "    def score(self, image: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        image_tensor: torch.Tensor of shape [1, H, W] or [H, W], values in [-0.5, 0.5] (float32)\n",
    "        \"\"\"\n",
    "        if self.mean_vector is None or self.covariance_matrix is None:\n",
    "            raise ValueError(\"NIQE model parameters not loaded or trained.\")\n",
    "        print(\"Start Scoring\")\n",
    "        # print(image.shape, type(image), image.dtype, len(image))\n",
    "        if image.ndim == 3:\n",
    "            image = image[0]  # shape [H, W]\n",
    "        elif image.ndim != 2:\n",
    "            raise ValueError(f\"Expected ndarray with shape [1, H, W] or [H, W], got {image.shape}\")\n",
    "\n",
    "        image_np = np.clip((image + 0.5) * 255, 0, 255).astype(np.uint8)\n",
    "        feat = self._extract_features(image_np)\n",
    "        # print(feat.shape, self.mean_vector)\n",
    "        delta = feat - self.mean_vector\n",
    "        try:\n",
    "            inv_cov = np.linalg.inv(self.covariance_matrix)\n",
    "        except RuntimeError:\n",
    "            inv_cov = np.linalg.pinv(self.covariance_matrix)\n",
    "\n",
    "        score = np.sqrt(np.dot(np.dot(delta, inv_cov), delta))\n",
    "        return float(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b9923d-f464-424d-b4cc-a37504b33e9a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "src_dir = Path(\"./Datasets/HQ_Mphase/Full_Dataset_Images\")\n",
    "dst_dir = Path(\"PyTorchDatasets\")\n",
    "\n",
    "class NIQEN:\n",
    "    def __init__(self, src_pth:Path=Path(\"\"), dst_pth:Path=Path(\"\"), sigma:float=7/6, patch_size=96):\n",
    "        self.mean_vector=None\n",
    "        self.covariance_matrix=None\n",
    "        self.sigma=sigma\n",
    "        self.patch_size = patch_size\n",
    "        self.src_pth=src_pth\n",
    "        self.dst_pth=dst_pth\n",
    "        \n",
    "    def __call__(self, image) -> float:\n",
    "        return self.score(image)\n",
    "    \n",
    "    def save(self, path:Path=None, file_name:str=\"NIQE_model\"):\n",
    "        if self.mean_vector is None or self.covariance_matrix is None:\n",
    "            raise ValueError(\"NIQE model not trained yet.\")\n",
    "            \n",
    "        if path is None:\n",
    "            path = self.dst_pth\n",
    "            warnings.warn(f\"Empty Path Warning! Saving to current active directory: {path}\")\n",
    "        print(f\"Saving model to: [ {path} ] as - [ {(file_name + '_mu.npz')} ] and [ {(file_name + '_cov.npz')} ]\")\n",
    "        \n",
    "        temp_path = path / (file_name + \"_mu\")\n",
    "        np.savez(temp_path.with_suffix(\".npz\"), mu=self.mean_vector.astype(np.float32), patch_size=self.patch_size)\n",
    "        \n",
    "        temp_path = path / (file_name + \"_cov\")\n",
    "        np.savez(temp_path.with_suffix(\".npz\"), cov=self.covariance_matrix.astype(np.float32))\n",
    "        \n",
    "        # print(f\"mu shape: {self.mean_vector.shape}, dtype: {self.mean_vector.dtype}\")\n",
    "        # print(f\"cov shape: {self.covariance_matrix.shape}, dtype: {self.covariance_matrix.dtype}\")\n",
    "        # print(f\"Patch Size: {self.patch_size}\")\n",
    "        print(f\"Covariance Matrix({self.covariance_matrix.shape}), Mean Vector({self.mean_vector.shape}) and Patch Size({self.patch_size}) saved successfuly!\")\n",
    "\n",
    "    def load(self, path: Path=None, file_name:str=\"NIQE_model\"):\n",
    "        if path is None:\n",
    "            path = self.dst_pth\n",
    "            warnings.warn(f\"Empty Path Warning! Loading from current active directory: {path}\")\n",
    "        print(\"Loading params for NIQE\")\n",
    "        \n",
    "        temp_path = path / (file_name + \"_mu\")\n",
    "        data = np.load(temp_path.with_suffix(\".npz\"))\n",
    "        self.mean_vector = data['mu']\n",
    "        self.patch_size = data['patch_size']\n",
    "        \n",
    "        temp_path = path / (file_name + \"_cov\")\n",
    "        self.covariance_matrix = np.load(temp_path.with_suffix(\".npz\"))['cov']\n",
    "        \n",
    "        # print(self.mean_vector.shape)\n",
    "        # print(self.covariance_matrix.shape)\n",
    "        # print(self.patch_size)\n",
    "        print(f\"Covariance Matrix({self.covariance_matrix.shape}), Mean Vector({self.mean_vector.shape}) and Patch Size({self.patch_size}) loaded successfuly!\")\n",
    "    \n",
    "    def _aggd_features(self, imdata):\n",
    "        \"\"\" Compute AGGD (Asymmetric Generalized Gaussian Distribution) features \"\"\"\n",
    "        imdata = imdata.flatten()\n",
    "        imdata2 = imdata ** 2\n",
    "        left_data = imdata2[imdata < 0]\n",
    "        right_data = imdata2[imdata >= 0]\n",
    "        lsq = np.sqrt(np.mean(left_data)) if len(left_data) > 0 else 0\n",
    "        rsq = np.sqrt(np.mean(right_data)) if len(right_data) > 0 else 0\n",
    "        gamma_hat = lsq / rsq if rsq != 0 else np.inf\n",
    "\n",
    "        denominator = np.mean(imdata2)\n",
    "        if denominator == 0:\n",
    "            print(\"Warning: Zero variance in patch. Skipping or using default values.\")\n",
    "            return 0, 0, 0, 0, 0, 0\n",
    "        \n",
    "        r_hat = (np.mean(np.abs(imdata)) ** 2) / denominator\n",
    "        rhat_norm = r_hat * (((gamma_hat ** 3 + 1) * (gamma_hat + 1)) / ((gamma_hat ** 2 + 1) ** 2))\n",
    "\n",
    "        gamma_range = np.arange(0.2, 10, 0.001)\n",
    "        prec_gammas = (special.gamma(2.0 / gamma_range) ** 2) / (special.gamma(1.0 / gamma_range) * special.gamma(3.0 / gamma_range))\n",
    "        pos = np.argmin((prec_gammas - rhat_norm) ** 2)\n",
    "        alpha = gamma_range[pos]\n",
    "\n",
    "        gam1 = special.gamma(1.0 / alpha)\n",
    "        gam2 = special.gamma(2.0 / alpha)\n",
    "        gam3 = special.gamma(3.0 / alpha)\n",
    "        aggdratio = np.sqrt(gam1) / np.sqrt(gam3)\n",
    "        bl = aggdratio * lsq\n",
    "        br = aggdratio * rsq\n",
    "        N = (br - bl) * (gam2 / gam1)\n",
    "        return alpha, N, bl, br, lsq, rsq\n",
    "\n",
    "    def _paired_product(self, im):\n",
    "        \"\"\" Compute pairwise products of MSCN transformed image \"\"\"\n",
    "        H = np.roll(im, -1, axis=1) * im\n",
    "        V = np.roll(im, -1, axis=0) * im\n",
    "        D1 = np.roll(np.roll(im, -1, axis=0), -1, axis=1) * im\n",
    "        D2 = np.roll(np.roll(im, -1, axis=0), 1, axis=1) * im\n",
    "        return H, V, D1, D2\n",
    "    \n",
    "    def _extract_patch_features(self, patch):\n",
    "        \"\"\" Extract features from image patch \"\"\"\n",
    "        alpha_m, N, bl, br, lsq, rsq = self._aggd_features(patch.copy())\n",
    "        pps = self._paired_product(patch)\n",
    "        results = [alpha_m, (bl + br) / 2.0]\n",
    "        for pp in pps:\n",
    "            a, N, bl, br, _, _ = self._aggd_features(pp)\n",
    "            results.extend([a, N, bl, br])\n",
    "        return np.array(results)\n",
    "    \n",
    "    def _extract_patches(self, img, patch_size):\n",
    "        \"\"\" Extract patches from the MSCN-transformed image \"\"\"\n",
    "        h, w = img.shape\n",
    "        patches = []\n",
    "        for j in range(0, h - patch_size + 1, patch_size):\n",
    "            for i in range(0, w - patch_size + 1, patch_size):\n",
    "                patch = img[j:j + patch_size, i:i + patch_size]\n",
    "                if patch.shape == (patch_size, patch_size):\n",
    "                    patches.append(self._extract_patch_features(patch))\n",
    "        if len(patches) == 0:\n",
    "            return np.empty((0, 18), dtype=np.float32)\n",
    "        return np.array(patches)\n",
    "\n",
    "    def _extract_features(self, img):\n",
    "        \"\"\" Extract features from an entire image \"\"\"\n",
    "        mscn1, _, _ = self._compute_mscn_transform(img)\n",
    "        mscn2, _, _ = self._compute_mscn_transform(ndimage.zoom(img, 0.5, order=3))\n",
    "        \n",
    "        f1 = self._extract_patches(mscn1, self.patch_size)\n",
    "        f2 = self._extract_patches(mscn2, self.patch_size // 2)\n",
    "        \n",
    "        if f1.size == 0 or f2.size == 0:\n",
    "            return np.empty((0, 36), dtype=np.float32)\n",
    "        \n",
    "        return np.hstack((f1, f2))\n",
    "    \n",
    "    def _gen_gauss_window(self, lw, sigma):\n",
    "        \"\"\" Generate a Gaussian window for MSCN filtering \"\"\"\n",
    "        sd = float(sigma)\n",
    "        lw = int(lw)\n",
    "        weights = [0.0] * (2 * lw + 1)\n",
    "        weights[lw] = 1.0\n",
    "        s = 1.0\n",
    "        sd *= sd\n",
    "        for ii in range(1, lw + 1):\n",
    "            tmp = np.exp(-0.5 * ii * ii / sd)\n",
    "            weights[lw + ii] = tmp\n",
    "            weights[lw - ii] = tmp\n",
    "            s += 2.0 * tmp\n",
    "        for ii in range(2 * lw + 1):\n",
    "            weights[ii] /= s\n",
    "        return weights\n",
    "\n",
    "    def _compute_mscn_transform(self, image, C=1, avg_window=None):\n",
    "        \"\"\" Compute MSCN (Mean Subtracted Contrast Normalized) transformation \"\"\"\n",
    "        if avg_window is None:\n",
    "            avg_window = self._gen_gauss_window(3, self.sigma)\n",
    "        \n",
    "        h, w = image.shape\n",
    "        mu = np.zeros((h, w), dtype=np.float32)\n",
    "        var = np.zeros((h, w), dtype=np.float32)\n",
    "        \n",
    "        image = image.astype(np.float32)\n",
    "        ndimage.correlate1d(image, avg_window, 0, mu, mode='reflect')\n",
    "        ndimage.correlate1d(mu, avg_window, 1, mu, mode='reflect')\n",
    "        ndimage.correlate1d(image**2, avg_window, 0, var, mode='reflect')\n",
    "        ndimage.correlate1d(var, avg_window, 1, var, mode='reflect')\n",
    "        var = np.sqrt(np.abs(var - mu**2))\n",
    "        \n",
    "        return (image - mu) / (var + C), var, mu\n",
    "    \n",
    "    def train(self, src_dir: Path=None, dst_dir: Path=None, file_name:str=\"NIQE_model\"):\n",
    "        \"\"\"\n",
    "        src_dir: Path to the directory containing training images (8-bit grayscale PNGs).\n",
    "        The function will load all images, convert them to tensors, and use them for training.\n",
    "        \"\"\"\n",
    "        src_dir = src_dir or self.src_pth\n",
    "        dst_dir = dst_dir or self.dst_pth\n",
    "\n",
    "        features = []\n",
    "        for image_path in tqdm(list(src_dir.glob('*.png')), desc=f'Loading and Extracting Features for Images '):\n",
    "            img = np.array(Image.open(image_path).convert('L')).astype(np.uint8)\n",
    "            feats = self._extract_features(img)\n",
    "            if feats.size > 0:\n",
    "                features.append(feats)\n",
    "            \n",
    "        if not features:\n",
    "            raise ValueError(\"No valid features extracted from images.\")\n",
    "        \n",
    "        features = np.vstack(features)\n",
    "        self.mean_vector = np.mean(features, axis=0)\n",
    "        self.covariance_matrix = np.cov(features, rowvar=False)\n",
    "\n",
    "        self.save(path=dst_dir, file_name=file_name)\n",
    "    \n",
    "    def score(self, img):\n",
    "        \"\"\" Evaluate the NIQE score for a given image \"\"\"\n",
    "        if self.mean_vector is None or self.covariance_matrix is None:\n",
    "            raise ValueError(\"NIQE model parameters not loaded or trained.\")\n",
    "            \n",
    "        print(\"Start Scoring\")\n",
    "        if img.ndim == 3:\n",
    "            img = img[0]  # shape [H, W]\n",
    "        elif img.ndim != 2:\n",
    "            raise ValueError(f\"Expected ndarray with shape [1, H, W] or [H, W], got {img.shape}\")\n",
    "        \n",
    "        img = np.clip((img + 0.5) * 255, 0, 255).astype(np.uint8)\n",
    "        feats = self._extract_features(img)\n",
    "        if feats.size == 0:\n",
    "            raise ValueError(\"Image too small for feature extraction with given patch size.\")\n",
    "        \n",
    "        sample_mu = np.mean(feats, axis=0)\n",
    "        sample_cov = np.cov(feats, rowvar=False)\n",
    "        delta = sample_mu - self.mean_vector\n",
    "        covmat = (self.covariance_matrix + sample_cov) / 2.0\n",
    "        pinvmat = linalg.pinv(covmat)\n",
    "\n",
    "        score = np.sqrt(np.dot(np.dot(delta, pinvmat), delta))\n",
    "        return float(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1df961f-ea9d-4ae6-949d-8d91ac0f9304",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "src_dir = Path(\"./Image Datasets/HQ_Mphase/Images\")\n",
    "dst_dir = Path(\"datasets\")\n",
    "\n",
    "class NIQEG:\n",
    "    def __init__(self, src_pth: Path = Path(\"\"), dst_pth: Path = Path(\"\"), sigma: float = 7 / 6, patch_size=96, device=None):\n",
    "        self.mean_vector = None\n",
    "        self.covariance_matrix = None\n",
    "        self.sigma = sigma\n",
    "        self.patch_size = patch_size\n",
    "        self.src_pth = src_pth\n",
    "        self.dst_pth = dst_pth\n",
    "        self.device = device or (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "\n",
    "    def __call__(self, image) -> float:\n",
    "        return self.score(image)\n",
    "\n",
    "    def save(self, path: Path = None, file_name: str = \"NIQE\"):\n",
    "        if self.mean_vector is None or self.covariance_matrix is None:\n",
    "            raise ValueError(\"NIQE model not trained yet.\")\n",
    "\n",
    "        if path is None:\n",
    "            path = self.dst_pth\n",
    "            warnings.warn(f\"Empty Path Warning! Saving to current active directory: {path}\")\n",
    "\n",
    "        temp_path = path / (file_name + \"_mu\")\n",
    "        np.savez(temp_path.with_suffix(\".npz\"), mu=self.mean_vector.astype(np.float32), patch_size=self.patch_size)\n",
    "\n",
    "        temp_path = path / (file_name + \"_cov\")\n",
    "        np.savez(temp_path.with_suffix(\".npz\"), cov=self.covariance_matrix.astype(np.float32))\n",
    "\n",
    "        print(f\"Covariance Matrix({self.covariance_matrix.shape}), Mean Vector({self.mean_vector.shape}) and Patch Size({self.patch_size}) saved successfully!\")\n",
    "\n",
    "    def load(self, path: Path = None, file_name: str = \"NIQE\"):\n",
    "        if path is None:\n",
    "            path = self.dst_pth\n",
    "            warnings.warn(f\"Empty Path Warning! Loading from current active directory: {path}\")\n",
    "        print(\"Loading params for NIQE\")\n",
    "\n",
    "        temp_path = path / (file_name + \"_mu\")\n",
    "        data = np.load(temp_path.with_suffix(\".npz\"))\n",
    "        self.mean_vector = data['mu']\n",
    "        self.patch_size = data['patch_size']\n",
    "\n",
    "        temp_path = path / (file_name + \"_cov\")\n",
    "        self.covariance_matrix = np.load(temp_path.with_suffix(\".npz\"))['cov']\n",
    "\n",
    "        print(f\"Covariance Matrix({self.covariance_matrix.shape}), Mean Vector({self.mean_vector.shape}) and Patch Size({self.patch_size}) loaded successfully!\")\n",
    "\n",
    "    def _gen_gauss_kernel(self, kernel_size=7):\n",
    "        coords = torch.arange(kernel_size, dtype=torch.float32) - kernel_size // 2\n",
    "        g = torch.exp(-(coords ** 2) / (2 * self.sigma ** 2))\n",
    "        g /= g.sum()\n",
    "        kernel = torch.outer(g, g)\n",
    "        return kernel.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    def _compute_mscn(self, image: torch.Tensor):\n",
    "        kernel = self._gen_gauss_kernel().to(image.device)\n",
    "        padding = kernel.shape[-1] // 2\n",
    "        mu = F.conv2d(image, kernel, padding=padding)\n",
    "        mu_sq = mu ** 2\n",
    "        sigma = torch.sqrt(F.conv2d(image ** 2, kernel, padding=padding) - mu_sq + 1e-8)\n",
    "        mscn = (image - mu) / (sigma + 1.0)\n",
    "        return mscn\n",
    "\n",
    "    def _aggd_features(self, imdata: torch.Tensor):\n",
    "        imdata = imdata.flatten()\n",
    "        if imdata.dim() > 1:\n",
    "            imdata = imdata.squeeze(0)  # Only squeeze if necessary\n",
    "        \n",
    "        imdata2 = imdata ** 2\n",
    "        left = imdata2[imdata < 0]\n",
    "        right = imdata2[imdata >= 0]\n",
    "        lsq = torch.sqrt(left.mean()) if left.numel() > 0 else torch.tensor(0.0, device=imdata.device)\n",
    "        rsq = torch.sqrt(right.mean()) if right.numel() > 0 else torch.tensor(0.0, device=imdata.device)\n",
    "        gamma_hat = lsq / rsq if rsq != 0 else torch.tensor(float('inf'), device=imdata.device)\n",
    "        r_hat = (imdata.abs().mean() ** 2) / imdata2.mean()\n",
    "\n",
    "        gamma_range = torch.arange(0.2, 10, 0.001, device=imdata.device)\n",
    "        prec_gammas = (special.gamma(2.0 / gamma_range.cpu()) ** 2) / (\n",
    "            special.gamma(1.0 / gamma_range.cpu()) * special.gamma(3.0 / gamma_range.cpu()))\n",
    "        rhat_norm = r_hat * (((gamma_hat ** 3 + 1) * (gamma_hat + 1)) / ((gamma_hat ** 2 + 1) ** 2))\n",
    "        pos = torch.argmin((torch.tensor(prec_gammas, device=imdata.device) - rhat_norm) ** 2)\n",
    "        alpha = gamma_range[pos]\n",
    "\n",
    "        gam1 = special.gamma(1.0 / alpha.item())\n",
    "        gam2 = special.gamma(2.0 / alpha.item())\n",
    "        gam3 = special.gamma(3.0 / alpha.item())\n",
    "        aggdratio = np.sqrt(gam1) / np.sqrt(gam3)\n",
    "        bl = aggdratio * lsq\n",
    "        br = aggdratio * rsq\n",
    "        N = (br - bl) * (gam2 / gam1)\n",
    "        return torch.tensor([alpha, (bl + br) / 2.0], device=self.device) \n",
    "    \n",
    "    def _aggd_pair_features(self, img):\n",
    "        if img.dim() == 2:\n",
    "            img = img.unsqueeze(0).unsqueeze(0)\n",
    "        elif img.dim() == 3:\n",
    "            img = img.unsqueeze(0)\n",
    "        H = img * torch.roll(img, shifts=-1, dims=3)\n",
    "        V = img * torch.roll(img, shifts=-1, dims=2)\n",
    "        D1 = img * torch.roll(torch.roll(img, shifts=-1, dims=2), shifts=-1, dims=3)\n",
    "        D2 = img * torch.roll(torch.roll(img, shifts=-1, dims=2), shifts=1, dims=3)\n",
    "        features = []\n",
    "        if img.dim() > 1:\n",
    "            img = img.squeeze()  # Only squeeze if necessary\n",
    "        for paired in [H, V, D1, D2]:\n",
    "            features.extend(self._aggd_features(paired.squeeze(0).squeeze(0)))\n",
    "        return torch.tensor(features, device=self.device)\n",
    "    \n",
    "    def _extract_features(self, imgs: torch.Tensor):\n",
    "        if imgs.dim() == 3:\n",
    "            imgs = imgs.unsqueeze(1)  # [B, 1, H, W] for grayscale, no C dimension\n",
    "        imgs = imgs.to(self.device)\n",
    "        mscn1 = self._compute_mscn(imgs)\n",
    "        mscn2 = self._compute_mscn(F.interpolate(imgs, scale_factor=0.5, mode='bilinear', align_corners=False))\n",
    "\n",
    "        features = []\n",
    "        for mscn in tqdm([mscn1, mscn2], desc=\"Calculating MSCN \", position=1, leave=False):  # each: [B, 1, H, W]\n",
    "            B, _, H, W = mscn.shape\n",
    "            patches = []\n",
    "            for i in range(0, H - self.patch_size + 1, self.patch_size):\n",
    "                for j in range(0, W - self.patch_size + 1, self.patch_size):\n",
    "                    patch = mscn[:, :, i:i+self.patch_size, j:j+self.patch_size]  # [B, 1, ps, ps]\n",
    "                    if patch.shape[2:] == (self.patch_size, self.patch_size):\n",
    "                        patches.append(patch)\n",
    "\n",
    "            if patches:\n",
    "                all_patches = torch.cat(patches, dim=0)  # [B * P, 1, ps, ps]\n",
    "                # feats = [self._aggd_features(patch.squeeze(0).squeeze(0)) for patch in all_patches]\n",
    "                feats = [torch.cat([self._aggd_features(patch.squeeze(0).squeeze(0)), self._aggd_pair_features(patch)]) for patch in tqdm(all_patches, position=2, leave=False)]\n",
    "                features.extend(feats)\n",
    "\n",
    "        if not features:\n",
    "            return torch.empty((0, 36), dtype=torch.float32, device=self.device)\n",
    "        return torch.stack(features)\n",
    "    \n",
    "    def train(self, src_dir: Path = None, dst_dir: Path = None, file_name: str = \"NIQE\", batch_size: int = 20):\n",
    "        src_dir = src_dir or self.src_pth\n",
    "        dst_dir = dst_dir or self.dst_pth\n",
    "    \n",
    "        # Initialize accumulators for features and number of samples\n",
    "        accumulated_features = []\n",
    "        num_samples = 0\n",
    "    \n",
    "        # Load images in mini-batches\n",
    "        image_paths = list(src_dir.glob(\"*.png\"))\n",
    "        num_batches = len(image_paths) // batch_size + (1 if len(image_paths) % batch_size != 0 else 0)\n",
    "        \n",
    "        for batch_idx in tqdm(range(num_batches), desc=f\"Processing images in batches from {src_dir}\", position=0, leave=True):\n",
    "            # Get the paths for the current batch of images\n",
    "            batch_paths = image_paths[batch_idx * batch_size: (batch_idx + 1) * batch_size]\n",
    "    \n",
    "            # Load images for the current batch\n",
    "            image_tensors = []\n",
    "            for image_path in tqdm(batch_paths, desc=f\"Images in batch {batch_idx}\", position=1, leave=False):\n",
    "                img = np.array(Image.open(image_path).convert(\"L\"), dtype=np.uint8)\n",
    "                img = torch.from_numpy(img).to(torch.float32)\n",
    "                image_tensors.append(img)\n",
    "    \n",
    "            # Stack the images into a batch tensor [B, H, W]\n",
    "            batch = torch.stack(image_tensors).to(self.device)\n",
    "    \n",
    "            # Extract features for the current batch\n",
    "            feats = self._extract_features(batch)\n",
    "            if feats.size(0) > 0:\n",
    "                accumulated_features.append(feats.cpu())\n",
    "                num_samples += feats.size(0)\n",
    "    \n",
    "        if num_samples == 0:\n",
    "            raise ValueError(\"No valid features extracted from training images.\")\n",
    "    \n",
    "        # Concatenate all extracted features into a single tensor\n",
    "        all_features = torch.cat(accumulated_features, dim=0).numpy()\n",
    "    \n",
    "        # Compute the mean vector and covariance matrix\n",
    "        self.mean_vector = all_features.mean(axis=0)\n",
    "        self.covariance_matrix = np.cov(all_features, rowvar=False)\n",
    "    \n",
    "        # Save the model\n",
    "        self.save(path=dst_dir, file_name=file_name)\n",
    "    \n",
    "    def score(self, img: np.ndarray):\n",
    "        if self.mean_vector is None or self.covariance_matrix is None:\n",
    "            raise ValueError(\"NIQE model parameters not loaded or trained.\")\n",
    "\n",
    "        print(\"Start Scoring\")\n",
    "        if img.ndim == 3:\n",
    "            img = img[0]\n",
    "        elif img.ndim != 2:\n",
    "            raise ValueError(f\"Expected ndarray with shape [1, H, W] or [H, W], got {img.shape}\")\n",
    "\n",
    "        img = np.clip((img + 0.5) * 255, 0, 255).astype(np.uint8)\n",
    "        img = torch.tensor(img, dtype=torch.float32, device=self.device)\n",
    "        img = img.unsqueeze(0).unsqueeze(0)\n",
    "        feats = self._extract_features(img)\n",
    "        if feats.size(0) == 0:\n",
    "            raise ValueError(\"Image too small for feature extraction with given patch size.\")\n",
    "\n",
    "        feats = feats.cpu().numpy()\n",
    "        sample_mu = np.mean(feats, axis=0)\n",
    "        sample_cov = np.cov(feats, rowvar=False)\n",
    "        delta = sample_mu - self.mean_vector\n",
    "        covmat = (self.covariance_matrix + sample_cov) / 2.0\n",
    "        pinvmat = linalg.pinv(covmat)\n",
    "        score = np.sqrt(np.dot(np.dot(delta, pinvmat), delta))\n",
    "        return float(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ff3707-74da-43c7-aa89-922287a0c749",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the NIQE model\n",
    "\n",
    "# niqe_model = NIQEG(src_pth=src_dir, dst_pth=dst_dir)\n",
    "# niqe_model.load(file_name=\"NIQEG\")\n",
    "# niqe_model.train(file_name=\"NIQEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3581b3a5-b73e-4e48-8a58-8951142e2ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del niqe_model\n",
    "# gc.collect() # GC collects the deleted model and clears the memory.\n",
    "# torch.cuda.empty_cache() # Removes any cache data related to the removed model from the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d1e559-af40-4be1-a753-ddfc936af25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path = list((dataset_root_dir / \"evalImgs\").glob('*.png'))[0]\n",
    "# im = Image.open(image_path).convert('L')\n",
    "# image = np.array(im, dtype=np.float32)/255.0 - 0.5\n",
    "# print(image.min(), image.max())\n",
    "\n",
    "# plt.figure(figsize=(5,5))\n",
    "# plt.imshow(im, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dea4532-5fbb-4e27-b0b0-c8d80bd677d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(image.shape)\n",
    "# for idx, img_path in enumerate(list((dataset_root_dir / \"evalImgs\").glob('*.png'))):\n",
    "    # im = Image.open(image_path).convert('L')\n",
    "    # image = np.array(im, dtype=np.float32)/255.0 - 0.5\n",
    "    # score = niqe_model.score(image)\n",
    "    # print(f\"Image {idx} -> {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df7c1c7-c559-4fe2-b7ac-fa2f1c5df92a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PATH = Path(\"./Results_bernoulli_test_5/Evaluation Tests_0/output001.png\")\n",
    "# I = np.array(Image.open(PATH).convert('L'), dtype=np.uint8)\n",
    "# plt.figure(figsize=(20,20))\n",
    "# plt.imshow(I, cmap='gray')\n",
    "# I = np.array(I, dtype=np.float32)/255.0 - 0.5\n",
    "# niqe_model.score(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3a325f-93c1-4228-9d8c-d3536c9c1ccc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import ndimage, special, linalg\n",
    "\n",
    "class NIQE2:\n",
    "    def __init__(self, patch_size=96):\n",
    "        self.patch_size = patch_size\n",
    "        self.mu = None\n",
    "        self.cov = None\n",
    "\n",
    "    def save(self, path):\n",
    "        np.savez(path, mu=self.mu, cov=self.cov, patch_size=self.patch_size)\n",
    "\n",
    "    def load(self, path):\n",
    "        data = np.load(path)\n",
    "        self.mu = data['mu']\n",
    "        self.cov = data['cov']\n",
    "        self.patch_size = int(data['patch_size'])\n",
    "\n",
    "    def _gen_gauss_window(self, lw, sigma):\n",
    "        sd = float(sigma)\n",
    "        lw = int(lw)\n",
    "        weights = [0.0] * (2 * lw + 1)\n",
    "        weights[lw] = 1.0\n",
    "        s = 1.0\n",
    "        sd *= sd\n",
    "        for ii in range(1, lw + 1):\n",
    "            tmp = np.exp(-0.5 * ii * ii / sd)\n",
    "            weights[lw + ii] = tmp\n",
    "            weights[lw - ii] = tmp\n",
    "            s += 2.0 * tmp\n",
    "        for ii in range(2 * lw + 1):\n",
    "            weights[ii] /= s\n",
    "        return weights\n",
    "\n",
    "    def _compute_mscn_transform(self, image, C=1, avg_window=None):\n",
    "        if avg_window is None:\n",
    "            avg_window = self._gen_gauss_window(3, 7.0 / 6.0)\n",
    "        h, w = image.shape\n",
    "        mu = np.zeros((h, w), dtype=np.float32)\n",
    "        var = np.zeros((h, w), dtype=np.float32)\n",
    "        image = image.astype(np.float32)\n",
    "        ndimage.correlate1d(image, avg_window, 0, mu, mode='reflect')\n",
    "        ndimage.correlate1d(mu, avg_window, 1, mu, mode='reflect')\n",
    "        ndimage.correlate1d(image**2, avg_window, 0, var, mode='reflect')\n",
    "        ndimage.correlate1d(var, avg_window, 1, var, mode='reflect')\n",
    "        var = np.sqrt(np.abs(var - mu**2))\n",
    "        return (image - mu) / (var + C), var, mu\n",
    "\n",
    "    def _aggd_features(self, imdata):\n",
    "        imdata = imdata.flatten()\n",
    "        imdata2 = imdata ** 2\n",
    "        left_data = imdata2[imdata < 0]\n",
    "        right_data = imdata2[imdata >= 0]\n",
    "        lsq = np.sqrt(np.mean(left_data)) if len(left_data) > 0 else 0\n",
    "        rsq = np.sqrt(np.mean(right_data)) if len(right_data) > 0 else 0\n",
    "        gamma_hat = lsq / rsq if rsq != 0 else np.inf\n",
    "        r_hat = (np.mean(np.abs(imdata)) ** 2) / np.mean(imdata2)\n",
    "        rhat_norm = r_hat * (((gamma_hat ** 3 + 1) * (gamma_hat + 1)) / ((gamma_hat ** 2 + 1) ** 2))\n",
    "\n",
    "        gamma_range = np.arange(0.2, 10, 0.001)\n",
    "        prec_gammas = (special.gamma(2.0 / gamma_range) ** 2) / (special.gamma(1.0 / gamma_range) * special.gamma(3.0 / gamma_range))\n",
    "        pos = np.argmin((prec_gammas - rhat_norm) ** 2)\n",
    "        alpha = gamma_range[pos]\n",
    "\n",
    "        gam1 = special.gamma(1.0 / alpha)\n",
    "        gam2 = special.gamma(2.0 / alpha)\n",
    "        gam3 = special.gamma(3.0 / alpha)\n",
    "        aggdratio = np.sqrt(gam1) / np.sqrt(gam3)\n",
    "        bl = aggdratio * lsq\n",
    "        br = aggdratio * rsq\n",
    "        N = (br - bl) * (gam2 / gam1)\n",
    "        return alpha, N, bl, br, lsq, rsq\n",
    "\n",
    "    def _paired_product(self, im):\n",
    "        H = np.roll(im, -1, axis=1) * im\n",
    "        V = np.roll(im, -1, axis=0) * im\n",
    "        D1 = np.roll(np.roll(im, -1, axis=0), -1, axis=1) * im\n",
    "        D2 = np.roll(np.roll(im, -1, axis=0), 1, axis=1) * im\n",
    "        return H, V, D1, D2\n",
    "\n",
    "    def _extract_patch_features(self, patch):\n",
    "        alpha_m, N, bl, br, lsq, rsq = self._aggd_features(patch.copy())\n",
    "        pps = self._paired_product(patch)\n",
    "        results = [alpha_m, (bl + br) / 2.0]\n",
    "        for pp in pps:\n",
    "            a, N, bl, br, _, _ = self._aggd_features(pp)\n",
    "            results.extend([a, N, bl, br])\n",
    "        return np.array(results)\n",
    "\n",
    "    def _extract_features(self, img):\n",
    "        mscn1, _, _ = self._compute_mscn_transform(img)\n",
    "        mscn2, _, _ = self._compute_mscn_transform(ndimage.zoom(img, 0.5, order=3))\n",
    "        f1 = self._extract_patches(mscn1, self.patch_size)\n",
    "        f2 = self._extract_patches(mscn2, self.patch_size // 2)\n",
    "        if f1.size == 0 or f2.size == 0:\n",
    "            return np.empty((0, 36), dtype=np.float32)\n",
    "        return np.hstack((f1, f2))\n",
    "\n",
    "    def _extract_patches(self, img, patch_size):\n",
    "        h, w = img.shape\n",
    "        patches = []\n",
    "        for j in range(0, h - patch_size + 1, patch_size):\n",
    "            for i in range(0, w - patch_size + 1, patch_size):\n",
    "                patch = img[j:j + patch_size, i:i + patch_size]\n",
    "                if patch.shape == (patch_size, patch_size):\n",
    "                    patches.append(self._extract_patch_features(patch))\n",
    "        if len(patches) == 0:\n",
    "            return np.empty((0, 18), dtype=np.float32)\n",
    "        return np.array(patches)\n",
    "\n",
    "    def train(self, images):\n",
    "        feats = []\n",
    "        for img in images:\n",
    "            feats.append(self._extract_features(img))\n",
    "        feats = np.vstack(feats)\n",
    "        self.mu = np.mean(feats, axis=0)\n",
    "        self.cov = np.cov(feats.T)\n",
    "\n",
    "    def eval(self, img):\n",
    "        feats = self._extract_features(img)\n",
    "        if feats.size == 0:\n",
    "            raise ValueError(\"Image too small for feature extraction with given patch size.\")\n",
    "        sample_mu = np.mean(feats, axis=0)\n",
    "        sample_cov = np.cov(feats.T)\n",
    "        X = sample_mu - self.mu\n",
    "        covmat = (self.cov + sample_cov) / 2.0\n",
    "        pinvmat = linalg.pinv(covmat)\n",
    "        return float(np.sqrt(np.dot(np.dot(X, pinvmat), X)))\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return self.eval(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9f8b48-0863-41ce-a0b0-ff5035be27f5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class NIQE:\n",
    "    def __init__(self, patch_size=96, sigma=7/6):\n",
    "        self.patch_size = patch_size\n",
    "        self.sigma = sigma\n",
    "        self.mu = None\n",
    "        self.cov = None\n",
    "    \n",
    "    def save(self, path):\n",
    "        \"\"\" Save trained NIQE model to a specified path \"\"\"\n",
    "        np.savez(path, mu=self.mu, cov=self.cov, patch_size=self.patch_size)\n",
    "    \n",
    "    def load(self, path):\n",
    "        \"\"\" Load a pre-trained NIQE model from a specified path \"\"\"\n",
    "        data = np.load(path)\n",
    "        self.mu = data['mu']\n",
    "        self.cov = data['cov']\n",
    "        self.patch_size = int(data['patch_size'])\n",
    "\n",
    "    def _gen_gauss_window(self, lw, sigma):\n",
    "        \"\"\" Generate a Gaussian window for MSCN filtering \"\"\"\n",
    "        sd = float(sigma)\n",
    "        lw = int(lw)\n",
    "        weights = [0.0] * (2 * lw + 1)\n",
    "        weights[lw] = 1.0\n",
    "        s = 1.0\n",
    "        sd *= sd\n",
    "        for ii in range(1, lw + 1):\n",
    "            tmp = np.exp(-0.5 * ii * ii / sd)\n",
    "            weights[lw + ii] = tmp\n",
    "            weights[lw - ii] = tmp\n",
    "            s += 2.0 * tmp\n",
    "        for ii in range(2 * lw + 1):\n",
    "            weights[ii] /= s\n",
    "        return weights\n",
    "\n",
    "    def _compute_mscn_transform(self, image, C=1, avg_window=None):\n",
    "        \"\"\" Compute MSCN (Mean Subtracted Contrast Normalized) transformation \"\"\"\n",
    "        if avg_window is None:\n",
    "            avg_window = self._gen_gauss_window(3, self.sigma)\n",
    "        \n",
    "        h, w = image.shape\n",
    "        mu = np.zeros((h, w), dtype=np.float32)\n",
    "        var = np.zeros((h, w), dtype=np.float32)\n",
    "        \n",
    "        image = image.astype(np.float32)\n",
    "        ndimage.correlate1d(image, avg_window, 0, mu, mode='reflect')\n",
    "        ndimage.correlate1d(mu, avg_window, 1, mu, mode='reflect')\n",
    "        ndimage.correlate1d(image**2, avg_window, 0, var, mode='reflect')\n",
    "        ndimage.correlate1d(var, avg_window, 1, var, mode='reflect')\n",
    "        var = np.sqrt(np.abs(var - mu**2))\n",
    "        \n",
    "        return (image - mu) / (var + C), var, mu\n",
    "\n",
    "    def _aggd_features(self, imdata):\n",
    "        \"\"\" Compute AGGD (Asymmetric Generalized Gaussian Distribution) features \"\"\"\n",
    "        imdata = imdata.flatten()\n",
    "        imdata2 = imdata ** 2\n",
    "        left_data = imdata2[imdata < 0]\n",
    "        right_data = imdata2[imdata >= 0]\n",
    "        lsq = np.sqrt(np.mean(left_data)) if len(left_data) > 0 else 0\n",
    "        rsq = np.sqrt(np.mean(right_data)) if len(right_data) > 0 else 0\n",
    "        gamma_hat = lsq / rsq if rsq != 0 else np.inf\n",
    "        r_hat = (np.mean(np.abs(imdata)) ** 2) / np.mean(imdata2)\n",
    "        rhat_norm = r_hat * (((gamma_hat ** 3 + 1) * (gamma_hat + 1)) / ((gamma_hat ** 2 + 1) ** 2))\n",
    "\n",
    "        gamma_range = np.arange(0.2, 10, 0.001)\n",
    "        prec_gammas = (special.gamma(2.0 / gamma_range) ** 2) / (special.gamma(1.0 / gamma_range) * special.gamma(3.0 / gamma_range))\n",
    "        pos = np.argmin((prec_gammas - rhat_norm) ** 2)\n",
    "        alpha = gamma_range[pos]\n",
    "\n",
    "        gam1 = special.gamma(1.0 / alpha)\n",
    "        gam2 = special.gamma(2.0 / alpha)\n",
    "        gam3 = special.gamma(3.0 / alpha)\n",
    "        aggdratio = np.sqrt(gam1) / np.sqrt(gam3)\n",
    "        bl = aggdratio * lsq\n",
    "        br = aggdratio * rsq\n",
    "        N = (br - bl) * (gam2 / gam1)\n",
    "        return alpha, N, bl, br, lsq, rsq\n",
    "\n",
    "    def _paired_product(self, im):\n",
    "        \"\"\" Compute pairwise products of MSCN transformed image \"\"\"\n",
    "        H = np.roll(im, -1, axis=1) * im\n",
    "        V = np.roll(im, -1, axis=0) * im\n",
    "        D1 = np.roll(np.roll(im, -1, axis=0), -1, axis=1) * im\n",
    "        D2 = np.roll(np.roll(im, -1, axis=0), 1, axis=1) * im\n",
    "        return H, V, D1, D2\n",
    "\n",
    "    def _extract_patch_features(self, patch):\n",
    "        \"\"\" Extract features from image patch \"\"\"\n",
    "        alpha_m, N, bl, br, lsq, rsq = self._aggd_features(patch.copy())\n",
    "        pps = self._paired_product(patch)\n",
    "        results = [alpha_m, (bl + br) / 2.0]\n",
    "        for pp in pps:\n",
    "            a, N, bl, br, _, _ = self._aggd_features(pp)\n",
    "            results.extend([a, N, bl, br])\n",
    "        return np.array(results)\n",
    "\n",
    "    def _extract_features(self, img):\n",
    "        \"\"\" Extract features from an entire image \"\"\"\n",
    "        mscn1, _, _ = self._compute_mscn_transform(img)\n",
    "        mscn2, _, _ = self._compute_mscn_transform(ndimage.zoom(img, 0.5, order=3))\n",
    "        \n",
    "        f1 = self._extract_patches(mscn1, self.patch_size)\n",
    "        f2 = self._extract_patches(mscn2, self.patch_size // 2)\n",
    "        \n",
    "        if f1.size == 0 or f2.size == 0:\n",
    "            return np.empty((0, 36), dtype=np.float32)\n",
    "        \n",
    "        return np.hstack((f1, f2))\n",
    "\n",
    "    def _extract_patches(self, img, patch_size):\n",
    "        \"\"\" Extract patches from the MSCN-transformed image \"\"\"\n",
    "        h, w = img.shape\n",
    "        patches = []\n",
    "        for j in range(0, h - patch_size + 1, patch_size):\n",
    "            for i in range(0, w - patch_size + 1, patch_size):\n",
    "                patch = img[j:j + patch_size, i:i + patch_size]\n",
    "                if patch.shape == (patch_size, patch_size):\n",
    "                    patches.append(self._extract_patch_features(patch))\n",
    "        if len(patches) == 0:\n",
    "            return np.empty((0, 18), dtype=np.float32)\n",
    "        return np.array(patches)\n",
    "\n",
    "    def train(self, images):\n",
    "        \"\"\" Train NIQE model using a list of images \"\"\"\n",
    "        feats = []\n",
    "        for img in tqdm(images, desc=\"Extracting features\"):\n",
    "            feats.append(self._extract_features(img))\n",
    "        feats = np.vstack(feats)\n",
    "        self.mu = np.mean(feats, axis=0)\n",
    "        self.cov = np.cov(feats.T)\n",
    "\n",
    "    def eval(self, img):\n",
    "        \"\"\" Evaluate the NIQE score for a given image \"\"\"\n",
    "        feats = self._extract_features(img)\n",
    "        if feats.size == 0:\n",
    "            raise ValueError(\"Image too small for feature extraction with given patch size.\")\n",
    "        \n",
    "        sample_mu = np.mean(feats, axis=0)\n",
    "        sample_cov = np.cov(feats.T)\n",
    "        X = sample_mu - self.mu\n",
    "        covmat = (self.cov + sample_cov) / 2.0\n",
    "        pinvmat = linalg.pinv(covmat)\n",
    "        \n",
    "        return float(np.sqrt(np.dot(np.dot(X, pinvmat), X)))\n",
    "\n",
    "    def __call__(self, img):\n",
    "        \"\"\" Simplified interface to evaluate NIQE score \"\"\"\n",
    "        return self.eval(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd830da3-a2ba-4fb1-9117-5c95f1ec4228",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9f0fe8-e1b3-4c83-898b-d2f7a7b0c7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, n_ip, n_out, kernel_size=3, gain=torch.sqrt(torch.tensor(2, dtype=torch.float32)), bias=True):\n",
    "        super(ConvLayer, self).__init__()\n",
    "\n",
    "        wstd = gain / torch.sqrt(torch.prod(torch.tensor([kernel_size, kernel_size , n_ip], dtype=torch.float32)))\n",
    "        self.conv = nn.Conv2d(in_channels=n_ip, out_channels=n_out, kernel_size=kernel_size, padding=kernel_size//2, stride=1, bias=bias)\n",
    "        # Initialize weights\n",
    "        nn.init.normal_(self.conv.weight, mean=0.0, std=wstd)\n",
    "        # Initialize Bias\n",
    "        nn.init.zeros_(self.conv.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "    \n",
    "class UpsampleLayer(nn.Module):\n",
    "    def __init__(self, scale_factor=2):\n",
    "        super(UpsampleLayer, self).__init__()\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Tensor structure: [batch_size, channels, height, width]\n",
    "        # return x.repeat_interleave(self.scale_factor, dim=2).repeat_interleave(self.scale_factor, dim=3) # tile across dim=2 (height) and 3(width)\n",
    "        return F.interpolate(x, scale_factor=self.scale_factor, mode='nearest')\n",
    "\n",
    "class DownsampleLayer(nn.Module):\n",
    "    def __init__(self, scale_factor=2):\n",
    "        super(DownsampleLayer, self).__init__()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=scale_factor, stride=scale_factor, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pool(x)\n",
    "    \n",
    "class Concat(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Concat, self).__init__()\n",
    "        \n",
    "    def forward(self, layers):\n",
    "        return torch.cat(layers, dim=1)\n",
    "        \n",
    "class LeakyReLU(nn.Module):\n",
    "    def __init__(self, negative_slope=0.1):\n",
    "        super(LeakyReLU, self).__init__()\n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope=negative_slope)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.leaky_relu(x)\n",
    "        \n",
    "class Noise2Noise(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Noise2Noise, self).__init__()\n",
    "        self.enc_conv0 = ConvLayer(1, 48)\n",
    "        self.enc_conv1 = ConvLayer(48, 48)\n",
    "        self.pool1 = DownsampleLayer() # 24\n",
    "        \n",
    "        self.enc_conv2 = ConvLayer(48, 48)\n",
    "        self.pool2 = DownsampleLayer() # 24\n",
    "        \n",
    "        self.enc_conv3 = ConvLayer(48, 48)\n",
    "        self.pool3 = DownsampleLayer() # 24\n",
    "        \n",
    "        self.enc_conv4 = ConvLayer(48, 48)\n",
    "        self.pool4 = DownsampleLayer() # 24\n",
    "        \n",
    "        self.enc_conv5 = ConvLayer(48, 48)\n",
    "        self.pool5 = DownsampleLayer() # 24\n",
    "        \n",
    "        self.enc_conv6 = ConvLayer(48, 48)\n",
    "        \n",
    "        self.upsample5 = UpsampleLayer() # 48\n",
    "        self.concat5 = Concat()\n",
    "        self.dec_conv5 = ConvLayer(96, 96)\n",
    "        self.dec_conv5b = ConvLayer(96, 96)\n",
    "        \n",
    "        self.upsample4 = UpsampleLayer() # 96\n",
    "        self.concat4 = Concat()\n",
    "        self.dec_conv4 = ConvLayer(144, 96)\n",
    "        self.dec_conv4b = ConvLayer(96, 96)\n",
    "        \n",
    "        self.upsample3 = UpsampleLayer() # 96\n",
    "        self.concat3 = Concat()\n",
    "        self.dec_conv3 = ConvLayer(144, 96)\n",
    "        self.dec_conv3b = ConvLayer(96, 96)\n",
    "        \n",
    "        self.upsample2 = UpsampleLayer() # 96\n",
    "        self.concat2 = Concat()\n",
    "        self.dec_conv2 = ConvLayer(144, 96)\n",
    "        self.dec_conv2b = ConvLayer(96, 96)\n",
    "        \n",
    "        self.upsample1 = UpsampleLayer() # 96\n",
    "        self.concat1 = Concat()\n",
    "        self.dec_conv1a = ConvLayer(96 + 1, 64)\n",
    "        self.dec_conv1b = ConvLayer(64, 32)\n",
    "        \n",
    "        self.dec_conv1 = ConvLayer(32, 1, gain=1.0)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        if int(x.shape[-1])%2 == 1:\n",
    "            x = F.pad(x, (0, 1, 0, 1), \"constant\", -0.5)\n",
    "        \n",
    "        # x = F.pad(x, (0, 1, 0, 1), \"constant\", -0.5)\n",
    "        input = x.unsqueeze(1)\n",
    "        \n",
    "        x = F.leaky_relu(self.enc_conv0(input), 0.1)\n",
    "        x = F.leaky_relu(self.enc_conv1(x), 0.1)\n",
    "        x = self.pool1(x)\n",
    "        pool1 = x\n",
    "        \n",
    "        x = F.leaky_relu(self.enc_conv2(pool1), 0.1)\n",
    "        x = self.pool2(x)\n",
    "        pool2 = x\n",
    "        \n",
    "        x = F.leaky_relu(self.enc_conv3(pool2), 0.1)\n",
    "        x = self.pool3(x)\n",
    "        pool3 = x\n",
    "        \n",
    "        x = F.leaky_relu(self.enc_conv4(pool3), 0.1)\n",
    "        x = self.pool4(x)\n",
    "        pool4 = x\n",
    "        \n",
    "        x = F.leaky_relu(self.enc_conv5(pool4), 0.1)\n",
    "        x = self.pool5(x)\n",
    "        pool5 = x\n",
    "        x = F.leaky_relu(self.enc_conv6(x), 0.1)\n",
    "        \n",
    "        x = self.upsample5(x)\n",
    "        x = self.concat5([x, pool4])\n",
    "        x = F.leaky_relu(self.dec_conv5(x), 0.1)\n",
    "        x = F.leaky_relu(self.dec_conv5b(x), 0.1)\n",
    "        \n",
    "        x = self.upsample4(x)\n",
    "        x = self.concat4([x, pool3])\n",
    "        x = F.leaky_relu(self.dec_conv4(x), 0.1)\n",
    "        x = F.leaky_relu(self.dec_conv4b(x), 0.1)\n",
    "        \n",
    "        x = self.upsample3(x)\n",
    "        x = self.concat3([x, pool2])\n",
    "        x = F.leaky_relu(self.dec_conv3(x), 0.1)\n",
    "        x = F.leaky_relu(self.dec_conv3b(x), 0.1)\n",
    "        \n",
    "        x = self.upsample2(x)\n",
    "        x = self.concat2([x, pool1])\n",
    "        x = F.leaky_relu(self.dec_conv2(x), 0.1)\n",
    "        x = F.leaky_relu(self.dec_conv2b(x), 0.1)\n",
    "        \n",
    "        x = self.upsample1(x)\n",
    "        x = self.concat1([x, input])\n",
    "        x = F.leaky_relu(self.dec_conv1a(x), 0.1)\n",
    "        x = F.leaky_relu(self.dec_conv1b(x), 0.1)\n",
    "        \n",
    "        x = self.dec_conv1(x)\n",
    "        return x.squeeze(1)[:, :-1, :-1]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bafce3-1da7-4fb6-85d5-29e5b6ee0b7f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# The Execution Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f296f55f-45ce-4145-ac97-a3b456d3ed34",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Trainer Class\n",
    "<b>Description: </b> \n",
    "    This class will contain functions for the model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab7b0cb-5164-4aee-a2da-27422ad20eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Trainer Class\n",
    "#\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self,\n",
    "            gpu_id: int,\n",
    "            model: torch.nn.Module,\n",
    "            train_data: Dataset,\n",
    "            valid_data: Dataset,\n",
    "            optimizer: torch.optim.Optimizer,\n",
    "            scheduler: torch.optim.lr_scheduler,\n",
    "            loss_fn: Callable,\n",
    "            experiment_id: int,\n",
    "            save_interval: int = 10,\n",
    "            batch_size: int = 32,\n",
    "            load_checkpoint: bool = False,\n",
    "            **kwargs) -> None:\n",
    "        self.device = gpu_id\n",
    "        self.model = model.to(gpu_id)\n",
    "        self.train_data = train_data\n",
    "        self.valid_data = valid_data\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler if scheduler else torch.optim.lr_scheduler.ConstantLR(optimizer, factor=1.0)\n",
    "        self.loss_fn = loss_fn\n",
    "        self.experiment_id = experiment_id\n",
    "        self.save_interval = save_interval\n",
    "        self.batch_size = batch_size\n",
    "        self.init_kwargs = kwargs\n",
    "        self.experiment_desc = \"\"\n",
    "        self.post_op = kwargs.get(\"post_op\", None)\n",
    "        self.load_checkpoint = load_checkpoint\n",
    "        self.snapshot_path = kwargs.get(\"snapshot_path\", Path(\".\"))\n",
    "        self.snapshot_name = kwargs.get(\"snapshot_name\", Path(\"latest-snapshot\"))\n",
    "        self.final_epoch = kwargs.get('final_epoch', False)\n",
    "        self.max_epochs = kwargs.get(\"max_epochs\", 300)\n",
    "        self.results_dir = kwargs.get(\"results_dir\", self.get_results_dir())\n",
    "        self.start_epoch = 0\n",
    "        self.epoch = 0\n",
    "        self.target_noise_injection_factor = 1\n",
    "        self.corruption_masks = {}\n",
    "        self.augment_translate_cache = {}\n",
    "        self.train_loader = None\n",
    "        self.valid_loader = None\n",
    "        self.training_test_path = self.results_dir / \"Training Tests\"\n",
    "        self.validation_test_path = self.results_dir / \"Post Training Validation Tests\"\n",
    "        self.evaluation_test_path = self.results_dir / \"Evaluation Tests\"\n",
    "        # Make Required Directories\n",
    "        self.training_test_path.mkdir(parents=True, exist_ok=True)\n",
    "        self.validation_test_path.mkdir(parents=True, exist_ok=True)\n",
    "        self.evaluation_test_path.mkdir(parents=True, exist_ok=True)\n",
    "        if str(self.snapshot_path) == \".\":\n",
    "            self.snapshot_path = self.results_dir / \"Snapshots\"\n",
    "        if self.load_checkpoint:\n",
    "            self._load_snapshot()\n",
    "        # Logging Setup\n",
    "        self.writer = SummaryWriter(log_dir=str(self.results_dir))\n",
    "        self.logger = self.Logger(str(self.results_dir / \"log.txt\"))\n",
    "    \n",
    "    class Logger(object):\n",
    "        '''\n",
    "        A Logger class that directs all the calls to standard output stream to a log file.\n",
    "        '''\n",
    "        def __init__(self, filepath):\n",
    "            self.terminal = sys.stdout\n",
    "            self.log = open(filepath, \"a\", buffering=1)  # Line-buffered\n",
    "\n",
    "        def __enter__(self):\n",
    "            sys.stdout = self\n",
    "            return self\n",
    "\n",
    "        def __exit__(self, exception_type, exception_value, exception_traceback):\n",
    "            if self.log:\n",
    "                self.log.close()\n",
    "            sys.stdout = sys.__stdout__\n",
    "\n",
    "        def __del__(self):\n",
    "            \"\"\"Ensure log file is closed when Logger object is deleted.\"\"\"\n",
    "            if self.log:\n",
    "                self.log.close()\n",
    "        \n",
    "        def write(self, message):\n",
    "            self.terminal.write(message)\n",
    "            self.log.write(message)\n",
    "        \n",
    "        def flush(self):\n",
    "            self.terminal.flush()\n",
    "            self.log.flush()\n",
    "\n",
    "        def start(self):\n",
    "            sys.stdout = self\n",
    "        \n",
    "        def stop(self):\n",
    "            if self.log:\n",
    "                self.log.close()\n",
    "            sys.stdout = sys.__stdout__\n",
    "    \n",
    "    def get_results_dir(self, idx=0):\n",
    "        '''\n",
    "        Generates a unique address path for results directory for a new run.\n",
    "        \n",
    "        Args:\n",
    "            [Optional] idx (int): Starting index for the counting.\n",
    "        \n",
    "        Returns:\n",
    "            results_dir (Path): Path object with a uniquely indexed path.\n",
    "        '''\n",
    "        root = Path(\"results\")\n",
    "        if self.experiment_desc != \"\": \n",
    "            root /= f\"{self.experiment_id:03d}-{self.experiment_desc}\"\n",
    "        else:\n",
    "            root /= f\"{self.experiment_id:03d}\"\n",
    "\n",
    "        chk_dir = root / f\"run-{idx}_{dt.now().strftime('%Y-%m-%d')}\"\n",
    "        \n",
    "        while chk_dir.is_dir():\n",
    "            idx += 1\n",
    "            chk_dir = root / f\"run-{idx}_{dt.now().strftime('%Y-%m-%d')}\"\n",
    "        return chk_dir\n",
    "    \n",
    "    def _save_snapshot(self):\n",
    "        \"\"\"\n",
    "        This function saves a snapshot of current training model and optimizer dict parameters along with the current epoch.\n",
    "        \"\"\"\n",
    "        self.snapshot_path.mkdir(parents=True, exist_ok=True)\n",
    "        snapshot = {}\n",
    "        snapshot[\"STATE_DICT\"] = self.model.state_dict()\n",
    "        snapshot[\"CURR_EPOCH\"] = self.epoch\n",
    "        snapshot[\"OPTIMIZER_DICT\"] = self.optimizer.state_dict()\n",
    "        torch.save(snapshot, self.snapshot_path / \"latest-snapshot.pth\")\n",
    "        torch.save(snapshot, self.snapshot_path / f\"snapshot-{self.epoch:03d}.pth\")\n",
    "        print(f\"Epoch {self.epoch}:\\n\\t Training Snapshot Saved at as [snapshot-{self.epoch:03d}.pth] at {self.snapshot_path} \\n\\t Latest Snapshot Updated!\")\n",
    "        \n",
    "    def _load_snapshot(self):\n",
    "        '''\n",
    "        This function loads a snapshot of the model with a given snapshot_name from the provided snapshot_path.\n",
    "        Loads the latest-snapshot.pth from default location if no snapshot_name is provided.\n",
    "        '''\n",
    "        path = self.snapshot_path / (str(self.snapshot_name) + \".pth\")\n",
    "        assert path.exists()\n",
    "        \n",
    "        snapshot = torch.load(path, weights_only=True)\n",
    "        self.model.load_state_dict(snapshot[\"STATE_DICT\"])\n",
    "        self.start_epoch = snapshot[\"CURR_EPOCH\"]\n",
    "        self.optimizer.load_state_dict(snapshot[\"OPTIMIZER_DICT\"])\n",
    "        print(f\"Loading Snapshot: %s.pth | Current Epoch: %d\"%(self.snapshot_name, self.start_epoch))\n",
    "    \n",
    "    def _post_op(self, op_type, denoised, spec_value, spec_mask):\n",
    "        '''\n",
    "        Performs the post-operation procedure of forcing known frequencies before the training.\n",
    "\n",
    "        Args:\n",
    "            op_type (str): Type of post-op requested.\n",
    "            denoised (Tensor: float): The image to perform post-op on.\n",
    "            spec_value (Tensor: complex): The spectral representation of the image.\n",
    "            spec_mask (Tensor: float): The mask used for post-op in spectral domain.\n",
    "            \n",
    "        Returns:\n",
    "            denoised (Tensor: float): The image after post-op is performed.\n",
    "        '''\n",
    "        if op_type =='fspec':\n",
    "            def fftshift3d(x, ifft=False):\n",
    "                '''\n",
    "                Performs a mannual Fast Fourier Shift over a 3D tensor.\n",
    "                '''\n",
    "                assert len(x.shape) == 3\n",
    "                s0 = (x.shape[-2] // 2) + (0 if ifft else 1)\n",
    "                s1 = (x.shape[-1] // 2) + (0 if ifft else 1)\n",
    "                x = torch.cat([x[:, s0:, :], x[:, :s0, :]], dim=1)\n",
    "                x = torch.cat([x[:, :, s1:], x[:, :, :s1]], dim=2)\n",
    "                return x\n",
    "            \n",
    "            # print(\"Force denoised spectrum to known values.\")\n",
    "            # FFT\n",
    "            denoised_spec = torch.fft.fft2(denoised)     \n",
    "            # FFT shift\n",
    "            denoised_spec = fftshift3d(denoised_spec, ifft=False)\n",
    "            # Ensure correct dtypes and device\n",
    "            spec_value = spec_value.to(denoised_spec.dtype).to(denoised_spec.device)\n",
    "            spec_mask = spec_mask.to(denoised_spec.dtype).to(denoised_spec.device)\n",
    "            # Force known frequencies using mask\n",
    "            denoised_spec = spec_value * spec_mask + denoised_spec * (1. - spec_mask)\n",
    "            # Shift back and IFFT\n",
    "            denoised = torch.fft.ifft2(fftshift3d(denoised_spec, ifft=True)).real\n",
    "        else:\n",
    "            warnings.warn(\"Invalid Post-Op requested. No Post-Op performed.\")\n",
    "        return denoised\n",
    "    \n",
    "    def _compute_spectral(self, image, ifft=False, magnitude=False, normalize=True):\n",
    "        \"\"\"\n",
    "        Computes the spectral image using the magnitude of the 2D Fourier Transform.\n",
    "        \n",
    "        Args:\n",
    "            image (Tensor): A single CT scan patch (grayscale).\n",
    "            ifft (bool): Boolean for if it's an inverse fast fourier shift.\n",
    "            magnitude (bool): Boolean to get log of magnitude of the spectral representation.\n",
    "            normalize (bool): Boolean to normalize the magnitude to the range [0, 1]\n",
    "            \n",
    "        Returns:\n",
    "            spectral_image (Tensor): The spectral representation.\n",
    "            magnitude (Tensor: float): Log of the magnitude of the spectral representation.\n",
    "        \"\"\"\n",
    "        fft_shift = None\n",
    "        if ifft:\n",
    "            fft_shift = torch.fft.ifftshift(image, dim=(-2, -1))  # Shift zero frequency to center\n",
    "        else:\n",
    "            fft_image = torch.fft.fft2(image)  # Apply 2D Fourier Transform\n",
    "            fft_shift = torch.fft.fftshift(fft_image, dim=(-2, -1))  # Shift zero frequency to center\n",
    "        \n",
    "        if magnitude:\n",
    "            magnitude_spectrum = torch.abs(fft_shift)  # Get magnitude\n",
    "            # Normalize the spectrum for consistency\n",
    "            magnitude_spectrum = torch.log1p(magnitude_spectrum)  # Log scaling\n",
    "            \n",
    "            if normalize:\n",
    "                magnitude_spectrum = (magnitude_spectrum - magnitude_spectrum.min()) / (magnitude_spectrum.max() - magnitude_spectrum.min())\n",
    "                # magnitude_spectrum /= magnitude_spectrum.max()  # Normalize [0,1]\n",
    "                \n",
    "            return fft_shift.to(torch.complex64), magnitude_spectrum\n",
    "        else: \n",
    "            return fft_shift.to(torch.complex64)\n",
    "        \n",
    "    def _psnr_scores(self, image, target, max_pixel_value=1.0):\n",
    "        '''\n",
    "        Computed PSNR scores for given image and target pair.\n",
    "\n",
    "        Args:\n",
    "            image (Tensor): Image to calculate the score for.\n",
    "            target (Tensor): Image as a reference target.\n",
    "            max_pixel_value (float): Max value of \n",
    "            \n",
    "        Returns:\n",
    "            spectral_image (Tensor): The spectral representation.\n",
    "        '''\n",
    "        # max_pixel_value = 1.0 as the input is in range [-0.5, 0.5], making the amplitude/range of values to be 1.0 \n",
    "        assert len(image.shape) == 3 and len(target.shape) == 3\n",
    "        image = torch.clip(image, -0.5, 0.5).add(0.5)\n",
    "        target = torch.clip(target, -0.5, 0.5).add(0.5)\n",
    "        \n",
    "        mse = torch.clip(torch.mean((target - image)**2, dim=(-2, -1)), min=1e-8)\n",
    "        psnr = 10.0 * torch.log10(max_pixel_value**2 / mse)\n",
    "        return psnr\n",
    "    \n",
    "    def _augment_data(self, imgs, specs, augment_params):\n",
    "        '''\n",
    "        This function performs augmentation operations like translation.\n",
    "        \n",
    "        Args:\n",
    "            images (Tensor): Tensor of images to augment.\n",
    "            specs (Tensor: complex): Tensor of spectral representations of the images.\n",
    "            augment_params (dict()): Dictionary of augmentation parameters.\n",
    "        \n",
    "        Returns:\n",
    "            augmented_images (Tensor): Tensor of the augmented images.\n",
    "            augmented_spectrals (Tensor): Tensor of the spectral representations of the augmented images.\n",
    "        '''\n",
    "        t = augment_params.get('translate', 0)\n",
    "        if t <= 0:\n",
    "            return imgs, specs\n",
    "        else:\n",
    "            trans = torch.randint(-t, t + 1, size=(2, ))\n",
    "            cache_key = (int(trans[0].item()), int(trans[1].item()))\n",
    "            if cache_key not in self.augment_translate_cache:\n",
    "                # Create delta image with a shifted impulse\n",
    "                x = torch.zeros(imgs[0].shape, dtype=torch.float32)\n",
    "                y_idx = (trans[0].item() + imgs[0].shape[0]) % imgs[0].shape[0]\n",
    "                x_idx = (trans[1].item() + imgs[0].shape[1]) % imgs[0].shape[1]\n",
    "                x[y_idx, x_idx] = 1.0\n",
    "                kernel_spec = self._compute_spectral(x)\n",
    "                augment_translate_cache[cache_key] = kernel_spec\n",
    "                kernel_spec = kernel_spec.to(self.device)\n",
    "            else:\n",
    "                kernel_spec = augment_translate_cache[cache_key].to(self.device)\n",
    "            new_imgs = torch.roll(imgs, shifts=(cache_key[0], cache_key[1]), dims=(1, 2))\n",
    "            new_specs = specs * kernel_spec[None, :, :]\n",
    "            return new_imgs, new_specs\n",
    "    \n",
    "    def _inject_noise(self, imgs, specs, corruption_type: Optional[str]=\"\", **kwargs):\n",
    "        '''\n",
    "        Injects images with artificial noise values.\n",
    "        \n",
    "        Args:\n",
    "            images (Tensor): Source image tensor\n",
    "            specs (Tensor): Spectral representation of the input images.\n",
    "            corruption_type (str): Corruption type to add.\n",
    "            **kwargs: keyword arguments for respective corruption type.\n",
    "        \n",
    "        Returns:\n",
    "            corrupted_images (Tensor): Images after adding the noise values.\n",
    "            corrupted_spectrals (Tensor): The spectral representation of noisy images.\n",
    "            corruption_mask (Tensor: float): The mask used to inject noise.\n",
    "        '''\n",
    "        _, H, W = imgs.shape\n",
    "        unique_key_freq = 1\n",
    "        noise_injection_factor = kwargs.get(\"noise_injection_factor\", 1.0)\n",
    "        # Choose to corrupt or not, and choose the corruption type.\n",
    "        if corruption_type == \"\":\n",
    "            return imgs, specs, torch.ones_like(imgs)\n",
    "            \n",
    "        elif corruption_type == \"bspec\":\n",
    "            if \"p_edge\" not in kwargs[\"corruption_params\"]:\n",
    "                warnings.warn(\"Missing Parameter Warning: Using default values for - corruption_params:{\\\"p_edge\\\" = 0.025}\")\n",
    "            p_edge = kwargs[\"corruption_params\"].get(\"p_edge\", 0.025) * noise_injection_factor\n",
    "            \n",
    "            cache_key = (self.epoch%unique_key_freq, \"bernoulli\", p_edge)\n",
    "            if cache_key not in self.corruption_masks:\n",
    "                # Create a corruption mask\n",
    "                y = torch.arange(H, dtype=torch.float32, device=self.device) - H // 2\n",
    "                x = torch.arange(W, dtype=torch.float32, device=self.device) - W // 2\n",
    "                yy, xx = torch.meshgrid(y**2, x**2, indexing='ij')\n",
    "                r_dist = torch.sqrt(xx + yy)\n",
    "                prob_mask = (p_edge ** (2.0 / W)) ** r_dist\n",
    "                \n",
    "                keep = (torch.rand(size=(H, W), device=self.device, dtype=torch.float32) ** 2) < prob_mask\n",
    "                keep = keep & torch.flip(keep, dims=[0, 1])\n",
    "                \n",
    "                self.corruption_masks[cache_key] = (keep, prob_mask)\n",
    "                \n",
    "            else:    \n",
    "                keep, prob_mask = self.corruption_masks[cache_key]\n",
    "            \n",
    "            # Apply Mask\n",
    "            mskd_specs = specs * keep\n",
    "            spec_msk = keep.to(torch.float32)\n",
    "            new_specs = self._compute_spectral(mskd_specs / torch.where(keep, prob_mask, 1e-8), ifft=True)\n",
    "            new_imgs = torch.fft.ifft2(new_specs).real.float()\n",
    "            \n",
    "            spec_msk *= -1\n",
    "            \n",
    "            return new_imgs, new_specs, spec_msk\n",
    "\n",
    "        elif corruption_type == \"poisson\":\n",
    "            if \"poisson_strength\" not in kwargs[\"corruption_params\"]:\n",
    "                warnings.warn(\"Missing Parameter Warning: Using default values for - corruption_params:{\\\"poisson_strength\\\" = 0.102}\")\n",
    "            corruption_strength = kwargs[\"corruption_params\"].get(\"poisson_strength\", 0.102) * noise_injection_factor\n",
    "        \n",
    "            if \"distribution\" not in kwargs[\"corruption_params\"]:\n",
    "                warnings.warn(\"Missing Parameter Warning: Using default values for - corruption_params:{\\\"distribution\\\" = \\\"uniform\\\"}\")\n",
    "            distribution = kwargs[\"corruption_params\"].get(\"distribution\", \"uniform\")\n",
    "        \n",
    "            cache_key = (self.epoch % unique_key_freq, \"poisson_spectral\", corruption_strength, distribution)\n",
    "            if cache_key not in self.corruption_masks:\n",
    "                if distribution == \"uniform\":\n",
    "                    if \"mask_ratio\" not in kwargs[\"corruption_params\"]:\n",
    "                        warnings.warn(\"Missing Parameter Warning: Using default values for - corruption_params:{\\\"mask_ratio\\\" = 0.05}\")\n",
    "                    criterion = kwargs[\"corruption_params\"].get(\"mask_ratio\", 0.05)\n",
    "                elif distribution == \"gaussian\":\n",
    "                    if \"sigma\" not in kwargs[\"corruption_params\"]:\n",
    "                        raise ValueError(\"Missing 'sigma' in corruption_params.\")\n",
    "                    sigma = kwargs[\"corruption_params\"].get(\"poisson_sigma\", 1.0)\n",
    "                    y = torch.arange(H, dtype=torch.float32, device=self.device) - H // 2\n",
    "                    x = torch.arange(W, dtype=torch.float32, device=self.device) - W // 2\n",
    "                    yy, xx = torch.meshgrid(y, x, indexing=\"ij\")\n",
    "                    criterion = torch.exp(-(xx**2 + yy**2) / (2 * sigma**2))\n",
    "                else:\n",
    "                    criterion = 0.05\n",
    "        \n",
    "                mask = (torch.rand((H, W), device=self.device) < criterion).float()\n",
    "                self.corruption_masks[cache_key] = mask\n",
    "            else:\n",
    "                mask = self.corruption_masks[cache_key]\n",
    "        \n",
    "            # === Spectral Poisson Injection ===\n",
    "            specs_shifted = self._compute_spectral(imgs)\n",
    "            magnitude = torch.abs(specs_shifted)\n",
    "            phase = torch.angle(specs_shifted)\n",
    "        \n",
    "            noise = torch.poisson((magnitude + 1e-5) * corruption_strength) / corruption_strength\n",
    "            new_magnitude = torch.where(mask.bool(), noise, magnitude)\n",
    "        \n",
    "            # Reconstruct corrupted complex spectrum\n",
    "            new_specs = new_magnitude * torch.exp(1j * phase)\n",
    "        \n",
    "            # Enforce Hermitian symmetry\n",
    "            new_specs = self._compute_spectral(new_specs, ifft=True)\n",
    "            new_imgs = torch.fft.ifft2(new_specs).real.float()\n",
    "        \n",
    "            # Generate spectral-domain mask (normalized log-magnitude diff)\n",
    "            mask_spec = torch.log1p(torch.abs(magnitude - new_magnitude))\n",
    "            mask_spec = (mask_spec - mask_spec.min()) / torch.max((mask_spec.max() - mask_spec.min()), torch.tensor(1e-8, device=mask_spec.device))\n",
    "            mask_spec *= -1  # Consistent with your negative corruption convention\n",
    "            \n",
    "            return new_imgs, new_specs, mask_spec\n",
    "\n",
    "        elif corruption_type == \"gaussian\":\n",
    "            if \"gaussian_std\" not in kwargs[\"corruption_params\"]:\n",
    "                warnings.warn(\"Missing Parameter Warning: Using default values for - corruption_params:{\\\"Gaussian Standard Deviation\\\" = 0.1}\")\n",
    "            std = kwargs[\"corruption_params\"].get(\"gaussian_std\", 0.1) * noise_injection_factor\n",
    "        \n",
    "            cache_key = (self.epoch % unique_key_freq, \"gaussian_spectral\", std)\n",
    "            if cache_key not in self.corruption_masks:\n",
    "                mask = torch.normal(mean=0.0, std=std, size=imgs[0].shape, device=self.device)\n",
    "        \n",
    "                self.corruption_masks[cache_key] = mask\n",
    "            else:\n",
    "                mask = self.corruption_masks[cache_key]\n",
    "        \n",
    "            # === Spectral Gaussian Injection ===\n",
    "            specs_shifted = self._compute_spectral(imgs)\n",
    "            magnitude = torch.abs(specs_shifted)\n",
    "            phase = torch.angle(specs_shifted)\n",
    "        \n",
    "            # Add Gaussian noise to magnitude (keeping the phase intact)\n",
    "            noise = mask  # Using the pre-generated Gaussian mask for added noise\n",
    "            new_magnitude = magnitude + noise\n",
    "        \n",
    "            # Reconstruct the corrupted complex spectrum\n",
    "            new_specs = new_magnitude * torch.exp(1j * phase)\n",
    "        \n",
    "            # Enforce Hermitian symmetry\n",
    "            new_specs = self._compute_spectral(new_specs, ifft=True)\n",
    "            new_imgs = torch.fft.ifft2(new_specs).real.float()\n",
    "        \n",
    "            # Generate spectral-domain mask (log-magnitude diff)\n",
    "            mask_spec = torch.log1p(torch.abs(magnitude - new_magnitude))\n",
    "            mask_spec = (mask_spec - mask_spec.min()) / torch.max(mask_spec.max() - mask_spec.min(), torch.tensor(1e-8, device=mask_spec.device))\n",
    "            mask_spec *= -1  # Consistent with your negative corruption convention\n",
    "        \n",
    "            return new_imgs, new_specs, mask_spec\n",
    "\n",
    "        elif corruption_type == \"poisson0\":\n",
    "            if \"poisson_strength\" not in kwargs[\"corruption_params\"]:\n",
    "                warnings.warn(\"Missing Parameter Warning: Using default values for - corruption_params:{\\\"poisson_strength\\\" = 0.102}\")\n",
    "            corruption_strength = kwargs[\"corruption_params\"].get(\"poisson_strength\", 0.102) * noise_injection_factor\n",
    "            \n",
    "            if \"distribution\" not in kwargs[\"corruption_params\"]:\n",
    "                warnings.warn(\"Missing Parameter Warning: Using default values for - corruption_params:{\\\"distribution\\\" = \\\"uniform\\\"}\")\n",
    "            distribution = kwargs[\"corruption_params\"].get(\"distribution\", \"uniform\")\n",
    "\n",
    "            mask = None\n",
    "            cache_key = (self.epoch%unique_key_freq, \"poisson\", corruption_strength, distribution)\n",
    "            if cache_key not in self.corruption_masks:\n",
    "                # Create a corruption mask\n",
    "                if distribution == \"uniform\":\n",
    "                    if \"mask_ratio\" not in kwargs[\"corruption_params\"]:\n",
    "                        warnings.warn(\"Missing Parameter Warning: Using default values for - corruption_params:{\\\"mask_ratio\\\" = 0.05}\")\n",
    "                    criterion = kwargs[\"corruption_params\"].get(\"mask_ratio\", 0.05)\n",
    "                    \n",
    "                elif distribution == \"gaussian\":\n",
    "                    if \"sigma\" not in kwargs[\"corruption_params\"]:\n",
    "                        raise ValueError(\"Missing 'sigma' in corruption_params.\")\n",
    "                        \n",
    "                    sigma = kwargs[\"corruption_params\"].get(\"poisson_sigma\", 1.0)\n",
    "                    y = torch.arange(H, dtype=torch.float32, device=device) - H // 2\n",
    "                    x = torch.arange(W, dtype=torch.float32, device=device) - W // 2\n",
    "                    yy, xx = torch.meshgrid(y, x, indexing=\"ij\")\n",
    "                    criterion = torch.exp(-(xx**2 + yy**2) / (2 * sigma**2))\n",
    "                    \n",
    "                else:\n",
    "                    # Default to uniform distribution with mask_ratio = 0.05\n",
    "                    criterion = 0.05\n",
    "                    \n",
    "                mask = (torch.rand((H, W), device=self.device) < criterion).float()\n",
    "                self.corruption_masks[cache_key] = mask\n",
    "            else:\n",
    "                mask = self.corruption_masks[cache_key]\n",
    "            \n",
    "            poisson_noise = torch.poisson(torch.abs(imgs + 0.5) * corruption_strength) / corruption_strength - 0.5\n",
    "            batch_mask = mask.unsqueeze(0)\n",
    "            new_imgs = torch.where(batch_mask.bool(), poisson_noise, imgs)\n",
    "            new_specs = self._compute_spectral(new_imgs)\n",
    "            \n",
    "            mask = torch.log1p(self._compute_spectral(mask).abs())\n",
    "            mask = (mask - mask.min())/(mask.max() - mask.min())\n",
    "            mask *= -1\n",
    "            return new_imgs, new_specs, mask\n",
    "        \n",
    "        elif corruption_type == \"gaussian0\":\n",
    "            if \"gaussian_std\" not in kwargs[\"corruption_params\"]:\n",
    "                warnings.warn(\"Missing Parameter Warning: Using default values for - corruption_params:{\\\"Daussian Standard Deviation\\\" = 0.1}\")\n",
    "            std = kwargs[\"corruption_params\"].get(\"gaussian_std\", 0.1) * noise_injection_factor\n",
    "\n",
    "            cache_key = (self.epoch%unique_key_freq, \"gaussian\", std)\n",
    "            if cache_key not in self.corruption_masks:\n",
    "                mask = torch.normal(mean=0.0, std=std, size=imgs[0].shape, device=self.device)\n",
    "                \n",
    "            new_imgs = imgs + mask\n",
    "            new_specs = self._compute_spectral(new_imgs)\n",
    "            \n",
    "            mask = torch.log1p(self._compute_spectral(mask).abs())\n",
    "            mask = (mask - mask.min())/(mask.max() - mask.min())\n",
    "            mask *= -1\n",
    "            return new_imgs, new_specs, mask\n",
    "            \n",
    "        elif corruption_type == \"blur\":\n",
    "            if \"blur_kernel\" not in kwargs[\"corruption_params\"]:\n",
    "                warnings.warn(\"Missing Parameter Warning: Using default values for - corruption_params:{\\\"Blur Kernel\\\" = 15}\")\n",
    "            kernel = kwargs[\"corruption_params\"].get(\"blur_kernel\", 15)\n",
    "            \n",
    "            if \"blur_sigma\" not in kwargs[\"corruption_params\"]:\n",
    "                warnings.warn(\"Missing Parameter Warning: Using default values for - corruption_params:{\\\"Blur Sigma\\\" = 1.0}\")\n",
    "            sigma = kwargs[\"corruption_params\"].get(\"blur_sigma\", 1.0) * noise_injection_factor\n",
    "\n",
    "            \n",
    "            new_imgs = gaussian_blur(img=imgs, kernel_size=kernel, sigma=sigma)\n",
    "            \n",
    "            # cache_key = (self.epoch%unique_key_freq, \"blur\", kernel, sigma)\n",
    "            # if cache_key not in self.corruption_masks:\n",
    "            #     new_imgs = gaussian_blur(img=imgs, kernel_size=kernel, sigma=sigma)\n",
    "            #     mask = new_imgs[0] - imgs[0]\n",
    "            #     # print(mask.shape, imgs.shape, new_imgs.shape)\n",
    "            #     self.corruption_masks[cache_key] = mask\n",
    "            # else:\n",
    "            #     mask = self.corruption_masks[cache_key]\n",
    "            #     new_imgs = imgs + mask\n",
    "                \n",
    "            new_specs = self._compute_spectral(new_imgs)\n",
    "            \n",
    "            # mask = torch.log1p(self._compute_spectral(mask).abs())\n",
    "            # mask = (mask - mask.min())/(mask.max() - mask.min())\n",
    "            # mask *= -1\n",
    "            return new_imgs, new_specs, torch.zeros_like(new_imgs)\n",
    "            \n",
    "        elif corruption_type == \"mixed\":\n",
    "\n",
    "            # Apply Gaussian\n",
    "            gaussian_imgs, gaussian_specs, gaussian_mask = self._inject_noise(imgs, specs, corruption_type=\"gaussian\", corruption_params=kwargs[\"corruption_params\"])\n",
    "            # Apply Blur\n",
    "            #  blur_imgs, blur_specs, blur_mask = self._inject_noise(gaussian_imgs, gaussian_specs, corruption_type=\"blur\", corruption_params=kwargs[\"corruption_params\"])\n",
    "            # Apply Poisson\n",
    "            poisson_imgs, poisson_specs, poisson_mask = self._inject_noise(gaussian_imgs, gaussian_specs, corruption_type=\"poisson\", corruption_params=kwargs[\"corruption_params\"])\n",
    "            \n",
    "            # Apply bspec\n",
    "            # bspec_imgs, bspec_specs, bspec_mask= self._inject_noise(gaussian_imgs, gaussian_specs, corruption_type=\"bspec\", corruption_params=kwargs[\"corruption_params\"])\n",
    "            \n",
    "            corrupted_imgs, corrupted_specs = poisson_imgs, poisson_specs\n",
    "\n",
    "            # combi_mask = gaussian_mask + poisson_mask\n",
    "            # combi_mask = torch.log1p(self._compute_spectral(combi_mask).abs())\n",
    "            # combi_mask = (combi_mask - combi_mask.min())/(combi_mask.max() - combi_mask.min())\n",
    "            \n",
    "            # gaussian_mask = torch.log1p(self._compute_spectral(gaussian_mask).abs())\n",
    "            # gaussian_mask = (gaussian_mask - gaussian_mask.min())/(gaussian_mask.max() - gaussian_mask.min())\n",
    "\n",
    "            # poisson_mask = torch.log1p(self._compute_spectral(poisson_mask).abs())\n",
    "            # poisson_mask = (poisson_mask - poisson_mask.min())/(poisson_mask.max() - poisson_mask.min())\n",
    "\n",
    "            corrupted_mask = gaussian_mask + poisson_mask\n",
    "            return corrupted_imgs, corrupted_specs, corrupted_mask\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"Requested \\\"{corruption_type}\\\" which is an invalid corruption type!\")\n",
    "    \n",
    "    def _noise_injector(self, imgs, specs, corruption_type: Optional[List[str]]=None, **kwargs):\n",
    "        '''\n",
    "        This function sequentially injects noise to a tensor of images.\n",
    "\n",
    "        Args:\n",
    "            imgs (Tensor): Images to add noise to.\n",
    "            specs (Tensor): Spectral representation of the images.\n",
    "            corruption_type (List[str]): List of corruptions to add in sequence.\n",
    "            **kwargs: Keyword arguments for respective noise types.\n",
    "        \n",
    "        Returns:\n",
    "            corrupted_images (Tensor): Corrupted images.\n",
    "            corrupted_spectrals (Tensor): The spectral representation.\n",
    "            corruption_mask (Tensor): The effective corruption mask for the sequence of noise patterns.\n",
    "        '''\n",
    "        output_imgs, output_specs, output_masks = imgs, specs, torch.ones_like(imgs)\n",
    "        if corruption_type:\n",
    "            for corruption in corruption_type:\n",
    "                output_imgs, output_specs, masks = self._inject_noise(output_imgs, output_specs, corruption_type=corruption, **kwargs)\n",
    "                output_masks += masks\n",
    "        \n",
    "        return output_imgs, output_specs, output_masks\n",
    "    \n",
    "    def _preprocessbatch(self, imgs, specs, noisy_targets=True, inject_noise=True, **kwargs):\n",
    "        '''\n",
    "        This function performs preprocessing on a batch of images.\n",
    "\n",
    "        Args:\n",
    "            imgs (Tensor): Batch of images to process.\n",
    "            specs (Tensor): Spectral representation of images.\n",
    "            noisy_targets (bool): Boolean to select noisy or clean targets.\n",
    "            inject_noise (bool): Boolean to add noise to images or not.\n",
    "            **kwargs: keyword arguments for respective processes.\n",
    "        \n",
    "        Returns:\n",
    "            processed_images (Tensor): Images after processing.\n",
    "            processed_targets (Tensor): Targets for training.\n",
    "            processed_spectrals (Tensor): The spectral representation.\n",
    "            corruption_mask (Tensor: float): The effective mask used for injecting noise values.\n",
    "            original_images (Tensor): Original images before any preprocessing.\n",
    "        '''\n",
    "        augmented_imgs, augmented_specs = self._augment_data(imgs, specs, augment_params=kwargs.get(\"augment_params\", dict()))\n",
    "        if inject_noise:\n",
    "            new_imgs, new_specs, corruption_mask = self._noise_injector(augmented_imgs, augmented_specs, corruption_type=kwargs.get(\"corruption_type\", None), corruption_params=kwargs.get(\"corruption_params\"))\n",
    "        else:\n",
    "            new_imgs, new_specs, corruption_mask = augmented_imgs, augmented_specs, []\n",
    "        \n",
    "        if noisy_targets:\n",
    "            targets, _, _ = self._noise_injector(augmented_imgs, augmented_specs, corruption_type=kwargs.get(\"corruption_type\", None), corruption_params=kwargs.get(\"corruption_params\"), noise_injection_factor=self.target_noise_injection_factor)\n",
    "        else:\n",
    "            targets = augmented_imgs\n",
    "\n",
    "        return new_imgs, targets, new_specs, corruption_mask, imgs\n",
    "    \n",
    "    def _save_config(self, **kwargs):\n",
    "        '''\n",
    "        This function saves the parameters and hyperparameters used for the current run of the experiment to 'run-config.txt'.\n",
    "        '''\n",
    "        logger = self.Logger(str(self.results_dir / \"run-config.txt\"))\n",
    "        kwargs = {**self.init_kwargs, **kwargs}\n",
    "        config = {\n",
    "            'loss': str(self.loss_fn),\n",
    "            'learning_rate': self.optimizer.param_groups[0]['lr'],\n",
    "            'post_op': self.post_op,\n",
    "            'max_epochs': self.max_epochs,\n",
    "            'start_epoch': self.start_epoch,\n",
    "            'results_dir': str(self.results_dir),\n",
    "            'corrupt_targets': kwargs.get(\"n2n\", True),\n",
    "            'batch_size': self.batch_size,\n",
    "            'checkpoint_save_interval': self.save_interval,\n",
    "            'augmentation_params': kwargs.get(\"augment_params\", dict()),\n",
    "            'corruption_type': kwargs.get(\"corruption_type\", None),\n",
    "            'noisy_target_factor': self.target_noise_injection_factor, \n",
    "            'corruption_params': kwargs.get(\"corruption_params\", dict())\n",
    "        }\n",
    "        \n",
    "        logger.start()\n",
    "        print(\"############ Config #############\")\n",
    "        print(json.dumps({'config': config}, indent=4))\n",
    "        print(\"#################################\")\n",
    "        logger.stop()\n",
    "\n",
    "    def _train_phase(self, train_loss=0.0, train_n=0.0, inject_noise=True, **kwargs):\n",
    "        '''\n",
    "        This function executes the training phase of the training epoch.\n",
    "\n",
    "        Args:\n",
    "            train_loss (float): Average training loss from the previous epoch.\n",
    "            train_n (float): Number of image samples in the previous batch.\n",
    "            inject_noise (bool): Boolean for corrupting images.\n",
    "        \n",
    "        Returns:\n",
    "            train_loss (float): Average training loss from the current epoch.\n",
    "            train_n (float): Number of image samples in the batch.\n",
    "        '''\n",
    "        # Do Data Minibatching \n",
    "        for idx, batch in tqdm(enumerate(self.train_loader), desc=\"Training Batch\", total=len(self.train_loader), position=0, leave=True):\n",
    "            imgs, specs = batch\n",
    "            imgs, specs = imgs.to(self.device), specs.to(self.device)\n",
    "            \n",
    "            inps, targs, _, spec_mask, _= self._preprocessbatch(imgs, specs,\n",
    "                                                                noisy_targets=kwargs.get(\"n2n\", True), \n",
    "                                                                inject_noise=inject_noise, \n",
    "                                                                **kwargs)\n",
    "            \n",
    "            outputs = self.model(inps)\n",
    "\n",
    "            if self.post_op:\n",
    "                outputs = self._post_op(self.post_op, outputs, specs, spec_mask)\n",
    "            \n",
    "            loss = self.loss_fn(outputs, targs)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "    \n",
    "            train_loss += loss.item() * inps.size(0)\n",
    "            train_n += inps.size(0)\n",
    "        \n",
    "        train_loss = (train_loss / train_n) if train_n > 0 else 0.0\n",
    "        return train_loss, train_n\n",
    "    \n",
    "    def _valid_phase(self, valid_loss=0.0, valid_n=0.0, inject_noise=True, **kwargs):\n",
    "        '''\n",
    "        This function executes the Validation phase of the training epoch.\n",
    "\n",
    "        Args:\n",
    "            valid_loss (float): Average training loss from the previous epoch.\n",
    "            valid_n (float): Number of image samples in the previous batch.\n",
    "            inject_noise (bool): Boolean for corrupting images.\n",
    "        \n",
    "        Returns:\n",
    "            valid_loss (float): Average training loss from the current epoch.\n",
    "            valid_n (float): Number of image samples in the batch.\n",
    "            average_psnr (float): Average PSNR score of the batch.\n",
    "        '''\n",
    "        # Validation Process\n",
    "        self.model.eval()\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            for idx, batch in tqdm(enumerate(self.valid_loader), desc=\"Validation Batch\", total=len(self.valid_loader), leave=True):\n",
    "                # inps, targs, _, _, origs = batch\n",
    "                # inps, targs, origs = inps.to(self.device), targs.to(self.device), origs.to(self.device)\n",
    "                imgs, specs = batch\n",
    "                imgs, specs = imgs.to(self.device), specs.to(self.device)\n",
    "                inps, targs, _, _, origs = self._preprocessbatch(imgs, specs, \n",
    "                                                                 noisy_targets=False, \n",
    "                                                                 inject_noise=inject_noise, \n",
    "                                                                 **kwargs)\n",
    "                \n",
    "                outputs = self.model(inps)\n",
    "\n",
    "                # if self.post_op == 'fspec':\n",
    "                #     outputs = self._post_op(outputs, specs, spec_mask)\n",
    "                \n",
    "                loss = self.loss_fn(outputs, targs)\n",
    "    \n",
    "                valid_loss += loss.item() * inps.size(0)\n",
    "                valid_n += inps.size(0)\n",
    "\n",
    "                # Calculate PSNR scores\n",
    "                avg_psnr = torch.mean(self._psnr_scores(outputs, targs))\n",
    "                \n",
    "                if idx == 0:\n",
    "                    # 4-in-1 image + spectrum\n",
    "                    assert inps.shape[0] >= 7, \"Batch size too small. Minimum permitted size = 7\"\n",
    "                    prim = [x.squeeze(0) for x in [origs[6], inps[6], outputs[6], targs[6]]]\n",
    "                    spec = [v for _, v in (self._compute_spectral(x, magnitude=True, normalize=False) for x in prim)]\n",
    "                    pimg = torch.cat(prim, dim=1).add(0.5)\n",
    "                    simg = torch.cat(spec, dim=1).mul(0.05)\n",
    "                    img = torch.cat([pimg, simg], dim=0)\n",
    "\n",
    "                    # Saving the Outputs.\n",
    "                    save_image(img, self.training_test_path / f\"img{self.epoch:03d}.png\", normalize=False)\n",
    "                    \n",
    "        valid_loss = (valid_loss / valid_n) if valid_n > 0 else 0.0\n",
    "        return valid_loss, valid_n, avg_psnr.item()\n",
    "    \n",
    "    def _final_epoch(self, inject_noise=True, **kwargs):\n",
    "        '''\n",
    "        This function executes the Final Epoch phase of the training epoch.\n",
    "        '''\n",
    "        print(\"Final Epoch: \\n\")\n",
    "        # Do a full Validation set testing with result saving.\n",
    "        loader = DataLoader(Subset(self.valid_data, indices=range(10)), batch_size=1, shuffle=False, pin_memory=True, pin_memory_device=\"cuda\")\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.inference_mode():\n",
    "            psnr_file = self.validation_test_path / \"PSNR.txt\"\n",
    "            with psnr_file.open('wt') as fout:\n",
    "                fout.write(f'Sr.no.:\\tOriginal\\tInput\\t\\tOutput\\t\\tGains\\n' +\n",
    "                           '-'*70 + '\\n')\n",
    "                for idx, batch in tqdm(enumerate(loader), desc=\"Validation Testing\", total=len(loader), leave=True):\n",
    "                    imgs, specs = batch\n",
    "                    imgs, specs = imgs.to(self.device), specs.to(self.device)\n",
    "                    inp, targ, _, _, orig = self._preprocessbatch(imgs, specs,\n",
    "                                                                 noisy_targets=False,\n",
    "                                                                 inject_noise=inject_noise,\n",
    "                                                                 **kwargs)\n",
    "                    denoised_op = self.model(inp)\n",
    "                    \n",
    "                    # 4-in-1 image + spectrum\n",
    "                    prim = [x.squeeze(0) for x in [orig, inp, denoised_op, targ]]\n",
    "                    spec = [v for _, v in (self._compute_spectral(x, magnitude=True, normalize=False) for x in prim)]\n",
    "                    pimg = torch.cat(prim, dim=1).add(0.5)\n",
    "                    simg = torch.cat(spec, dim=1).mul(0.05)\n",
    "                    img = torch.cat([pimg, simg], dim=0)\n",
    "\n",
    "                    # Saving the Outputs.\n",
    "                    save_image(img, self.validation_test_path / f\"final{idx:03d}.png\", normalize=False)\n",
    "                    # save_image((torch.clip(orig, -0.5, 0.5) + 0.5).cpu(), self.validation_test_path / f\"original{idx:03d}.png\")\n",
    "                    save_image((torch.clip(denoised_op, -0.5, 0.5).add(0.5)).cpu(), self.validation_test_path / f\"output{idx:03d}.png\")\n",
    "                    save_image((torch.clip(targ, -0.5, 0.5).add(0.5)).cpu(), self.validation_test_path / f\"target{idx:03d}.png\")\n",
    "                    save_image((torch.clip(inp, -0.5, 0.5).add(0.5)).cpu(), self.validation_test_path / f\"input{idx:03d}.png\")\n",
    "                    \n",
    "                    # PSNR Scores\n",
    "                    orig_vs_targ = self._psnr_scores(imgs, targ).item()\n",
    "                    op_vs_targ = self._psnr_scores(denoised_op, targ).item()\n",
    "                    inp_vs_targ = self._psnr_scores(inp, targ).item()\n",
    "                    \n",
    "                    fout.write(f'{idx:02d}:\\t{orig_vs_targ:0.5f}\\t{inp_vs_targ:0.5f}\\t{op_vs_targ:0.5f}\\t{(op_vs_targ - orig_vs_targ):0.5f}\\n')\n",
    "    \n",
    "    def _generate_example(self, inject_noise=True, **kwargs):\n",
    "        '''\n",
    "        This function generates an example sample pair of the noisy input and target images for the active training experiment.\n",
    "        It also saves a labeled and an unlabeled versions of the sample for the report.\n",
    "        \n",
    "        Args:\n",
    "            inject_noise (bool) : Boolean to inject noise onto images.\n",
    "            **kwargs: Keyword arguments for respective noise types.\n",
    "        \n",
    "        Returns:\n",
    "            corrupted_image (Tensor): Sample of the corrupted image.\n",
    "        '''\n",
    "        # Save image sample\n",
    "        imgs, specs = next(iter(self.train_loader))\n",
    "        assert imgs.shape[0] >= 10, \"Batch size too small. Minimum permitted size = 10\"\n",
    "        imgs, specs = torch.narrow(imgs, 0, 9, 1), torch.narrow(specs, 0, 9, 1)\n",
    "        imgs, specs = imgs.to(self.device), specs.to(self.device)\n",
    "        dummy_ip, t, s, s_m, o= self._preprocessbatch(imgs, specs, \n",
    "                                                     noisy_targets=kwargs.get(\"n2n\", True), \n",
    "                                                     inject_noise=inject_noise, \n",
    "                                                     **kwargs)\n",
    "\n",
    "        prim = [x.squeeze(0) for x in [dummy_ip, t]]\n",
    "        spec = [v for _, v in (self._compute_spectral(x, magnitude=True, normalize=False) for x in prim)]\n",
    "        pimg = torch.cat(prim, dim=1).add(0.5)\n",
    "        simg = torch.cat(spec, dim=1).mul(0.05)\n",
    "        img = torch.cat([pimg, simg], dim=0)\n",
    "        save_image(img.cpu(), self.results_dir / \"2x2_example.png\", normalize=False)\n",
    "\n",
    "        imgs = [np.clip(x.squeeze(0).add(0.5).cpu().numpy().astype(np.float32), 0.0, 1.0) for x in prim]\n",
    "        specs = [np.clip(x.squeeze(0).mul(0.05).cpu().numpy().astype(np.float32), 0.0, 1.0) for x in spec]\n",
    "        fig, axes = plt.subplots(2, 2)\n",
    "\n",
    "        # Titles for columns\n",
    "        axes[0, 0].set_title(\"Noisy\", fontsize=12)\n",
    "        axes[0, 1].set_title(\"Target\", fontsize=12)\n",
    "        \n",
    "        # Plot images\n",
    "        axes[0, 0].imshow(imgs[0], cmap='gray')\n",
    "        axes[0, 1].imshow(imgs[1], cmap='gray')\n",
    "        axes[1, 0].imshow(specs[0], cmap='gray')\n",
    "        axes[1, 1].imshow(specs[1], cmap='gray')\n",
    "        \n",
    "        # Clean up axes\n",
    "        for ax in axes.ravel():\n",
    "            ax.axis('off')\n",
    "\n",
    "        # Add row labels using fig.text\n",
    "        fig.text(0.08, 0.75, \"Spatial\", va='center', ha='left', fontsize=12, rotation='vertical')\n",
    "        fig.text(0.08, 0.28, \"Spectral\", va='center', ha='left', fontsize=12, rotation='vertical')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.results_dir / \"2x2_example_labled.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        return dummy_ip\n",
    "    \n",
    "    def train(self, inject_noise=True, **kwargs):\n",
    "        '''\n",
    "        This function implements the training loop.\n",
    "        \n",
    "        Args:\n",
    "            inject_noise (bool): Boolean for corrupting images.\n",
    "        '''\n",
    "        # Save config\n",
    "        self._save_config(**kwargs)\n",
    "        \n",
    "        # Start Logging\n",
    "        self.logger.start()\n",
    "        \n",
    "        print(\"Training Started...\")\n",
    "        print(f\"Total Epochs: {self.max_epochs} \\nBatch Size: {self.train_loader.batch_size} \\nInitial Learning Rate: {self.optimizer.param_groups[0]['lr']}\\n\")\n",
    "\n",
    "        # Generate a sample of training input-target pairs.\n",
    "        dummy_ip = self._generate_example(**kwargs)\n",
    "        \n",
    "        # Add Model graph to the Tensorboard.\n",
    "        self.writer.add_graph(model=self.model, input_to_model=dummy_ip.to(self.device), verbose=False)\n",
    "\n",
    "        # Clock Training start time.\n",
    "        train_start_time = time.time()\n",
    "\n",
    "        # Training Loop\n",
    "        for epoch in range(self.start_epoch, self.max_epochs):\n",
    "            self.epoch = epoch\n",
    "            # Clocking Epoch start time\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Training Phase\n",
    "            train_loss, train_n = self._train_phase(**kwargs)\n",
    "            \n",
    "            # Validation Phase\n",
    "            valid_loss, valid_n, avg_psnr = self._valid_phase(**kwargs)\n",
    "\n",
    "            # Update LR Scheduler step\n",
    "            self.scheduler.step()\n",
    "\n",
    "            # Calculating time elapsed for the current epoch.\n",
    "            epoch_time = time.time() - start_time\n",
    "            # Update Tensorboard Summary\n",
    "            self.writer.add_scalar(\"Training/Loss\", train_loss, global_step=epoch, new_style=True)\n",
    "            self.writer.add_scalar(\"Validation/Loss\", valid_loss, global_step=epoch, new_style=True)\n",
    "            self.writer.add_scalar(\"Validation/Average_PSNR\", avg_psnr, global_step=epoch, new_style=True)\n",
    "            self.writer.add_scalar(\"Learning_rate\", self.optimizer.param_groups[0][\"lr\"], global_step=epoch, new_style=True)\n",
    "            self.writer.add_scalar(\"Training/time-per-epoch\", epoch_time, global_step=epoch, new_style=True)\n",
    "            print(f'[{self.device}]Epoch [{epoch+1}/{self.max_epochs}] | Time: {epoch_time: 0.2f} | Train Loss: {train_loss: 0.6f} | Validation Loss: {valid_loss: 0.6f} | Avg. PSNR: {avg_psnr: 0.6f} | Learning Rate: {self.optimizer.param_groups[0][\"lr\"]: 0.10f}')\n",
    "            \n",
    "             # Final Epoch\n",
    "            if epoch == self.max_epochs-1:\n",
    "                # Last Epoch Phase\n",
    "                self.final_epoch = True\n",
    "                self._final_epoch(**kwargs)\n",
    "\n",
    "            # Save Snapshot\n",
    "            if (epoch%self.save_interval == self.save_interval-1 or self.final_epoch) and self.device == 0:\n",
    "                self._save_snapshot()\n",
    "        \n",
    "        # Close the Tensorboard Summary Writer\n",
    "        self.writer.close()\n",
    "        \n",
    "        # Calculate the Elapsed Time for the Training Loop\n",
    "        total_seconds = time.time() - train_start_time\n",
    "        print(f\"Time Elapsed: {int(total_seconds // 3600)}hrs : {int((total_seconds % 3600) // 60)}mins : {int(total_seconds % 60)}secs.\" )\n",
    "        \n",
    "        # Stop with the logging\n",
    "        self.logger.stop()\n",
    "    \n",
    "    def _setup_training(self):\n",
    "        # Dataset exists\n",
    "        if not hasattr(self, 'train_data') or not hasattr(self, 'valid_data'):\n",
    "            raise ValueError(\"Training or validation data not loaded!\")\n",
    "        \n",
    "        self.train_loader = DataLoader(self.train_data, batch_size=self.batch_size, shuffle=True, pin_memory=True, pin_memory_device=\"cuda\")\n",
    "        self.valid_loader = DataLoader(self.valid_data, batch_size=self.batch_size, shuffle=False, pin_memory=True, pin_memory_device=\"cuda\")\n",
    "        \n",
    "        # Set Seed for reproducibility.\n",
    "        torch.manual_seed(42)\n",
    "        torch.cuda.manual_seed(42)\n",
    "        # print(train_batch[0].shape)\n",
    "        \n",
    "        # Define starting conditions\n",
    "        # Fresh start from 0 or load snapshot\n",
    "        if self.load_checkpoint:\n",
    "            # self._load_snapshot()\n",
    "            # Update the snapshot dir for the active run\n",
    "            self.snapshot_path = self.results_dir / \"Snapshots\"\n",
    "            self.snapshot_name = \"\"\n",
    "        else:\n",
    "            self.epoch = 0\n",
    "            self.start_epoch = 0\n",
    "    \n",
    "    def eval(self, data_loader: DataLoader, output_dir: Path = Path(\"\"), inject_noise=False, **kwargs):\n",
    "\n",
    "        def save_labeled_image(img, spec, img_idx):\n",
    "            # Preprocess the values for matplotlib.\n",
    "            imgs = [torch.clip(x.add(0.5), 0.0, 1.0).cpu().numpy().astype(np.float32) for x in img]\n",
    "            specs = [torch.clip(x.mul(0.05), 0.0, 1.0).cpu().numpy().astype(np.float32) for x in spec]\n",
    "            \n",
    "            fig, axes = plt.subplots(2, 4, figsize=(22, 11), gridspec_kw={'left': 0.04, 'right': 0.97, 'top': 0.97, 'bottom': 0.03, 'wspace': 0.01, 'hspace': 0.01})\n",
    "            \n",
    "            # Clean up axes\n",
    "            for ax in axes.ravel():\n",
    "                ax.axis('off')\n",
    "            \n",
    "            # fig.subplots_adjust(0.04, 0.03, 0.03, 0.03, hspace=0.01, wspace=0.01)\n",
    "            \n",
    "            # Titles for columns\n",
    "            axes[0, 0].set_title(\"Original\", fontsize=12)\n",
    "            axes[0, 1].set_title(\"Noisy Input\", fontsize=12)\n",
    "            axes[0, 2].set_title(\"Output\", fontsize=12)\n",
    "            axes[0, 3].set_title(\"Target\", fontsize=12)\n",
    "            \n",
    "            # Plot Original\n",
    "            axes[0, 0].imshow(imgs[0], cmap='gray')\n",
    "            axes[1, 0].imshow(specs[0], cmap='inferno')\n",
    "            # Plot Noisy Input\n",
    "            axes[0, 1].imshow(imgs[1], cmap='gray')\n",
    "            axes[1, 1].imshow(specs[1], cmap='inferno')\n",
    "            # Plot Output\n",
    "            axes[0, 2].imshow(imgs[2], cmap='gray')\n",
    "            axes[1, 2].imshow(specs[2], cmap='inferno')\n",
    "            # Plot Target\n",
    "            axes[0, 3].imshow(imgs[3], cmap='gray')\n",
    "            axes[1, 3].imshow(specs[3], cmap='inferno')\n",
    "\n",
    "            \n",
    "    \n",
    "            # Add row labels using fig.text\n",
    "            fig.text(0.01, 0.75, \"Spatial\", va='center', ha='left', fontsize=12, rotation='vertical')\n",
    "            fig.text(0.01, 0.28, \"Spectral\", va='center', ha='left', fontsize=12, rotation='vertical')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(output_dir / f\"final_labeled{img_idx:03d}.png\", dpi=300, bbox_inches='tight')\n",
    "            # plt.show()\n",
    "            \n",
    "        patch_size = kwargs.get(\"patch_size\", 255)\n",
    "        original_img_size = kwargs.get(\"image_size\", 2570)\n",
    "        overlap = kwargs.get(\"overlap\", 0.5)\n",
    "        step = int(patch_size * (1 - overlap))\n",
    "    \n",
    "        if str(output_dir) == '.':\n",
    "            output_dir = self.evaluation_test_path\n",
    "        else:\n",
    "            output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "        def blank():\n",
    "            return torch.zeros((1, original_img_size, original_img_size), dtype=torch.float32, device=self.device)\n",
    "        \n",
    "        # Buffers for reconstruction\n",
    "        original_reconst = blank()\n",
    "        denoised_reconst = blank()\n",
    "        target_reconst = blank()\n",
    "        input_reconst = blank()\n",
    "        mod_count = blank()\n",
    "    \n",
    "        # Generate patch positions exactly like extract_patches()\n",
    "        coords = []\n",
    "        h = w = original_img_size\n",
    "        for i in range(0, h - patch_size + 1, step):\n",
    "            for j in range(0, w - patch_size + 1, step):\n",
    "                coords.append((i, j))\n",
    "            if (w - patch_size) % step != 0:\n",
    "                j = w - patch_size\n",
    "                coords.append((i, j))\n",
    "                \n",
    "        if (h - patch_size) % step != 0:\n",
    "            i = h - patch_size\n",
    "            for j in range(0, w - patch_size + 1, step):\n",
    "                coords.append((i, j))\n",
    "            if (w - patch_size) % step != 0:\n",
    "                j = w - patch_size\n",
    "                coords.append((i, j))\n",
    "                \n",
    "        n_patches = len(coords)\n",
    "        \n",
    "        patch_idx = 0\n",
    "        img_idx = 1\n",
    "        \n",
    "        self.model.eval()\n",
    "    \n",
    "        with torch.inference_mode():\n",
    "            psnr_file = output_dir / \"PSNR.txt\"\n",
    "            with psnr_file.open('wt') as fout:\n",
    "                fout.write(f'Sr.no.:\\tOriginal\\tInput\\t\\tOutput\\t\\tGains\\t\\tNIQE\\n' +\n",
    "                           '-'*80 + '\\n')\n",
    "    \n",
    "                for _, batch in tqdm(enumerate(data_loader), desc=\"Evaluation Dataset\", total=len(data_loader), position=0, leave=True):\n",
    "                    imgs, specs = batch\n",
    "                    imgs, specs = imgs.to(self.device), specs.to(self.device)\n",
    "    \n",
    "                    inp, targ, _, _, orig = self._preprocessbatch(imgs, specs, \n",
    "                                                                  noisy_targets=False, \n",
    "                                                                  inject_noise=inject_noise, \n",
    "                                                                  **kwargs)\n",
    "                    # Predict\n",
    "                    denoised_op = self.model(inp)\n",
    "                    r, c = coords[patch_idx]\n",
    "                    original_reconst[:, r:r+patch_size, c:c+patch_size] += orig\n",
    "                    denoised_reconst[:, r:r+patch_size, c:c+patch_size] += denoised_op\n",
    "                    target_reconst[:, r:r+patch_size, c:c+patch_size] += targ\n",
    "                    input_reconst[:, r:r+patch_size, c:c+patch_size] += inp\n",
    "                    mod_count[:, r:r+patch_size, c:c+patch_size] += 1\n",
    "                    patch_idx += 1\n",
    "    \n",
    "                    if patch_idx == n_patches:\n",
    "                        # Normalize\n",
    "                        mod_count[mod_count == 0] = 1\n",
    "                        original_reconst /= mod_count\n",
    "                        denoised_reconst /= mod_count\n",
    "                        target_reconst /= mod_count\n",
    "                        input_reconst /= mod_count\n",
    "    \n",
    "                        # Generate images\n",
    "                        prim = [x.squeeze(0) for x in [original_reconst, input_reconst, denoised_reconst, target_reconst]]\n",
    "                        spec = [v for _, v in (self._compute_spectral(x, magnitude=True, normalize=False) for x in prim)]\n",
    "    \n",
    "                        pimg = torch.cat(prim, dim=1).add(0.5)\n",
    "                        simg = torch.cat(spec, dim=1).mul(0.05)\n",
    "                        img = torch.cat([pimg, simg], dim=0)\n",
    "    \n",
    "                        # Save\n",
    "                        save_image(img, output_dir / f\"final{img_idx:03d}.png\", normalize=False)\n",
    "                        save_image((torch.clip(original_reconst, -0.5, 0.5) + 0.5).cpu(), output_dir / f\"original{img_idx:03d}.png\")\n",
    "                        save_image((torch.clip(denoised_reconst, -0.5, 0.5) + 0.5).cpu(), output_dir / f\"output{img_idx:03d}.png\")\n",
    "                        save_image((torch.clip(target_reconst, -0.5, 0.5) + 0.5).cpu(), output_dir / f\"target{img_idx:03d}.png\")\n",
    "                        save_image((torch.clip(input_reconst, -0.5, 0.5) + 0.5).cpu(), output_dir / f\"input{img_idx:03d}.png\")\n",
    "\n",
    "                        # Saved a labled version.\n",
    "                        save_labeled_image(prim, spec, img_idx)\n",
    "    \n",
    "                        # Metrics\n",
    "                        psnr_orig_vs_targ = self._psnr_scores(original_reconst, target_reconst).item()\n",
    "                        psnr_denoise_vs_targ = self._psnr_scores(denoised_reconst, target_reconst).item()\n",
    "                        psnr_input_vs_targ = self._psnr_scores(input_reconst, target_reconst).item()\n",
    "                        niqe_score = float(\"inf\")  # placeholder\n",
    "                        fout.write(f'{img_idx:03d}:\\t{psnr_orig_vs_targ:0.5f}\\t{psnr_input_vs_targ:0.5f}\\t{psnr_denoise_vs_targ:0.5f}\\t{(psnr_denoise_vs_targ - psnr_orig_vs_targ):0.5f}\\t{niqe_score}\\n')\n",
    "    \n",
    "                        # Reset\n",
    "                        for buf in [original_reconst, denoised_reconst, target_reconst, input_reconst, mod_count]:\n",
    "                            buf.zero_()\n",
    "                        patch_idx = 0\n",
    "                        img_idx += 1\n",
    "    \n",
    "    def _train(self, **kwargs):\n",
    "        self._save_config(**kwargs)\n",
    "\n",
    "        self.logger.start()\n",
    "        \n",
    "        inject_noise = True\n",
    "        noisy_targets = kwargs.get(\"n2n\", True)\n",
    "        \n",
    "        print(\"Training Started...\")\n",
    "        print(f\"Total Epochs: {self.max_epochs} \\nBatch Size: {self.train_loader.batch_size} \\nInitial Learning Rate: {optimizer.param_groups[0]['lr']}\\n\")\n",
    "        # Setup Tensorboard Summary\n",
    "        # dummy_ip, _, _, _, _ = next(iter(self.train_loader))\n",
    "        imgs, specs = next(iter(self.train_loader))\n",
    "        imgs, specs = imgs.to(self.device), specs.to(self.device)\n",
    "        dummy_ip, t, s, s_m, o= self._preprocessbatch(imgs, specs, \n",
    "                                                     noisy_targets=noisy_targets, \n",
    "                                                     inject_noise=inject_noise, \n",
    "                                                     **kwargs)\n",
    "\n",
    "        save_image((torch.clip(dummy_ip[9], -0.5, 0.5) + 0.5).cpu(), self.results_dir / f\"example.png\")\n",
    "        # save_image((torch.clip(t[9], -0.5, 0.5) + 0.5).cpu(), self.validation_test_path / f\"t{0}.png\")\n",
    "        # save_image((torch.clip(o[9], -0.5, 0.5) + 0.5).cpu(), self.validation_test_path / f\"o{0}.png\")\n",
    "        \n",
    "        self.writer.add_graph(model=self.model, input_to_model=dummy_ip.to(self.device), verbose=False)\n",
    "        train_start_time = time.time()\n",
    "        for epoch in range(self.start_epoch, self.max_epochs):\n",
    "            self.epoch = epoch\n",
    "            \n",
    "            # Training Process\n",
    "            self.model.train()\n",
    "            if epoch == self.max_epochs-1:\n",
    "                print(f\"Final Epoch\")\n",
    "                self.final_epoch = True\n",
    "            else:\n",
    "                self.final_epoch = False\n",
    "            \n",
    "            start_time = time.time()\n",
    "            train_loss, train_n = 0.0, 0.0\n",
    "\n",
    "            # Do Data Minibatching \n",
    "            for idx, batch in tqdm(enumerate(self.train_loader), desc=\"Training Batch\", total=len(self.train_loader), position=0, leave=True):\n",
    "                # inps, targs, _, _, _ = batch\n",
    "                # inps, targs = imgs.to(self.device), targs.to(self.device)\n",
    "                imgs, specs = batch\n",
    "                imgs, specs = imgs.to(self.device), specs.to(self.device)\n",
    "                # params will be passed instead of hardcoded.\n",
    "                inps, targs, _, spec_mask, _= self._preprocessbatch(imgs, specs,\n",
    "                                                                    noisy_targets=noisy_targets, \n",
    "                                                                    inject_noise=inject_noise, \n",
    "                                                                    **kwargs)\n",
    "                \n",
    "                outputs = self.model(inps)\n",
    "\n",
    "                if self.post_op:\n",
    "                    outputs = self._post_op(self.post_op, outputs, specs, spec_mask)\n",
    "                \n",
    "                loss = self.loss_fn(outputs, targs)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "        \n",
    "                train_loss += loss.item() * inps.size(0)\n",
    "                train_n += inps.size(0)\n",
    "            \n",
    "            train_loss = (train_loss / train_n) if train_n > 0 else 0.0\n",
    "\n",
    "            # Validation Process\n",
    "            self.model.eval()\n",
    "            valid_loss, valid_n = 0.0, 0.0\n",
    "            \n",
    "            with torch.inference_mode():\n",
    "                for idx, batch in tqdm(enumerate(self.valid_loader), desc=\"Validation Batch\", total=len(self.valid_loader), leave=True):\n",
    "                    # inps, targs, _, _, origs = batch\n",
    "                    # inps, targs, origs = inps.to(self.device), targs.to(self.device), origs.to(self.device)\n",
    "                    imgs, specs = batch\n",
    "                    imgs, specs = imgs.to(self.device), specs.to(self.device)\n",
    "                    inps, targs, _, _, origs = self._preprocessbatch(imgs, specs, \n",
    "                                                                     noisy_targets=False, \n",
    "                                                                     inject_noise=inject_noise, \n",
    "                                                                     **kwargs)\n",
    "                    \n",
    "                    outputs = self.model(inps)\n",
    "\n",
    "                    # if self.post_op == 'fspec':\n",
    "                    #     outputs = self._post_op(outputs, specs, spec_mask)\n",
    "                    \n",
    "                    loss = self.loss_fn(outputs, targs)\n",
    "        \n",
    "                    valid_loss += loss.item() * inps.size(0)\n",
    "                    valid_n += inps.size(0)\n",
    "\n",
    "                    # Calculate PSNR scores\n",
    "                    avg_psnr = torch.mean(self._psnr_scores(outputs, targs))\n",
    "                    \n",
    "                    if idx == 0:\n",
    "                        \"\"\"\n",
    "                        # Save 4-in-1 Image\n",
    "                        # prim = [x.squeeze(0).detach().cpu().numpy() for x in [val_origs[0], val_imgs[0], outputs[0], val_targs[0]]]\n",
    "                        # spec = [v for _, v in (compute_spectral_image(x, magnitude=True) for x in prim)]\n",
    "                        # pimg = np.concatenate(prim, axis=1) + 0.5\n",
    "                        # simg = np.concatenate(spec, axis=1) * 0.05\n",
    "                        # img = np.clip(np.concatenate([pimg, simg], axis=0), 0.0, 1.0) * 255\n",
    "                        # Image.fromarray(img.astype(np.uint8)).save(self.training_test_path / f'img{epoch:03d}.png')\n",
    "                        \"\"\"\n",
    "                        # 4-in-1 image + spectrum\n",
    "                        prim = [x.squeeze(0) for x in [origs[6], inps[6], outputs[6], targs[6]]]\n",
    "                        spec = [v for _, v in (self._compute_spectral(x, magnitude=True, normalize=False) for x in prim)]\n",
    "                        pimg = torch.cat(prim, dim=1).add(0.5)\n",
    "                        simg = torch.cat(spec, dim=1).mul(0.05)\n",
    "                        img = torch.cat([pimg, simg], dim=0)\n",
    "\n",
    "                        # Saving the Outputs.\n",
    "                        save_image(img, self.training_test_path / f\"img{epoch:03d}.png\", normalize=False)\n",
    "                        \n",
    "            valid_loss = (valid_loss / valid_n) if valid_n > 0 else 0.0\n",
    "            epoch_time = time.time() - start_time\n",
    "\n",
    "            # Update the Summary\n",
    "            self.writer.add_scalar(\"Training/Loss\", train_loss, global_step=epoch, new_style=True)\n",
    "            self.writer.add_scalar(\"Validation/Loss\", valid_loss, global_step=epoch, new_style=True)\n",
    "            self.writer.add_scalar(\"Validation/Average_PSNR\", avg_psnr.item(), global_step=epoch, new_style=True)\n",
    "            self.writer.add_scalar(\"Learning_rate\", self.optimizer.param_groups[0][\"lr\"], global_step=epoch, new_style=True)\n",
    "            self.writer.add_scalar(\"Training/time-per-epoch\", epoch_time, global_step=epoch, new_style=True)\n",
    "            \n",
    "            print(f'[{self.device}]Epoch [{epoch+1}/{self.max_epochs}] | Time: {epoch_time: 0.2f} | Train Loss: {train_loss: 0.6f} | Validation Loss: {valid_loss: 0.6f} | Avg. PSNR: {avg_psnr.item()} | Learning Rate: {self.optimizer.param_groups[0][\"lr\"]: 0.6f}')\n",
    "    \n",
    "            if epoch%self.save_interval == self.save_interval-1 and not self.final_epoch and self.device == 0:\n",
    "                self._save_snapshot()\n",
    "\n",
    "            if self.final_epoch:\n",
    "                if self.device == 0:\n",
    "                    # Save the snapshot\n",
    "                    self._save_snapshot()\n",
    "                \n",
    "                # Do a full Validation set testing with result saving.\n",
    "                loader = DataLoader(self.valid_data, batch_size=1, shuffle=False, pin_memory=True, pin_memory_device=\"cuda\")\n",
    "\n",
    "                self.model.eval()\n",
    "                with torch.inference_mode():\n",
    "                    psnr_file = self.validation_test_path / \"00_PSNR.txt\"\n",
    "                    with psnr_file.open('wt') as fout:\n",
    "                        fout.write(f'Index:\\tOriginal\\tInput\\t\\tOutput\\t\\tGains\\n---------------------------------------------------------------------------------\\n')\n",
    "                        for idx, batch in tqdm(enumerate(loader), desc=\"Validation Testing\", total=10, leave=True):\n",
    "                            if idx == 10:    break\n",
    "                            \n",
    "                            # inp, targ, _, _, orig = batch\n",
    "                            # inp, targ, orig = inp.to(self.device), targ.to(self.device), orig.to(self.device)\n",
    "                            imgs, specs = batch\n",
    "                            imgs, specs = imgs.to(self.device), specs.to(self.device)\n",
    "                            inp, targ, _, _, orig = self._preprocessbatch(imgs, specs,\n",
    "                                                                         noisy_targets=False,\n",
    "                                                                         inject_noise=inject_noise,\n",
    "                                                                         **kwargs)\n",
    "                            denoised_op = self.model(inp)\n",
    "\n",
    "                            # if self.post_op == 'fspec':\n",
    "                            #     denoised_op = self._post_op(denoised_op, specs, spec_mask)\n",
    "                            \n",
    "                            # 4-in-1 image + spectrum\n",
    "                            prim = [x.squeeze(0) for x in [orig, inp, denoised_op, targ]]\n",
    "                            spec = [v for _, v in (self._compute_spectral(x, magnitude=True, normalize=False) for x in prim)]\n",
    "                            pimg = torch.cat(prim, dim=1) + 0.5\n",
    "                            simg = torch.cat(spec, dim=1) * 0.05\n",
    "                            img = torch.cat([pimg, simg], dim=0)\n",
    "\n",
    "                            # Saving the Outputs.\n",
    "                            save_image(img, self.validation_test_path / f\"final{idx:03d}.png\", normalize=False)\n",
    "                            # save_image((torch.clip(orig, -0.5, 0.5) + 0.5).cpu(), self.validation_test_path / f\"original{idx:03d}.png\")\n",
    "                            save_image((torch.clip(denoised_op, -0.5, 0.5) + 0.5).cpu(), self.validation_test_path / f\"output{idx:03d}.png\")\n",
    "                            save_image((torch.clip(targ, -0.5, 0.5) + 0.5).cpu(), self.validation_test_path / f\"target{idx:03d}.png\")\n",
    "                            save_image((torch.clip(inp, -0.5, 0.5) + 0.5).cpu(), self.validation_test_path / f\"input{idx:03d}.png\")\n",
    "                            \n",
    "                            '''\n",
    "                            # # Saving the Outputs.\n",
    "                            # prim = [x.squeeze(0).detach().cpu().numpy() for x in [orig[0], inp[0], denoised_op[0], targ[0]]]\n",
    "                            # spec = [v for _, v in (compute_spectral_image(x, magnitude=True) for x in prim)]\n",
    "                            # pimg = np.concatenate(prim, axis=1) + 0.5\n",
    "                            # simg = np.concatenate(spec, axis=1) * 0.03\n",
    "                            # img = (np.clip(np.concatenate([pimg, simg], axis=0), 0.0, 1.0) * 255).astype(np.uint8)\n",
    "                            # # 4-in-1 image + spectrum\n",
    "                            # Image.fromarray(img).save(self.validation_test_path / f'final{idx:03d}.png')\n",
    "\n",
    "                            # inp_img = (np.clip((inp[0].squeeze(0).detach().cpu().numpy() + 0.5), 0.0, 1.0) * 255).astype(np.uint8)\n",
    "                            # targ_img = (np.clip((targ[0].squeeze(0).detach().cpu().numpy() + 0.5), 0.0, 1.0) * 255).astype(np.uint8)\n",
    "                            # denoised_img = (np.clip(denoised_op[0].squeeze(0).detach().cpu().numpy() + 0.5, 0.0, 1.0) * 255).astype(np.uint8)\n",
    "\n",
    "                            # Image.fromarray(inp_img).save(self.validation_test_path / f'input{idx:03d}.png')\n",
    "                            # Image.fromarray(targ_img).save(self.validation_test_path / f'target{idx:03d}.png')\n",
    "                            # Image.fromarray(denoised_img).save(self.validation_test_path / f'output{idx:03d}.png')\n",
    "                            '''\n",
    "                            # PSNR Scores\n",
    "                            orig_vs_targ = self._psnr_scores(orig, targ).item()\n",
    "                            op_vs_targ = self._psnr_scores(denoised_op, targ).item()\n",
    "                            inp_vs_targ = self._psnr_scores(inp, targ).item()\n",
    "                            \n",
    "                            fout.write(f'{idx:02d}:\\t{orig_vs_targ:0.5f}\\t\\t{inp_vs_targ:0.5f}\\t\\t{op_vs_targ:0.5f}\\t\\t{(op_vs_targ - orig_vs_targ):0.5f}\\n')\n",
    "        \n",
    "        self.writer.close()\n",
    "        total_seconds = time.time() - train_start_time\n",
    "        print(f\"Time Elapsed: {int(total_seconds // 3600)}hrs : {int((total_seconds % 3600) // 60)}mins : {int(total_seconds % 60)}secs.\" )\n",
    "        # Stop with the logging\n",
    "        self.logger.stop()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774d10c6-de26-4553-ad1f-120988429374",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Initialize Trainer Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723812a0-5f96-4ebc-a85c-6407365ea34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = 1000\n",
    "experiment_desc = \"\"\n",
    "batch_size = 20\n",
    "max_epochs = 6\n",
    "learning_rate = 0.0005\n",
    "loss_fn = nn.MSELoss()\n",
    "model = Noise2Noise()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "scheduler = lr_sch.SequentialLR(optimizer=optimizer, \n",
    "                                schedulers=[lr_sch.LinearLR(optimizer=optimizer, start_factor=0.001, total_iters=int(max_epochs * 0.1)),\n",
    "                                            lr_sch.ConstantLR(optimizer=optimizer, factor=1.0, total_iters=int(max_epochs * 0.6)), \n",
    "                                            lr_sch.LinearLR(optimizer=optimizer, start_factor=1.0, end_factor=0.001, total_iters=int(max_epochs * 0.3))], \n",
    "                                milestones=[int(max_epochs * 0.1), int(max_epochs * 0.7)])\n",
    "results_dir = Path(\"results/999/run-0_2025-05-14\")\n",
    "\n",
    "trainer = Trainer(gpu_id=0, model=model, \n",
    "                  train_data=train_dataset, \n",
    "                  valid_data=valid_dataset, \n",
    "                  optimizer=optimizer, \n",
    "                  scheduler=scheduler,\n",
    "                  loss_fn=loss_fn,\n",
    "                  experiment_id=experiment_id,\n",
    "                  experiment_desc=experiment_desc,\n",
    "                  batch_size=batch_size,\n",
    "                  post_op='fspec',\n",
    "                  max_epochs=max_epochs,\n",
    "                  results_dir=results_dir,\n",
    "                  load_checkpoint=True,\n",
    "                  snapshot_name=\"latest-snapshot\"\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb4e6e3-93e9-44f2-a2de-934b213fcf9d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setup and Start the Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a8c9da-3c08-4b47-9330-8ebda6717026",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setup the parameters and datasets\n",
    "trainer._setup_training()\n",
    "\n",
    "# Train the model\n",
    "trainer.train(n2n=False,\n",
    "              corruption_type=['gaussian0', 'poisson0'], \n",
    "              augment_params={\"translate\": 32},\n",
    "              corruption_params={\"p_edge\": 0.5, \n",
    "                                  \"distribution\": \"uniform\", \n",
    "                                 \"poisson_strength\": 3.0, \n",
    "                                 \"mask_ratio\": 0.1, \n",
    "                                 \"gaussian_std\": 0.15, \n",
    "                                 \"blur_sigma\": 1.0, \n",
    "                                 \"blur_kernel\": 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0716a801-90cd-43ef-8bd8-1aa98e53c61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# Delete the model from the GPU to avoid restarting the kernel for each execution.\n",
    "\n",
    "# Clear the CUDA Cache and Garbage Collector\n",
    "del model       # Deletes the model from the GPU\n",
    "del optimizer\n",
    "del trainer\n",
    "gc.collect() # GC collects the deleted model and clears the memory.\n",
    "torch.cuda.empty_cache() # Removes any cache data related to the removed model from the GPU.\n",
    "\n",
    "\n",
    "\n",
    "# Example Usage below:\n",
    "\n",
    "# import gc\n",
    "# ex_model = ExampleModel().cuda()\n",
    "# del ex_model # Deletes the model from the GPU\n",
    "# gc.collect() # GC collects the deleted model and clears memory\n",
    "# torch.cuda.empty_cache() # Removes any cache data related to the removed model from the GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2f2df1-ef4c-4312-9fa8-981fd702a05e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Evaluate The Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e17dea-12f5-48b3-a479-aeb566a5ffe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_loader = None\n",
    "if eval_loader is None:\n",
    "    eval_loader = DataLoader(eval_dataset, batch_size=1, shuffle=False, pin_memory=True, pin_memory_device=\"cuda\")\n",
    "\n",
    "trainer.eval(eval_loader, \n",
    "             inject_noise=True, \n",
    "             patch_size=255, \n",
    "             image_size=2550, \n",
    "             overlap=0.5, \n",
    "             corruption_type=['gaussian0', 'poisson0'], \n",
    "             corruption_params={\"p_edge\": 0.5, \n",
    "                                \"distribution\": \"uniform\", \n",
    "                                \"poisson_strength\": 3.0, \n",
    "                                \"mask_ratio\": 0.1, \n",
    "                                \"gaussian_std\": 0.15, \n",
    "                                \"blur_sigma\": 1.0, \n",
    "                                \"blurr_kernel\": 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33873b72-7666-4ee0-b2e0-b552c28afce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f343d3ad-5caf-4067-bbce-1b34580e0c38",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## DDP Associated Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da67bf98-c3b6-4e3b-8902-167ccc5930cb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def ddp_setup(rank, world_size):\n",
    "    '''\n",
    "    rank: Unique id for each process\n",
    "    world_size: Total number of processes. (n_gpus)\n",
    "    '''\n",
    "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "    os.environ[\"MASTER_PORT\"] = \"12335\"\n",
    "    init_process_group(backend=\"nccl\", rank=rank, world_size=world_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd709988-fe39-488a-bac1-ac1aaf9408f9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Report Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2f4993-09f0-4b35-8bd4-b75c8cc6797c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Visualizing Tensorboard Summaries\n",
    "\n",
    "<b><font size=\"4\">Starting Tensorboard Server: </font></b>\n",
    "!tensorboard --logdir=./results --port=6006\n",
    "\n",
    "<b><font size=\"4\">Shut down the Server in: </font></b>\n",
    "<details>\n",
    "     <summary><b><font size=\"4\">Linux</font></b></summary>\n",
    "<font color=\"yellow\">1) Kill tensorboard process:<br>\n",
    "</font>\n",
    "    !pkill -f tensorboard\n",
    "</details>\n",
    "<br>\n",
    "<details>\n",
    "     <summary><b><font size=\"4\">Windows</font></b></summary>\n",
    "  \n",
    "<font color=\"yellow\">1) Find the Process ID of active tensorboard instance: <br>\n",
    "    Note: Find the PID with port 6006 that is Listening. <br>\n",
    "</font>\n",
    "    !netstat -ano | findstr :6006 \n",
    "    <br>\n",
    "    \n",
    "<font color=\"yellow\">2) Kill the task with PID [!!!!!!!! TAKE EXTREME CAUTION !!!!!!!!!!!!]:<br>\n",
    "    Note: You can add \"/F\" at the end to force the command.<br>\n",
    "</font>\n",
    "    !taskkill /PID ****\n",
    "\n",
    "<font color=\"yellow\">3) Kill all tensorboard related instances:<br>\n",
    "    Note: You can add \"/F\" at the end to force the command.<br>\n",
    "</font>\n",
    "    !taskkill /IM tensorboard.exe /F\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4455e98d-0d66-4526-a55c-638df0fe3f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor Board\n",
    "!tensorboard --logdir=./Results_bernoulli_test_0 --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7682a4c-7da5-4529-b43e-988daba9f0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!netstat -ano | findstr :6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c1e075-9acd-4257-9e2c-030b53837f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !taskkill /PID 27464 /F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7299360-fb22-401b-b55f-551af6f478c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Experimentation Sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07bebb4-8ff0-48a0-bc66-e0d9d18b039f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Testing Different Noise and Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef11487-03ed-40ad-b0ea-6981ffbc9af7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "#    Poisson Noise\n",
    "#\n",
    "import numpy as np\n",
    "import imageio.v3 as iio\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.exposure import rescale_intensity\n",
    "\n",
    "def add_poisson_noise(image, amplification=0.102):\n",
    "    \"\"\"Apply Poisson noise to an image.\"\"\"\n",
    "    noisy_image = np.random.poisson(image * amplification) / amplification\n",
    "    return np.clip(noisy_image, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Load the image\n",
    "image_path = \"D:\\\\CAPSTONE\\\\Results Backup\\\\HQ_evalImgs\\\\00000390.png\"\n",
    "image = iio.imread(image_path)\n",
    "\n",
    "# Convert to grayscale if necessary\n",
    "if len(image.shape) == 3:\n",
    "    grayscale_image = np.mean(image, axis=-1).astype(np.uint8)\n",
    "else:\n",
    "    grayscale_image = image\n",
    "\n",
    "# Enhance contrast by stretching pixel values\n",
    "contrast_enhanced_image = rescale_intensity(grayscale_image, in_range='image', out_range=(0, 255)).astype(np.uint8)\n",
    "\n",
    "# Apply uniform Poisson noise with amplification factor of 0.05\n",
    "noisy_contrast_image = add_poisson_noise(contrast_enhanced_image, amplification=0.102)\n",
    "# noisy_contrast_image = add_poisson_noise(grayscale_image, amplification=0.102)\n",
    "\n",
    "# Save the output image\n",
    "output_contrast_path = \"D:\\\\CAPSTONE\\\\Results Backup\\\\HQ_evalImgs\\\\noisy_0.102.png\"\n",
    "iio.imwrite(output_contrast_path, noisy_contrast_image)\n",
    "\n",
    "# Display the processed image\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(noisy_contrast_image, cmap='gray')\n",
    "plt.title(\"Contrast Enhanced + Poisson Noise (0.05)\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Output the file path\n",
    "print(f\"Processed image saved at: {output_contrast_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d357fb-666f-48ae-b3a4-767c1e975554",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "#    Gaussian Noise\n",
    "#\n",
    "import numpy as np\n",
    "import imageio.v3 as iio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def add_gaussian_noise(image, mean=0, std=10):\n",
    "    \"\"\"\n",
    "    Adds Gaussian noise to an image.\n",
    "    :param image: Input grayscale image (NumPy array)\n",
    "    :param mean: Mean of the Gaussian noise\n",
    "    :param std: Standard deviation of the Gaussian noise\n",
    "    :return: Noisy image (NumPy array)\n",
    "    \"\"\"\n",
    "    noise = np.random.normal(mean, std, image.shape)  # Generate Gaussian noise\n",
    "    noisy_image = image + noise  # Add noise to the image\n",
    "    return np.clip(noisy_image, 0, 255).astype(np.uint8)  # Clip and convert to uint8\n",
    "\n",
    "# Load the original uploaded image\n",
    "image_path = \"D:\\\\CAPSTONE\\\\Results Backup\\\\HQ_evalImgs\\\\gaussian_noisy_blur_image.png\"  # Use the original uploaded file\n",
    "original_image = iio.imread(image_path, mode='L')  # Load as grayscale\n",
    "\n",
    "# Define Gaussian noise parameters\n",
    "mean = 0       # Mean of the Gaussian noise\n",
    "std = 30       # Standard deviation of the Gaussian noise (adjustable)\n",
    "\n",
    "# Apply Gaussian noise\n",
    "noisy_image = add_gaussian_noise(original_image, mean, std)\n",
    "\n",
    "# Save and display the noisy image\n",
    "output_path = \"D:\\\\CAPSTONE\\\\Results Backup\\\\HQ_evalImgs\\\\gaussian_noisy_blur_then_poisson_image.png\"\n",
    "iio.imwrite(output_path, noisy_image)\n",
    "\n",
    "# Show original and noisy images side by side\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(original_image, cmap='gray')\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(noisy_image, cmap='gray')\n",
    "plt.title(f\"Gaussian Noise (mean={mean}, std={std})\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Noisy image saved at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e508f934-eba4-4393-9df0-a8aad6610ad8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#    Gaussian Blur\n",
    "#\n",
    "import numpy as np\n",
    "import imageio.v3 as iio\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "def apply_gaussian_blur(image, sigma=1):\n",
    "    \"\"\"\n",
    "    Applies Gaussian blur to an image.\n",
    "    :param image: Input grayscale image (NumPy array)\n",
    "    :param sigma: Standard deviation for Gaussian kernel\n",
    "    :return: Blurred image (NumPy array)\n",
    "    \"\"\"\n",
    "    blurred_image = gaussian_filter(image, sigma=sigma)  # Apply Gaussian blur\n",
    "    return np.clip(blurred_image, 0, 255).astype(np.uint8)  # Clip and convert to uint8\n",
    "\n",
    "# Load the original uploaded image\n",
    "image_path = \"D:\\\\CAPSTONE\\\\Results Backup\\\\HQ_evalImgs\\\\noisy_0.102.png\"  # Use the original uploaded file\n",
    "original_image = iio.imread(image_path, mode='L')  # Load as grayscale\n",
    "\n",
    "# Define Gaussian blur parameter\n",
    "sigma = 1.5  # Standard deviation for Gaussian blur (adjustable)\n",
    "\n",
    "# Apply Gaussian blur\n",
    "blurred_image = apply_gaussian_blur(original_image, sigma)\n",
    "\n",
    "# Save and display the blurred image\n",
    "output_path = \"D:\\\\CAPSTONE\\\\Results Backup\\\\HQ_evalImgs\\\\poisson_noisy_then_blur_image.png\"\n",
    "# iio.imwrite(output_path, blurred_image)\n",
    "\n",
    "# print(original_image.dtype)\n",
    "\n",
    "# Show original and blurred images side by side\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(original_image, cmap='gray')\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(blurred_image, cmap='gray')\n",
    "plt.title(f\"Gaussian Blur (sigma={sigma})\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Blurred image saved at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7793a2f9-3838-4960-8189-31a8d8be3ebe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## PyTorch Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79cae14-f6fd-4855-aa58-005cb74b4a1c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.transforms.functional import gaussian_blur\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6bb4ff-1ebf-4d73-b8eb-f15bd7761fef",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def compute_spectral(image, ifft=False, magnitude=False, normalize=True):\n",
    "        fft_shift = None\n",
    "        if ifft:\n",
    "            fft_shift = torch.fft.ifftshift(image, dim=(-2, -1))  # Shift zero frequency to center\n",
    "        else:\n",
    "            fft_image = torch.fft.fft2(image)  # Apply 2D Fourier Transform\n",
    "            fft_shift = torch.fft.fftshift(fft_image, dim=(-2, -1))  # Shift zero frequency to center\n",
    "        \n",
    "        if magnitude:\n",
    "            magnitude_spectrum = torch.abs(fft_shift)  # Get magnitude\n",
    "            # Normalize the spectrum for consistency\n",
    "            magnitude_spectrum = torch.log1p(magnitude_spectrum)  # Log scaling\n",
    "            \n",
    "            if normalize:\n",
    "                magnitude_spectrum = (magnitude_spectrum - magnitude_spectrum.min()) / (magnitude_spectrum.max() - magnitude_spectrum.min())\n",
    "                # magnitude_spectrum /= magnitude_spectrum.max()  # Normalize [0,1]\n",
    "                \n",
    "            return fft_shift.to(torch.complex64), magnitude_spectrum\n",
    "        else: \n",
    "            return fft_shift.to(torch.complex64)\n",
    "    \n",
    "def apply_poisson(imgs, criterion=0.1, corruption_strength=0.102, device=\"cpu\"):\n",
    "    _, H, W = imgs.shape\n",
    "    mask = (torch.rand((H, W), device=device) < criterion).float()\n",
    "    \n",
    "    poisson_noise = torch.poisson(torch.abs(imgs) * corruption_strength) / corruption_strength\n",
    "    batch_mask = mask.unsqueeze(0)\n",
    "    new_imgs = torch.where(batch_mask.bool(), poisson_noise, imgs)\n",
    "    # print(f\"Value Range of output: [{torch.min(new_imgs)}, {torch.max(new_imgs)}]\")\n",
    "    return torch.clip(new_imgs, -0.5, 0.5)\n",
    "    \n",
    "def apply_gaussian(imgs, mean=0.0, std= 0.1, device=\"cpu\"):\n",
    "    mask = torch.normal(mean=mean, std=std, size=imgs[0].shape, device=device)\n",
    "    # print(f\"Mask Shape: {mask.shape}\")\n",
    "    new_imgs = imgs + mask\n",
    "    return torch.clip(new_imgs, -0.5, 0.5)\n",
    "\n",
    "def apply_blur(imgs, kernel_size=3, sigma=1):\n",
    "    # imgs.unsqueeze(1)\n",
    "    return torch.clip(gaussian_blur(img=imgs, kernel_size=kernel_size, sigma=sigma), -0.5, 0.5)\n",
    "    \n",
    "def apply_bernoulli(imgs, p_edge=0.025, device=\"cpu\"):\n",
    "    _, H, W = imgs.shape\n",
    "    y = torch.arange(H, dtype=torch.float32, device=device) - H // 2\n",
    "    x = torch.arange(W, dtype=torch.float32, device=device) - W // 2\n",
    "    yy, xx = torch.meshgrid(y**2, x**2, indexing='ij')\n",
    "    r_dist = torch.sqrt(xx + yy)\n",
    "    prob_mask = (p_edge ** (2.0 / W)) ** r_dist\n",
    "    \n",
    "    keep = (torch.rand(size=(H, W), device=device, dtype=torch.float32) ** 2) < prob_mask\n",
    "    keep = keep & torch.flip(keep, dims=[0, 1])\n",
    "    # Apply Mask\n",
    "    mskd_specs = specs * keep\n",
    "    spec_msk = keep.to(torch.float32)\n",
    "    new_specs = compute_spectral(mskd_specs / torch.where(keep, prob_mask, 1e-8), ifft=True)\n",
    "    new_imgs = torch.fft.ifft2(new_specs).real.float()\n",
    "    return torch.clip(new_imgs, -0.5, 0.5), new_specs, spec_msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0b2021-671f-49ea-9d6a-f8dc0a492596",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "ds_dir = Path(\"PyTorchDatasets\")\n",
    "poisson_criterion = 0.1\n",
    "poisson_strength = 0.0002\n",
    "\n",
    "gaussian_mean = 0.0\n",
    "gaussian_std = 0.1\n",
    "\n",
    "blur_sigma = 1.0\n",
    "blur_kernel = 15\n",
    "\n",
    "bernoulli_probability_at_edge = 0.025\n",
    "\n",
    "# (kernel = 17, sigm = 1.99, standdiv= 0.06, loss = 0.0126)\n",
    "# (kernel = 15, sigm = 1.98, standdiv= 0.01, crit=0.1, strength=0.0002)\n",
    "\n",
    "\n",
    "# Load Dataset\n",
    "img_dataset = torch.load(ds_dir / \"HQ_train_full_img.pth\", weights_only=False)\n",
    "loader = DataLoader(img_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "img_size = (10,10)\n",
    "img_size = (15,15)\n",
    "batch_size = loader.batch_size\n",
    "n_col = 2\n",
    "n_row = math.ceil(batch_size/n_col)\n",
    "\n",
    "plt.figure(figsize=(n_col * img_size[0], n_row * img_size[1])) # fig_size=(W, H)\n",
    "# Read image from dataset\n",
    "for idx, batch in tqdm(enumerate(loader), total=len(loader), desc=\"Processed Images\"):\n",
    "    imgs, specs = batch\n",
    "    # print(imgs.shape)\n",
    "    \n",
    "    imgs = apply_gaussian(imgs, gaussian_mean, gaussian_std)\n",
    "    imgs = apply_blur(imgs, kernel_size=blur_kernel, sigma=blur_sigma)\n",
    "    imgs = apply_poisson(imgs, criterion=poisson_criterion, corruption_strength=poisson_strength)\n",
    "    # imgs, _, _ = apply_bernoulli(imgs, p_edge=bernoulli_probability_at_edge) \n",
    "    \n",
    "    imgs = imgs.add(0.5).mul(255).to(torch.uint8).to(\"cpu\")\n",
    "    plt.figure(figsize=(n_col * img_size[0], n_row * img_size[1])) # fig_size=(W, H)\n",
    "    for idx2, img in enumerate(imgs):\n",
    "        plt.subplot(n_row, n_col, idx2+1)\n",
    "        plt.imshow(img.numpy(), cmap='gray')\n",
    "        plt.title(f\"Image-{idx2+1}\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "    time.sleep(1)\n",
    "    if idx == 10:\n",
    "        break\n",
    "\n",
    "# batch = next(iter(loader))\n",
    "# imgs, specs = batch\n",
    "# imgs = imgs[:, 1000:-1000, 1000:-1000]\n",
    "# best_params = (15, 0.98, 0.01,0.1, 0.0002)\n",
    "# best_score = 0.012798348441720009 # float(\"inf\")\n",
    "# # kernels = [x for x in range(1, 24, 2)]\n",
    "# sigmas = [round(x, 2) for x in np.arange(0.40, 2.0, 0.02)]\n",
    "# stds = [round(x, 2) for x in np.arange(0.01, 0.15, 0.01)]\n",
    "# kernels = [15, 17]\n",
    "# # sigmas = [1.9, 1.99]\n",
    "# # stds = [0.19, 1.99]\n",
    "# poisson_crits = [round(x, 2) for x in np.arange(0.1, 0.2, 0.01)]\n",
    "# poisson_strs = [round(x, 6) for x in np.arange(0.0001, 0.0005, 0.0001)]\n",
    "\n",
    "# LQ_img = ToTensor()(Image.open(Path(\"Datasets/Mphase_3/Images/00000000.png\")).convert(\"L\"))[:, 1010:-1010, 1010:-1010] - 0.5\n",
    "# print(imgs.shape, LQ_img.shape)\n",
    "# assert imgs.shape == LQ_img.shape\n",
    "\n",
    "# idx = 0\n",
    "# for k in tqdm(kernels, position=0, leave=True, desc=f\"Kernels\", ncols=100):\n",
    "#     for s in tqdm(sigmas, position=1, leave=True, desc=f\"Sigmas\", ncols=100):\n",
    "#         for std in tqdm(stds, desc=f\"STDs\", leave=False, position=2, ncols=100):\n",
    "#             for crit in poisson_crits: \n",
    "#                 for strength in poisson_strs:\n",
    "#                     idx += 1\n",
    "#                     img = apply_gaussian(imgs, mean=0.0, std=std)\n",
    "#                     blu = apply_blur(img, kernel_size=k, sigma=s)\n",
    "#                     output = apply_poisson(blu, criterion=crit, corruption_strength=strength)\n",
    "                    \n",
    "#                     score = torch.mean((output - LQ_img)**2)\n",
    "#                     if score < best_score:\n",
    "#                         best_score = score\n",
    "#                         best_params = (k, s, std, crit, strength)\n",
    "#                         print(f\"New Loss:{best_score} | Kernel size: {k} | Sigma: {s} | Gaussian STD: {std} | Criterion: {crit} | Strength: {strength}\")\n",
    "            \n",
    "# print(f\"FINAL:\\nMinimum Loss:{best_score} | Kernel size: {best_params[0]} | Sigma: {best_params[1]} | Gaussian STD: {best_params[2]} | Criterion: {best_params[3]} | Strength {best_params[4]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b3abfb-06a3-4ab3-8058-1e0d91d2c852",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08f88e2-ad07-484c-89cb-c4041f708cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95df7cda-a0f6-4c00-aa86-dbbed615676f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Depricated Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dec720-3c92-47ee-973e-4e9939640e3d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# This is Depricated way to create dataset. Now dataset does not include any transformations or injected noise.\n",
    "\n",
    "# Dataset Paths\n",
    "dataset_dir = Path(\"noise2noise/datasets/\")\n",
    "train_dataset_path = dataset_dir / \"HQ_20_xray_train.pkl\"\n",
    "valid_dataset_path = dataset_dir / \"HQ_5_xray_valid.pkl\"\n",
    "eval_dataset_path = dataset_dir / \"LQ_10_xray_eval.pkl\"\n",
    "\n",
    "# Data loader\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, inputs, targets, input_spectrals, input_spectral_masks, originals):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        self.input_spectrals = input_spectrals\n",
    "        self.input_spectral_masks = input_spectral_masks\n",
    "        self.originals = originals\n",
    "        # assert self.inputs.shape == self.targets.shape and self.inputs.shape == self.input_spectrals.shape\n",
    "        print(\"Dataset Information:\")\n",
    "        print(f\"\\t{inputs.shape[0]} samples in the dataset\")\n",
    "        print(f\"\\tSample size is {inputs.shape[1]} x {inputs.shape[2]}\")\n",
    "        print(f\"\\tSpectrum size is {input_spectrals.shape[1]} x {input_spectrals.shape[2]}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.targets[idx], self.input_spectrals[idx], self.input_spectral_masks[idx], self.originals[idx]\n",
    "\n",
    "def create_dataset(dataset_pkl_path, augment_params=dict(), add_noise=False, noisy_targets=False, **kwargs):\n",
    "    # Read the Images from pkl files.\n",
    "    dataset_pkl_path = Path(dataset_pkl_path)\n",
    "    images, spectrals = None, None\n",
    "    try:\n",
    "        with open(dataset_pkl_path, \"rb\") as file:\n",
    "            # Get Images and Spectrals from them.\n",
    "            images, spectrals = pickle.load(file)\n",
    "            spectrals = spectrals.astype(np.complex64)\n",
    "            images = images.astype(np.float32) / 255.0 - 0.5\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {dataset_pkl_path} was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Exception Raised: {e}\")\n",
    "\n",
    "    f_inputs, f_targets, f_input_spectrals, f_input_spectral_masks = [], [], [], []\n",
    "    for img, spec in tqdm(zip(images, spectrals), total=len(images), desc=kwargs[\"dataset_desc\"]):\n",
    "        # Perform Augmentation\n",
    "        augmented_image, augmented_spectral = augment_data(img, spec, augment_params)\n",
    "        \n",
    "        # Insert Noise in Input image\n",
    "        if add_noise:\n",
    "            corrupted_image, corrupted_spectral, corruption_mask = corrupt_data(augmented_image, augmented_spectral, corruption_type=kwargs[\"corruption_type\"], corruption_params=kwargs[\"corruption_params\"])\n",
    "        else:\n",
    "            corrupted_image, corrupted_spectral, corruption_mask = augmented_image, augmented_spectral, []\n",
    "        # Noisy Target vs Clean Targets\n",
    "        if noisy_targets:\n",
    "            mod_corruption_params = copy.deepcopy(kwargs[\"corruption_params\"])\n",
    "            noise_factor = 1.0\n",
    "            if kwargs[\"corruption_type\"] == \"bspec\":\n",
    "                mod_corruption_params[\"p_edge\"] *= noise_factor\n",
    "            elif kwargs[\"corruption_type\"] == \"poisson\":\n",
    "                mod_corruption_params[\"poisson_strength\"] *= noise_factor\n",
    "                \n",
    "            target, _, _ = corrupt_data(augmented_image, augmented_spectral, corruption_type=kwargs[\"corruption_type\"], corruption_params=mod_corruption_params)\n",
    "            f_targets.append(target)\n",
    "        else:\n",
    "            f_targets.append(augmented_image)\n",
    "\n",
    "        f_inputs.append(corrupted_image)\n",
    "        f_input_spectrals.append(corrupted_spectral.astype(np.complex64))\n",
    "        f_input_spectral_masks.append(corruption_mask)\n",
    "    # Create training dataset.\n",
    "    print(f\"Component dtypes:\\n \\tInputs: {np.array(f_inputs).dtype} | Targets: {np.array(f_targets).dtype} | Input's Spectrals: {np.array(f_input_spectrals).dtype} | Spectral Masks: {np.array(f_input_spectral_masks).dtype} | Originals: {images.dtype}\\n\")\n",
    "    return CustomDataset(np.array(f_inputs), np.array(f_targets), np.array(f_input_spectrals), np.array(f_input_spectral_masks), images)\n",
    "\n",
    "# Create and save Dataset\n",
    "ds_dir = Path(\"PyTorchDatasets\")\n",
    "\n",
    "train_dataset = create_dataset(dataset_pkl_path=valid_dataset_path, augment_params=dict(translate=32), add_noise=True, noisy_targets=True, dataset_desc='Training Dataset', corruption_type='bspec', corruption_params={\"p_edge\": 0.5, \"distribution\": \"uniform\", \"poisson_strength\": 0.102, \"mask_ratio\":0.1})\n",
    "torch.save(train_dataset, ds_dir / \"train_dataset_b.pth\", pickle_protocol=4)\n",
    "\n",
    "valid_dataset = create_dataset(dataset_pkl_path=valid_dataset_path, add_noise=True, noisy_targets=True, dataset_desc='Validation Dataset', corruption_type='bspec', corruption_params={\"p_edge\": 0.5, \"distribution\": \"uniform\", \"poisson_strength\": 0.102, \"mask_ratio\":0.1})\n",
    "torch.save(valid_dataset, ds_dir / \"valid_dataset_b.pth\", pickle_protocol=4)\n",
    "\n",
    "eval_dataset = create_dataset(dataset_pkl_path=eval_dataset_path, add_noise=True, noisy_targets=False, dataset_desc='Evaluation Dataset', corruption_type='bspec', corruption_params={\"p_edge\": 0.5, \"distribution\": \"uniform\", \"poisson_strength\": 0.102, \"mask_ratio\":0.1})\n",
    "torch.save(eval_dataset, ds_dir / \"eval_dataset_b_clean_targ.pth\", pickle_protocol=4)\n",
    "\n",
    "# Load Dataset\n",
    "train_dataset = torch.load(ds_dir / \"train_dataset_b.pth\", weights_only=False)\n",
    "valid_dataset = torch.load(ds_dir / \"valid_dataset_b.pth\", weights_only=False)\n",
    "eval_dataset = torch.load(ds_dir / \"eval_dataset_b_clean_targ.pth\", weights_only=False)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=12, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=15, shuffle=False)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c0ba83-dc9a-463a-9a17-6b03d3a266ad",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# This was a version of the dataset that used the older pickle files from the TensorFlow code\n",
    "class CTDataset(Dataset):\n",
    "    def __init__(self, dataset_file, shuffle=False, n_images=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataset_file (str): Path to the .npz file containing images and spectral data.\n",
    "        \"\"\"\n",
    "        # Can read imgs here and then apply corruptions later.\n",
    "        data = np.load(dataset_file)\n",
    "        self.images = torch.tensor(data[\"images\"], dtype=torch.float32).unsqueeze(1)  # Add channel dim\n",
    "        self.spectral_images = torch.tensor(data[\"spectral_images\"], dtype=torch.float32).unsqueeze(1)\n",
    "        assert self.images.shape == self.spectral_images.shape\n",
    "        \n",
    "        if shuffle:\n",
    "            permutation = np.arange(self.images.shape[0])\n",
    "            np.random.shuffle(permutation)\n",
    "            if n_images is not None:\n",
    "                permutation = permutation[:n_images]\n",
    "            self.images = self.images[permutation]\n",
    "            self.spectral_images = self.spectral_images[permutation]\n",
    "\n",
    "        if n_images is not None:\n",
    "            self.images = self.images[:n_images]\n",
    "            self.spectral_images = self.spectral_images[:n_images]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.spectral_images[idx]\n",
    "\n",
    "# Newer version of minibatching code, more inline with the updated dataset\n",
    "def _minibatchs(images, spectrals, shuffle: bool, corrupt_targets: bool, corruption_params=dict(), augment_params=dict(), n_images=None):\n",
    "        assert images.shape == spectrals.shape\n",
    "\n",
    "        total_samples = images.shape[0]\n",
    "        total_indices = np.arange(total_samples)\n",
    "\n",
    "        if shuffle:\n",
    "            np.random.shuffle(total_indices)\n",
    "\n",
    "        if n_images:\n",
    "            total_indices = total_indicesp[:n_images]\n",
    "            total_samples = len(total_indices)\n",
    "\n",
    "        inputs, targets = [], []\n",
    "        specs, spec_masks = [], []\n",
    "        \n",
    "        for idx in range(total_samples):\n",
    "            img_aug, spec_aug = augment_data(images[idx], spectrals[idx], augment_params)\n",
    "            img_corr, spec_corr, spec_mask_corr = corrupt_data(img_aug, spec_aug, corruption_params)\n",
    "            inputs.append(img_corr)\n",
    "            specs.append(spec_corr)\n",
    "            spec_masks.append(spec_mask_corr)\n",
    "\n",
    "            if corrupt_targets:\n",
    "                mod_corruption_params = copy.deepcopy(corruption_params)\n",
    "                \n",
    "                if corruption_params[\"corruption_type\"] == \"bspec\":\n",
    "                    mod_corruption_params[\"p_edge\"] *= 0.9\n",
    "                elif corruption_params[\"corruption_type\"] == \"poisson\":\n",
    "                    mod_corruption_params[\"poisson_strength\"] *= 0.9\n",
    "                corr_targ, _, _ = corrupt_data(img_aug, spec_aug, mod_corruption_params)\n",
    "                targets.append(corr_targ)\n",
    "                \n",
    "            else:\n",
    "                targets.append(img_aug)\n",
    "\n",
    "        yield total_indices, inputs, targets, spectral, spec_masks\n",
    "\n",
    "# First version of minibatch (inspired by the TensorFlow version)\n",
    "def _minibatchs(input_imgs, input_specs, shuffle: bool, corrupt_targets: bool, corruption_params=dict(), augment_params=dict(), n_images=None):\n",
    "        assert input_imgs.shape == input_specs.shape\n",
    "\n",
    "        total_samples = input_imgs.shape[0]\n",
    "        total_indices = np.arange(total_samples)\n",
    "\n",
    "        if shuffle:\n",
    "            np.random.shuffle(total_indices)\n",
    "\n",
    "        if n_images:\n",
    "            total_indices = total_indicesp[:n_images]\n",
    "            total_samples = len(total_indices)\n",
    "\n",
    "        inputs, targets = [], []\n",
    "        spectrals, spec_masks = [], []\n",
    "        \n",
    "        for idx in range(total_samples):\n",
    "            img_aug, spec_aug = augment_data(input_imgs[idx], input_specs[idx], augment_params)\n",
    "            img_corr, spec_corr, spec_mask_corr = corrupt_data(img_aug, spec_aug, corruption_params)\n",
    "            inputs.append(img_corr)\n",
    "            spectrals.append(spec_corr)\n",
    "            spec_masks.append(spec_mask_corr)\n",
    "\n",
    "            if corrupt_targets:\n",
    "                mod_corruption_params = copy.deepcopy(corruption_params)\n",
    "                \n",
    "                if corruption_params[\"corruption_type\"] == \"bspec\":\n",
    "                    mod_corruption_params[\"p_edge\"] *= 0.9\n",
    "                elif corruption_params[\"corruption_type\"] == \"poisson\":\n",
    "                    mod_corruption_params[\"poisson_strength\"] *= 0.9\n",
    "                targ_corr, _, _ = corrupt_data(img_aug, spec_aug, mod_corruption_params)\n",
    "                targets.append(targ_corr)\n",
    "                \n",
    "            else:\n",
    "                targets.append(img_aug)\n",
    "\n",
    "        yield total_indices, inputs, targets, spectral, spec_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebf1709-0277-472a-9683-7504fe0aa463",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Testing Block\n",
    "\n",
    "# a, b, c, d, e = next(iter(valid_loader))\n",
    "# print(a.shape, b.shape, c.shape, d.shape, e.shape)\n",
    "# print(a.dtype, b.dtype, c.dtype, d.dtype, e.dtype)\n",
    "\n",
    "\n",
    "# batch = next(iter(valid_loader))\n",
    "# batch\n",
    "# valid_spec_shape = next(iter(train_loader))[2].\n",
    "\n",
    "\n",
    "# def _psnr_scores(image, target, max_pixel_value=255.0):\n",
    "#     assert len(image.shape) == 2 and len(target.shape) == 2\n",
    "#     image = (np.clip(image, -0.5, 0.5) + 0.5) * 255.0\n",
    "#     target = (np.clip(target, -0.5, 0.5) + 0.5) * 255.0\n",
    "    \n",
    "#     # mse = self.loss_fn(image, target)      # Wondering if this would have worked.\n",
    "#     mse = torch.mean((target - image)**2, dim=(0, 1))        \n",
    "    \n",
    "#     if mse == 0:\n",
    "#         return float('inf')\n",
    "    \n",
    "#     psnr = 10.0 * torch.log10(max_pixel_value**2 / mse)\n",
    "#     return psnr.item()\n",
    "\n",
    "# print(_psnr_scores(torch.tensor(tr_inp), torch.tensor(va_orig)))\n",
    "\n",
    "# valid_loader.batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc3deb2-c9db-46ad-a972-8282343d1ce2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# From Trainer class\n",
    "\n",
    "def _eval(self, data_loader: DataLoader, output_dir: Path=Path(\"\"), **kwargs):\n",
    "    n_patches = 361\n",
    "    patch_size = 255\n",
    "    original_img_size = 2550\n",
    "    overlap = 0.5\n",
    "    \n",
    "    if str(output_dir) =='.':\n",
    "        output_dir = self.evaluation_test_path\n",
    "\n",
    "    # Setup NIQE\n",
    "    # niqe = NIQE(dst_pth=Path(\"./PyTorchDatasets\"))\n",
    "    # niqe.load()\n",
    "    \n",
    "    # Create blank image frame\n",
    "    original_reconst = torch.zeros((1, original_img_size, original_img_size), dtype=torch.float32, device=self.device)\n",
    "    denoised_reconst = torch.zeros((1, original_img_size, original_img_size), dtype=torch.float32, device=self.device)\n",
    "    target_reconst = torch.zeros((1, original_img_size, original_img_size), dtype=torch.float32, device=self.device)\n",
    "    input_reconst = torch.zeros((1, original_img_size, original_img_size), dtype=torch.float32, device=self.device)\n",
    "    mod_count = torch.zeros((1, original_img_size, original_img_size), dtype=torch.float32, device=self.device)\n",
    "    \n",
    "    # Establish the step\n",
    "    step = int(patch_size * (1-overlap))\n",
    "    patches_per_row = (original_img_size - patch_size) // step + 1\n",
    "\n",
    "    patch_idx = 0\n",
    "    img_idx = 1\n",
    "    \n",
    "    # Model in eval state\n",
    "    self.model.eval()\n",
    "    \n",
    "    # Inference mode\n",
    "    with torch.inference_mode():\n",
    "        psnr_file = output_dir / \"PSNR.txt\"\n",
    "        with psnr_file.open('wt') as fout:\n",
    "            fout.write(f'Sr.no.:\\tOriginal\\tInput\\t\\tOutput\\t\\tGains\\t\\tNIQE\\n---------------------------------------------------------------------------------\\n')\n",
    "            # Iterate over the Eval dataset\n",
    "            # fig, axes = plt.subplots(10,1, figsize=(20, 50))\n",
    "            for idx, batch in tqdm(enumerate(data_loader), desc=\"Evaluation Dataset\", total=len(data_loader), position=0, leave=True):\n",
    "                # inp, targ, _, _, orig = batch\n",
    "                # inp, targ, orig = inp.to(self.device), targ.to(self.device), orig.to(self.device)\n",
    "                imgs, specs = batch\n",
    "                imgs, specs = imgs.to(self.device), specs.to(self.device)\n",
    "                inp, targ, _, _, orig = self._preprocessbatch(imgs, specs,\n",
    "                                                             noisy_targets=False,\n",
    "                                                             inject_noise=False,\n",
    "                                                             **kwargs)\n",
    "                # Predict\n",
    "                denoised_op = self.model(inp)\n",
    "                \n",
    "                # Generate results and images\n",
    "                r, c = (patch_idx // patches_per_row) * step, (patch_idx % patches_per_row) * step\n",
    "                \n",
    "                original_reconst[:, r : r+patch_size, c : c+patch_size] += orig\n",
    "                denoised_reconst[:, r : r+patch_size, c : c+patch_size] += denoised_op\n",
    "                target_reconst[:, r : r+patch_size, c : c+patch_size] += targ\n",
    "                input_reconst[:, r : r+patch_size, c : c+patch_size] += inp\n",
    "                mod_count[:, r : r+patch_size, c : c+patch_size] += 1\n",
    "                patch_idx += 1\n",
    "                \n",
    "                if patch_idx == n_patches:\n",
    "                    # New Image will start from next iteration\n",
    "\n",
    "                    # Consolidate the reconstructions\n",
    "                    mod_count[mod_count == 0] = 1\n",
    "                    original_reconst /= mod_count\n",
    "                    denoised_reconst /= mod_count\n",
    "                    target_reconst /= mod_count\n",
    "                    input_reconst /= mod_count\n",
    "                    \n",
    "                    # Create 4-in-1\n",
    "                    prim = [x.squeeze(0) for x in [original_reconst, input_reconst, denoised_reconst, target_reconst]]\n",
    "                    spec = [v for _, v in (self._compute_spectral(x, magnitude=True, normalize=False) for x in prim)]\n",
    "                    pimg = torch.cat(prim, dim=1) + 0.5\n",
    "                    simg = torch.cat(spec, dim=1) * 0.05\n",
    "                    # img = torch.clip(torch.cat([pimg, simg], dim=0), 0.0, 1.0)\n",
    "                    img = torch.cat([pimg, simg], dim=0)\n",
    "\n",
    "                    # axes[img_idx-1][0].imshow(simg.detach().cpu().numpy(), cmap='gray', vmin=0, vmax=1)\n",
    "                    # axes[img_idx-1][0].set_title(img_idx)\n",
    "                    \n",
    "                    # prim = [x.squeeze(0).detach().cpu().numpy() for x in [original_reconst, input_reconst, denoised_reconst, target_reconst]]\n",
    "                    # spec = [v for _, v in (compute_spectral_image(x, magnitude=True) for x in prim)]\n",
    "                    # pimg = np.concatenate(prim, axis=1) + 0.5\n",
    "                    # simg = np.concatenate(spec, axis=1) * 0.03\n",
    "                    # img = np.clip(np.concatenate([pimg, simg], axis=0), 0, 1)\n",
    "                    \n",
    "                    # Save the current reconstruction\n",
    "                    save_image(img, output_dir / f\"final{img_idx:03d}.png\", normalize=False)\n",
    "                    save_image((torch.clip(original_reconst, -0.5, 0.5) + 0.5).cpu(), output_dir / f\"original{img_idx:03d}.png\")\n",
    "                    save_image((torch.clip(denoised_reconst, -0.5, 0.5) + 0.5).cpu(), output_dir / f\"output{img_idx:03d}.png\")\n",
    "                    save_image((torch.clip(target_reconst, -0.5, 0.5) + 0.5).cpu(), output_dir / f\"target{img_idx:03d}.png\")\n",
    "                    save_image((torch.clip(input_reconst, -0.5, 0.5) + 0.5).cpu(), output_dir / f\"input{img_idx:03d}.png\")\n",
    "                    \n",
    "                    # Calculate PSNR scores\n",
    "                    psnr_orig_vs_targ = self._psnr_scores(original_reconst, target_reconst).item()\n",
    "                    psnr_denoise_vs_targ = self._psnr_scores(denoised_reconst, target_reconst).item()\n",
    "                    psnr_input_vs_targ = self._psnr_scores(input_reconst, target_reconst).item()\n",
    "                    # niqe_score = niqe.score(torch.clip(denoised_reconst.squeeze(0), -0.5, 0.5).cpu().numpy())\n",
    "                    niqe_score = float(\"inf\")\n",
    "                    fout.write(f'{img_idx:03d}:\\t{psnr_orig_vs_targ:0.5f}\\t\\t{psnr_input_vs_targ:0.5f}\\t\\t{psnr_denoise_vs_targ:0.5f}\\t\\t{(psnr_denoise_vs_targ - psnr_orig_vs_targ):0.5f}\\t\\t{niqe_score}\\n')\n",
    "                    \n",
    "                    # Flush the image frames\n",
    "                    original_reconst *= 0.0\n",
    "                    denoised_reconst *= 0.0\n",
    "                    mod_count *= 0.0\n",
    "                    \n",
    "                    # reset indices\n",
    "                    patch_idx = 0\n",
    "                    img_idx += 1\n",
    "    \n",
    "def testing(self):\n",
    "    batch = next(iter(self.train_loader))\n",
    "    img, spec = batch\n",
    "    print(\"Initial: \", img.shape, spec.shape)\n",
    "    s = self._compute_spectral(img)\n",
    "    print(\"Spectral computed\", s.shape)\n",
    "                         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

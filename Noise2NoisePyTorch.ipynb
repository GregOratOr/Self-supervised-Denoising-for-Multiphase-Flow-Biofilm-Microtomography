{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d81c9663-7297-401d-b6d2-7709017cd13a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Library and Module Imports\n",
    "<b>Description: </b> \n",
    "    All the required packages, modules and libraries are imported here for this notebook.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69308fda-a364-4009-aff0-d6a9d07967ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import gc\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "import json\n",
    "import warnings\n",
    "import netCDF4 as nc\n",
    "from typing import Callable, List, Optional\n",
    "from pathlib import Path\n",
    "from datetime import datetime as dt\n",
    "\n",
    "# Progress Visualization\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "# import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Neural Networks\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.optim import lr_scheduler as lr_sch\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision.transforms.functional import gaussian_blur\n",
    "# Parallel training\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import init_process_group, destroy_process_group\n",
    "\n",
    "# Image Manipulation\n",
    "import scipy\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from PIL import Image\n",
    "from torchvision.utils import save_image\n",
    "from scipy.stats import kurtosis, skew\n",
    "from scipy import ndimage, special, linalg\n",
    "\n",
    "# import imageio.v3 as iio\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "\n",
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd9437c-adaf-44f6-bff0-d550429a9b06",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00944ed6-36c7-442a-8b67-a12daceb2f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def compute_spectral_image(image, ifft=False, magnitude=False, normalize=False):\n",
    "    \"\"\"\n",
    "    Computes the spectral image using the magnitude of the 2D Fourier Transform.\n",
    "    \n",
    "    Args:\n",
    "        image (numpy array): A single CT scan patch (grayscale).\n",
    "    \n",
    "    Returns:\n",
    "        spectral_image (numpy array): The spectral representation.\n",
    "    \"\"\"\n",
    "    fft_shift = None\n",
    "    if ifft:\n",
    "        fft_shift = np.fft.ifftshift(image)  # Shift zero frequency to center\n",
    "    else:\n",
    "        fft_image = np.fft.fft2(image)  # Apply 2D Fourier Transform\n",
    "        fft_shift = np.fft.fftshift(fft_image)  # Shift zero frequency to center\n",
    "    \n",
    "    if magnitude:\n",
    "        magnitude_spectrum = np.abs(fft_shift)  # Get magnitude\n",
    "        # Normalize the spectrum for consistency\n",
    "        magnitude_spectrum = np.log1p(magnitude_spectrum)  # Log scaling\n",
    "        \n",
    "        if normalize:\n",
    "            magnitude_spectrum = (magnitude_spectrum - np.min(magnitude_spectrum)) / (np.max(magnitude_spectrum) - np.min(magnitude_spectrum))  # Normalize [0,1]\n",
    "            \n",
    "        return fft_shift.astype(np.complex64), magnitude_spectrum\n",
    "    else: \n",
    "        return fft_shift.astype(np.complex64)\n",
    "\n",
    "bernoulli_mask_cache = dict()\n",
    "poisson_mask_cache = dict()\n",
    "def corrupt_data(img, spec, corruption_type=\"bspec\", **kwargs):\n",
    "    \"\"\"\n",
    "    Corrupts the image and spectral image with the given corruption_type.\n",
    "    \n",
    "    Args:\n",
    "        img (numpy array): A single CT scan patch (grayscale).\n",
    "        spectral_image (numpy array): The spectral representation.\n",
    "    \n",
    "    Returns:\n",
    "        img (numpy array): CT scan patch after corruption (grayscale).\n",
    "        spectral_image (numpy array): The corrupted spectral representation. \n",
    "        spectral_mask (numpy array): The corruption mask of spectral image.\n",
    "    \"\"\" \n",
    "    # print(img.shape, spec.shape)\n",
    "    \n",
    "    if corruption_type == \"bspec\":\n",
    "        # print(\"Bernoulli Process\")\n",
    "        p_at_edge = kwargs[\"corruption_params\"]['p_edge']\n",
    "        global bernoulli_mask_cache\n",
    "        if bernoulli_mask_cache.get(p_at_edge) is None:\n",
    "            half = [s//2 for s in spec.shape]\n",
    "            r_dist = [np.arange(s, dtype=np.float32) - h for s, h in zip(spec.shape, half)]\n",
    "            r_dist = [x ** 2 for x in r_dist]\n",
    "            r_dist = (r_dist[0][:, np.newaxis] + r_dist[1][np.newaxis, :]) ** .5 # r_dist[0]: Horizontal Component, r_dist[1]: Vertical Component\n",
    "            bernoulli_mask_probab = (p_at_edge ** (1.0/half[1])) ** r_dist\n",
    "            bernoulli_mask_cache[p_at_edge] = bernoulli_mask_probab\n",
    "            # print('Bernoulli probability at edge = %.5f' % bernoulli_mask_probab[half[0], 0])\n",
    "            # print('Average Bernoulli probability = %.5f' % np.mean(bernoulli_mask_probab))\n",
    "        mask = bernoulli_mask_cache[p_at_edge]\n",
    "        keep = (np.random.uniform(0.0, 1.0, size=spec.shape)**2 < mask)\n",
    "        keep = keep & keep[::-1, ::-1]\n",
    "        mskd_spec = spec * keep\n",
    "        spec_msk = keep.astype(np.float32)\n",
    "        spec = compute_spectral_image(mskd_spec / (mask + ~keep + 1e-8), ifft=True)\n",
    "        img = np.real(np.fft.ifft2(spec)).astype(np.float32)\n",
    "        return img, mskd_spec, spec_msk\n",
    "        \n",
    "    elif corruption_type == \"poisson\":\n",
    "        # print(\"Poisson Process\")\n",
    "        corruption_strength = kwargs[\"corruption_params\"]['poisson_strength']\n",
    "        mask = None\n",
    "        global poisson_mask_cache\n",
    "        poisson_noise = np.random.poisson(np.abs(img) * corruption_strength)/corruption_strength\n",
    "        # poisson_noise = np.clip(poisson_noise, 0, 255)\n",
    "        \n",
    "        if kwargs[\"corruption_params\"]['distribution'] == 'uniform':\n",
    "            assert kwargs[\"corruption_params\"]['mask_ratio'] is not None\n",
    "            criterion = kwargs[\"corruption_params\"]['mask_ratio']\n",
    "            \n",
    "        elif kwargs[\"corruption_params\"]['distribution'] == 'gaussian':\n",
    "            assert kwargs[\"corruption_params\"]['sigma'] is not None\n",
    "            criterion = gaussian_mask(img.shape, kwargs[\"corruption_params\"]['sigma'])\n",
    "        \n",
    "        if poisson_mask_cache.get((kwargs[\"corruption_params\"]['distribution'], criterion)) is None:\n",
    "            mask = np.random.uniform(0, 1, size=img.shape) < criterion\n",
    "            mask = mask.astype(np.float32)\n",
    "            poisson_mask_cache[(kwargs[\"corruption_params\"]['distribution'], criterion)] = mask\n",
    "        else:\n",
    "            mask = poisson_mask_cache[(kwargs[\"corruption_params\"]['distribution'], criterion)].astype(np.float32)\n",
    "            \n",
    "        img = np.where(mask, poisson_noise, img)\n",
    "        spec = compute_spectral_image(img)\n",
    "        return img, spec, mask\n",
    "        \n",
    "    else:\n",
    "        # Not a valid corruption/No corruption\n",
    "        print(\"No Corruption\")\n",
    "        return img, spec, np.ones_like(img)\n",
    "        \n",
    "augment_translate_cache = dict()\n",
    "def augment_data(img, spec, params):\n",
    "    t = params.get('translate', 0)\n",
    "    if t > 0:\n",
    "        global augment_translate_cache\n",
    "        trans = np.random.randint(-t, t + 1, size=(2,))\n",
    "        key = (trans[0], trans[1])\n",
    "        if key not in augment_translate_cache:\n",
    "            x = np.zeros_like(img)\n",
    "            x[trans[0], trans[1]] = 1.0\n",
    "            augment_translate_cache[key] = compute_spectral_image(x)\n",
    "        img = np.roll(img, trans, axis=(0, 1))\n",
    "        spec = spec * augment_translate_cache[key]\n",
    "    return img.astype(np.float32), spec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbf9c9d-15e6-476c-bba6-bb8843ed5cea",
   "metadata": {},
   "source": [
    "# Dataset Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b7ee0d-824d-439a-91e3-b1f3b79cc193",
   "metadata": {},
   "source": [
    "## Dataset Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d425583-800a-4b11-a405-f45225283278",
   "metadata": {},
   "outputs": [],
   "source": [
    "isHQ = 1 # 0:LQ ; 1:HQ ; 2:Bio\n",
    "fullDataset=False  # If False, provide the custom dir name. \"TrainScans\" - Placeholder\n",
    "\n",
    "if isHQ == 0:\n",
    "    active_dataset = \"LQ_Mphase\"\n",
    "elif isHQ == 1:\n",
    "    active_dataset = \"HQ_Mphase\"\n",
    "elif isHQ == 2:\n",
    "    active_dataset = \"Biofilm\"\n",
    "else:\n",
    "    raise ValueError(\"Invalid dataset selection.\")\n",
    "    \n",
    "dataset_root_dir = Path(\"../Datasets\") / active_dataset\n",
    "ds_dir = Path(\"datasets\")\n",
    "\n",
    "\n",
    "dataset_scans_folder = dataset_root_dir / (\"tomo_RMG_nc\" if fullDataset else \"TrainScans\")\n",
    "print(f\"Original Dataset Root: [ {dataset_root_dir} ]\")\n",
    "print(f\"Dataset .nc Scans: [ {dataset_scans_folder} ]\")\n",
    "print(f\"Dataset .pth Files: [ {ds_dir} ]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f45ce0-f246-4a12-a1f9-6117c1e25760",
   "metadata": {},
   "source": [
    "## Dataset Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1d002b-78c7-4805-92e1-3de74f2c57aa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Scan files to Images\n",
    "\n",
    "<b>Description:</b> The following code block reads x-ray scans(.nc files) and generates grayscale images for each vertical resolution/slice(.png Images).\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c629f-13ef-474c-9ce1-84866d4e9ba3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def nc_to_img(dataset_path, output_path, crop=False, **kwargs):\n",
    "    \n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    global_slice_idx = 0\n",
    "    block_pths = dataset_path.glob(\"*.nc\")\n",
    "\n",
    "    # Set min and max thresholds for the range of important values. [Clamping values to rescale the spectrum]\n",
    "    # For Phase3 dataset: [9083, 16500]\n",
    "    # For Biofilm dataset: [10750, 21800] \n",
    "    min_val = 10750 #np.iinfo(np.uint16).min # -24368\n",
    "    max_val = 21800 #np.iinfo(np.uint16).max # -14468 \n",
    "    diff = float(max_val - min_val)\n",
    "\n",
    "    for block_pth in tqdm(sorted(block_pths), desc=\"Blocks\", leave=True, position=0):\n",
    "        scan_data = None\n",
    "        \n",
    "        with nc.Dataset(block_pth, 'r') as block:\n",
    "            scan_data = block.variables['tomo'][:]\n",
    "            \n",
    "        # print(f\"Scan Data Shape: {scan_data.shape}\")\n",
    "        n_slices, H, W = scan_data.shape\n",
    "        \n",
    "        for slice_idx in tqdm(range(n_slices), desc=f'Slices [Block: {block_pth.name}]', leave=False, position=1):\n",
    "            # Extract the slice\n",
    "            if crop:\n",
    "                img_size = kwargs.get(\"imgsize\", 1352)\n",
    "                left_col, top_row = kwargs.get(\"origin\", (635, 522))\n",
    "                slice_data = scan_data[slice_idx, top_row:top_row + img_size, left_col:left_col + img_size]\n",
    "            else:\n",
    "                slice_data = scan_data[slice_idx, :, :]\n",
    "            \n",
    "            # Normalize all data values to the range [0, 255].\n",
    "            slice_data = slice_data.astype('uint16')\n",
    "            slice_data = slice_data.astype('float64')\n",
    "            slice_data = np.clip(slice_data, min_val, max_val)\n",
    "            slice_data = ((slice_data - min_val)/diff) * 255.0\n",
    "            slice_data = slice_data.astype(np.uint8)  # Ensure the data is in uint8 format (0-255)\n",
    "            \n",
    "            img = Image.fromarray(slice_data)\n",
    "            \n",
    "            # Ensure Grayscale\n",
    "            img = img.convert('L')\n",
    "\n",
    "            # Rescale the image dims (Not required)\n",
    "            # img = img.resize((1024, 1024), Image.LANCZOS)\n",
    "            # img = img.resize((512, 512), Image.LANCZOS)\n",
    "            # img = img.resize((256, 256), Image.LANCZOS)\n",
    "\n",
    "            # Generate the image name and save it\n",
    "            save_path = output_path / f\"{global_slice_idx :06d}.png\"\n",
    "            img.save(save_path)\n",
    "            \n",
    "            global_slice_idx += 1\n",
    "    \n",
    "            # print(f\"Saved {slice_filename} from {block_filename}\")\n",
    "        print(f\"Saved All Slices from {block_pth.name}\")\n",
    "            \n",
    "    print(\"All slices have been saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ae7b55-1082-45db-bb80-b00a18c6748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_pth = dataset_root_dir / \"Images\"\n",
    "# print(output_pth)\n",
    "\n",
    "# nc_to_img(dataset_scans_folder, output_pth, crop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff3fdbc-421c-4154-acd9-401da541d33b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Images to Patches\n",
    "\n",
    "<b>Description:</b> This code block creates patches from a larger image in sequential order.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70b92d8-a83f-4612-8975-20097c238934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches(img, patch_size=255, overlap=0.5, threshold=0):\n",
    "    step = int(patch_size * (1 - overlap))\n",
    "    patches = []\n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    for i in range(0, h - patch_size + 1, step):\n",
    "        for j in range(0, w - patch_size + 1, step):\n",
    "            patch = img[i:i + patch_size, j:j + patch_size]\n",
    "            variance = np.var(patch)\n",
    "            if variance >= threshold:\n",
    "                patches.append(patch)\n",
    "\n",
    "        if (w - patch_size) % step != 0:\n",
    "            j = w - patch_size\n",
    "            patch = img[i:i + patch_size, j:j + patch_size]\n",
    "            variance = np.var(patch)\n",
    "            if variance >= threshold:\n",
    "                patches.append(patch)\n",
    "    \n",
    "    # Add bottom row patches (bottom edge)\n",
    "    if (h - patch_size) % step != 0:\n",
    "        i = h - patch_size\n",
    "        for j in range(0, w - patch_size + 1, step):\n",
    "            patch = img[i:i + patch_size, j:j + patch_size]\n",
    "            variance = np.var(patch)\n",
    "            if variance >= threshold:\n",
    "                patches.append(patch)\n",
    "\n",
    "        # Also add the bottom-right corner patch\n",
    "        if (w - patch_size) % step != 0:\n",
    "            j = w - patch_size\n",
    "            patch = img[i:i + patch_size, j:j + patch_size]\n",
    "            variance = np.var(patch)\n",
    "            if variance >= threshold:\n",
    "                patches.append(patch)\n",
    "       \n",
    "    return patches\n",
    "\n",
    "def load_images_for_patching(src_path:Path, dst_path:Path, patch_size=255, overlap=0.5, threshold=0):\n",
    "    \n",
    "    dst_path.mkdir(parents=True, exist_ok=True)\n",
    "    imgs_pths = src_path.glob(\"*.png\")\n",
    "    \n",
    "    global_patch_idx = 0\n",
    "    img_idx = 0\n",
    "\n",
    "    for img_pth in tqdm(sorted(imgs_pths), desc=\"Images\", leave=True, position=0):\n",
    "        img = None\n",
    "        try:\n",
    "            img = Image.open(img_pth).convert('L')\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: Image file not found at {img_pth}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "        patches = extract_patches(np.array(img), patch_size=patch_size, overlap=overlap, threshold=threshold)\n",
    "        \n",
    "        # Save Patches\n",
    "        for patch in tqdm(patches, desc=\"Patches\", leave=False, position=1):\n",
    "            save_path = dst_path / f\"{global_patch_idx :08d}.png\"\n",
    "            p = Image.fromarray(patch)\n",
    "            p.save(save_path)\n",
    "            global_patch_idx += 1\n",
    "\n",
    "        img_idx += 1\n",
    "\n",
    "    print(f\"Total Patches: {global_patch_idx}\")\n",
    "    print(f\"All patches saved to - {dst_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f887536e-4ffc-44bb-ab86-cb536ba9630c",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 512\n",
    "overlap = 0.2\n",
    "threshold = 0\n",
    "\n",
    "src_image_folder = \"evalImgs\"\n",
    "dst_patch_folder = \"eval\"\n",
    "src_pth = dataset_root_dir / src_image_folder\n",
    "dst_pth = dataset_root_dir / (dst_patch_folder + f\"_patches_{str(patch_size)}_olap_{overlap}\")\n",
    "print(f\"Source: [ {src_pth} ]\")\n",
    "print(f\"Destination: [ {dst_pth} ]\")\n",
    "\n",
    "# load_images_for_patching(src_path=src_pth, dst_path=dst_pth, patch_size=patch_size, overlap=overlap, threshold=threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48ef79c-d4fe-454f-8081-eb8ae26888f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df7ff4f-85a6-4ff4-935d-430d9df5220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with just img and spec\n",
    "class CTScans(Dataset):\n",
    "    def __init__(self, images, spectrals):    \n",
    "        self.images = images.astype(np.float32)\n",
    "        self.spectrals = spectrals.astype(np.complex64)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.spectrals[idx]\n",
    "        \n",
    "def create_dataset(images_path=Path(\"\")):\n",
    "    file_paths = sorted([f for f in images_path.iterdir() if f.suffix == \".png\"])\n",
    "    if not file_paths:\n",
    "        raise ValueError(f\"No PNG files found at - {str(images_path)}\")\n",
    "\n",
    "    print(f\"Source Images Path - {images_path}\")\n",
    "    temp_img = np.array(Image.open(file_paths[0]).convert(\"L\"))\n",
    "    H, W = temp_img.shape\n",
    "    L = len(file_paths)\n",
    "    \n",
    "    imgs = np.zeros((L, H, W), dtype=np.float32)\n",
    "    specs = np.zeros((L, H, W), dtype=np.complex64)\n",
    "    \n",
    "    for idx, file_path in tqdm(enumerate(file_paths), total=len(file_paths), desc=\"Images\"):\n",
    "        imgs[idx] = (np.array(Image.open(file_path).convert(\"L\"), dtype=np.float32) / 255.0) - 0.5\n",
    "        specs[idx] = compute_spectral_image(imgs[idx])\n",
    "\n",
    "    return CTScans(imgs, specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ed1abc-9a3c-4727-b44e-d07e44268ab4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef73db2-b555-4971-aa6d-67701dba4855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating datasets\n",
    "dataset_create = False\n",
    "save_dataset = False\n",
    "\n",
    "patches = True\n",
    "patch_size = 512\n",
    "overlap = 0.2\n",
    "\n",
    "train_dataset = None\n",
    "valid_dataset = None\n",
    "eval_dataset = None\n",
    "\n",
    "img_count = {0:100, 1:20, 2:10, 3:10} # Number of images for training, validation, and evaluation, respectively.\n",
    "\n",
    "dataset_types = [3] # 0:train | 1:validation | 2:evaluation | 3:cropped eval \n",
    "dset_type = {0:\"train\", 1:\"valid\", 2:\"eval\", 3:\"evalC\"}\n",
    "\n",
    "if dataset_create:\n",
    "    if patches:\n",
    "        # Create Patch Datasets\n",
    "        for dstp in dataset_types:\n",
    "            dataset = create_dataset(images_path=dataset_root_dir / f\"{dset_type.get(dstp)}_patches_{str(patch_size)}_olap_{str(overlap)}\")\n",
    "            if save_dataset:\n",
    "                torch.save(dataset, ds_dir / f\"HQ_{dset_type.get(dstp)}_dataset_{img_count.get(dstp)}_patch_{str(patch_size)}_olap_{str(overlap)}.pth\", pickle_protocol=5)\n",
    "            dataset = None\n",
    "    else:\n",
    "        # Create Full Image Datasets\n",
    "        train_dataset = create_dataset(images_path=dataset_root_dir / \"trainImgs\")\n",
    "        valid_dataset = create_dataset(images_path=dataset_root_dir / \"validImgs\")\n",
    "        eval_dataset = create_dataset(images_path=dataset_root_dir / \"evalImgs\")\n",
    "        if save_dataset:\n",
    "            torch.save(train_dataset, ds_dir / \"HQ_train_full_img.pth\", pickle_protocol=5)\n",
    "            torch.save(valid_dataset, ds_dir / \"HQ_valid_full_img.pth\", pickle_protocol=5)\n",
    "            torch.save(eval_dataset, ds_dir / \"HQ_eval_full_img.pth\", pickle_protocol=5)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2582dcef-b977-42fa-8452-0388602715c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be2c2ba-5207-46dd-91f6-d567b790face",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = True\n",
    "patch_size = 512\n",
    "overlap = 0.2\n",
    "img_count = {0:100, 1:20, 2:10, 3:10} # Number of images for training, validation, and evaluation, respectively.\n",
    "\n",
    "if train_dataset is None or valid_dataset is None or eval_dataset is None: \n",
    "    if patches:\n",
    "        # Patch Dataset\n",
    "        train_dataset = torch.load(ds_dir / f\"HQ_train_dataset_{img_count.get(0)}_patch_{str(patch_size)}_olap_{str(overlap)}.pth\", weights_only=False)\n",
    "        valid_dataset = torch.load(ds_dir / f\"HQ_valid_dataset_{img_count.get(1)}_patch_{str(patch_size)}_olap_{str(overlap)}.pth\", weights_only=False)\n",
    "        eval_dataset = torch.load(ds_dir / f\"HQ_eval_dataset_{img_count.get(2)}_patch_{str(patch_size)}_olap_{str(overlap)}.pth\", weights_only=False)\n",
    "    else:    \n",
    "        # Full sized Image Datasets\n",
    "        train_dataset = torch.load(ds_dir / \"HQ_train_full_img.pth\", weights_only=False)\n",
    "        valid_dataset = torch.load(ds_dir / \"HQ_valid_full_img.pth\", weights_only=False)\n",
    "        eval_dataset = torch.load(ds_dir / \"HQ_eval_full_img.pth\", weights_only=False)\n",
    "        # valid_dataset = train_dataset # For testing only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81932053-af93-4ec8-b8fc-7655977e9857",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Visualize Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff723ce-4777-4d81-b914-0573ff1a52af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs an Update\n",
    "#                                                            Visualize a Sample from the Dataset\n",
    "#\n",
    "def visualize_dataset(train_dataset, valid_dataset):\n",
    "    tr_inp, tr_targ, tr_sp, tr_msk, tr_orig = next(iter(train_dataset))\n",
    "    va_inp, va_targ, va_sp, va_msk, va_orig = next(iter(valid_dataset))\n",
    "    \n",
    "    # print(tr_inp.dtype, tr_targ.dtype, tr_sp.dtype, tr_msk.dtype, tr_orig.dtype)\n",
    "    # print(va_inp.dtype, va_targ.dtype, va_sp.dtype, va_msk.dtype, va_orig.dtype)\n",
    "    \n",
    "    fig, axes = plt.subplots(2,5, figsize=(25,10))\n",
    "    \n",
    "    # Training Dataset\n",
    "    axes[0][0].imshow(tr_orig, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[0][0].set_title(\"Original\")\n",
    "    \n",
    "    axes[0][1].imshow(tr_inp, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[0][1].set_title(\"Input\")\n",
    "    \n",
    "    axes[0][2].imshow(tr_targ, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[0][2].set_title(\"Target\")\n",
    "    \n",
    "    axes[0][3].imshow(np.log1p(np.abs(tr_sp)), cmap='inferno')\n",
    "    axes[0][3].set_title(\"Input's Spectral\")\n",
    "    \n",
    "    axes[0][4].imshow(tr_msk, cmap='gray')\n",
    "    axes[0][4].set_title(\"Spectral Mask\")\n",
    "    \n",
    "    # Validation Dataset\n",
    "    axes[1][0].imshow(va_orig, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[1][0].set_title(\"Original\")\n",
    "    \n",
    "    axes[1][1].imshow(va_inp, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[1][1].set_title(\"Input\")\n",
    "    \n",
    "    axes[1][2].imshow(va_targ, cmap='gray', vmin=0, vmax=1)\n",
    "    axes[1][2].set_title(\"Target\")\n",
    "    \n",
    "    axes[1][3].imshow(np.log1p(np.abs(va_sp)), cmap='inferno')\n",
    "    axes[1][3].set_title(\"Inputs's Spectral\")\n",
    "    \n",
    "    axes[1][4].imshow(va_msk, cmap='gray')\n",
    "    axes[1][4].set_title(\"Spectral Mask\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "assert train_dataset is not None and valid_dataset is not None, \"Training Dataset and Validation Dataset should not be None\"\n",
    "# visualize_dataset(train_dataset, valid_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd830da3-a2ba-4fb1-9117-5c95f1ec4228",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9f0fe8-e1b3-4c83-898b-d2f7a7b0c7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLayer(nn.Module):\n",
    "    def __init__(self, n_ip, n_out, kernel_size=3, gain=torch.sqrt(torch.tensor(2, dtype=torch.float32)), bias=True):\n",
    "        super(ConvLayer, self).__init__()\n",
    "\n",
    "        wstd = gain / torch.sqrt(torch.prod(torch.tensor([kernel_size, kernel_size , n_ip], dtype=torch.float32)))\n",
    "        self.conv = nn.Conv2d(in_channels=n_ip, out_channels=n_out, kernel_size=kernel_size, padding=kernel_size//2, stride=1, bias=bias)\n",
    "        # Initialize weights\n",
    "        nn.init.normal_(self.conv.weight, mean=0.0, std=wstd)\n",
    "        # Initialize Bias\n",
    "        nn.init.zeros_(self.conv.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "    \n",
    "class UpsampleLayer(nn.Module):\n",
    "    def __init__(self, scale_factor=2):\n",
    "        super(UpsampleLayer, self).__init__()\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Tensor structure: [batch_size, channels, height, width]\n",
    "        # return x.repeat_interleave(self.scale_factor, dim=2).repeat_interleave(self.scale_factor, dim=3) # tile across dim=2 (height) and 3(width)\n",
    "        return F.interpolate(x, scale_factor=self.scale_factor, mode='nearest')\n",
    "\n",
    "class DownsampleLayer(nn.Module):\n",
    "    def __init__(self, scale_factor=2):\n",
    "        super(DownsampleLayer, self).__init__()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=scale_factor, stride=scale_factor, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pool(x)\n",
    "    \n",
    "class Concat(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Concat, self).__init__()\n",
    "        \n",
    "    def forward(self, layers):\n",
    "        return torch.cat(layers, dim=1)\n",
    "        \n",
    "class LeakyReLU(nn.Module):\n",
    "    def __init__(self, negative_slope=0.1):\n",
    "        super(LeakyReLU, self).__init__()\n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope=negative_slope)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.leaky_relu(x)\n",
    "        \n",
    "class Noise2Noise(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Noise2Noise, self).__init__()\n",
    "        self.enc_conv0 = ConvLayer(1, 48)\n",
    "        self.enc_conv1 = ConvLayer(48, 48)\n",
    "        self.pool1 = DownsampleLayer() # 24\n",
    "        \n",
    "        self.enc_conv2 = ConvLayer(48, 48)\n",
    "        self.pool2 = DownsampleLayer() # 24\n",
    "        \n",
    "        self.enc_conv3 = ConvLayer(48, 48)\n",
    "        self.pool3 = DownsampleLayer() # 24\n",
    "        \n",
    "        self.enc_conv4 = ConvLayer(48, 48)\n",
    "        self.pool4 = DownsampleLayer() # 24\n",
    "        \n",
    "        self.enc_conv5 = ConvLayer(48, 48)\n",
    "        self.pool5 = DownsampleLayer() # 24\n",
    "        \n",
    "        self.enc_conv6 = ConvLayer(48, 48)\n",
    "        \n",
    "        self.upsample5 = UpsampleLayer() # 48\n",
    "        self.concat5 = Concat()\n",
    "        self.dec_conv5 = ConvLayer(96, 96)\n",
    "        self.dec_conv5b = ConvLayer(96, 96)\n",
    "        \n",
    "        self.upsample4 = UpsampleLayer() # 96\n",
    "        self.concat4 = Concat()\n",
    "        self.dec_conv4 = ConvLayer(144, 96)\n",
    "        self.dec_conv4b = ConvLayer(96, 96)\n",
    "        \n",
    "        self.upsample3 = UpsampleLayer() # 96\n",
    "        self.concat3 = Concat()\n",
    "        self.dec_conv3 = ConvLayer(144, 96)\n",
    "        self.dec_conv3b = ConvLayer(96, 96)\n",
    "        \n",
    "        self.upsample2 = UpsampleLayer() # 96\n",
    "        self.concat2 = Concat()\n",
    "        self.dec_conv2 = ConvLayer(144, 96)\n",
    "        self.dec_conv2b = ConvLayer(96, 96)\n",
    "        \n",
    "        self.upsample1 = UpsampleLayer() # 96\n",
    "        self.concat1 = Concat()\n",
    "        self.dec_conv1a = ConvLayer(96 + 1, 64)\n",
    "        self.dec_conv1b = ConvLayer(64, 32)\n",
    "        \n",
    "        self.dec_conv1 = ConvLayer(32, 1, gain=1.0)\n",
    "\n",
    "    def pad_to_multiple(self, x, multiple=64):\n",
    "        h, w = x.shape[-2:]\n",
    "        pad_h = (multiple - h % multiple) % multiple\n",
    "        pad_w = (multiple - w % multiple) % multiple\n",
    "    \n",
    "        pad_top = pad_h // 2\n",
    "        pad_bottom = pad_h - pad_top\n",
    "        pad_left = pad_w // 2\n",
    "        pad_right = pad_w - pad_left\n",
    "    \n",
    "        padding = (pad_left, pad_right, pad_top, pad_bottom)  # (left, right, top, bottom)\n",
    "        x_padded = F.pad(x, padding, mode='reflect')\n",
    "        return x_padded, padding\n",
    "\n",
    "    def unpad(self, x, padding):\n",
    "        pad_left, pad_right, pad_top, pad_bottom = padding\n",
    "        return x[..., pad_top : x.shape[-2] - pad_bottom,\n",
    "                     pad_left : x.shape[-1] - pad_right]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # padded = False\n",
    "        # if int(x.shape[-1])%2 == 1:\n",
    "        #     x = F.pad(x, (0, 1, 0, 1), \"constant\", -0.5)\n",
    "        #     padded = True\n",
    "        # x = F.pad(x, (0, 1, 0, 1), \"constant\", -0.5)\n",
    "\n",
    "        x, padding = self.pad_to_multiple(x, multiple=64)\n",
    "        \n",
    "        input = x.unsqueeze(1)\n",
    "        \n",
    "        x = F.leaky_relu(self.enc_conv0(input), 0.1)\n",
    "        x = F.leaky_relu(self.enc_conv1(x), 0.1)\n",
    "        x = self.pool1(x)\n",
    "        pool1 = x\n",
    "        \n",
    "        x = F.leaky_relu(self.enc_conv2(pool1), 0.1)\n",
    "        x = self.pool2(x)\n",
    "        pool2 = x\n",
    "        \n",
    "        x = F.leaky_relu(self.enc_conv3(pool2), 0.1)\n",
    "        x = self.pool3(x)\n",
    "        pool3 = x\n",
    "        \n",
    "        x = F.leaky_relu(self.enc_conv4(pool3), 0.1)\n",
    "        x = self.pool4(x)\n",
    "        pool4 = x\n",
    "        \n",
    "        x = F.leaky_relu(self.enc_conv5(pool4), 0.1)\n",
    "        x = self.pool5(x)\n",
    "        pool5 = x\n",
    "        x = F.leaky_relu(self.enc_conv6(x), 0.1)\n",
    "        \n",
    "        x = self.upsample5(x)\n",
    "        x = self.concat5([x, pool4])\n",
    "        x = F.leaky_relu(self.dec_conv5(x), 0.1)\n",
    "        x = F.leaky_relu(self.dec_conv5b(x), 0.1)\n",
    "        \n",
    "        x = self.upsample4(x)\n",
    "        x = self.concat4([x, pool3])\n",
    "        x = F.leaky_relu(self.dec_conv4(x), 0.1)\n",
    "        x = F.leaky_relu(self.dec_conv4b(x), 0.1)\n",
    "        \n",
    "        x = self.upsample3(x)\n",
    "        x = self.concat3([x, pool2])\n",
    "        x = F.leaky_relu(self.dec_conv3(x), 0.1)\n",
    "        x = F.leaky_relu(self.dec_conv3b(x), 0.1)\n",
    "        \n",
    "        x = self.upsample2(x)\n",
    "        x = self.concat2([x, pool1])\n",
    "        x = F.leaky_relu(self.dec_conv2(x), 0.1)\n",
    "        x = F.leaky_relu(self.dec_conv2b(x), 0.1)\n",
    "        \n",
    "        x = self.upsample1(x)\n",
    "        x = self.concat1([x, input])\n",
    "        x = F.leaky_relu(self.dec_conv1a(x), 0.1)\n",
    "        x = F.leaky_relu(self.dec_conv1b(x), 0.1)\n",
    "        \n",
    "        x = self.dec_conv1(x)\n",
    "        # if padded:\n",
    "        #     x = x[:, : , :-1, :-1]\n",
    "        x = self.unpad(x, padding)\n",
    "        \n",
    "        return x.squeeze(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bafce3-1da7-4fb6-85d5-29e5b6ee0b7f",
   "metadata": {},
   "source": [
    "# The Execution Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f296f55f-45ce-4145-ac97-a3b456d3ed34",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Trainer Class\n",
    "<b>Description: </b> \n",
    "    This class will contain functions for the model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab7b0cb-5164-4aee-a2da-27422ad20eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Trainer Class\n",
    "#\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self,\n",
    "            gpu_id: int,\n",
    "            model: torch.nn.Module,\n",
    "            train_data: Dataset,\n",
    "            valid_data: Dataset,\n",
    "            optimizer: torch.optim.Optimizer,\n",
    "            loss_fn: Callable,\n",
    "            experiment_id: int,\n",
    "            scheduler: Optional[torch.optim.lr_scheduler._LRScheduler] = None,\n",
    "            save_interval: int = 10,\n",
    "            batch_size: int = 32,\n",
    "            load_checkpoint: bool = False,\n",
    "            **kwargs) -> None:\n",
    "        self.device = gpu_id\n",
    "        self.model = model.to(gpu_id)\n",
    "        self.train_data = train_data\n",
    "        self.valid_data = valid_data\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler if scheduler else torch.optim.lr_scheduler.ConstantLR(optimizer, factor=1.0, total_iters=1)\n",
    "        self.loss_fn = loss_fn\n",
    "        self.experiment_id = experiment_id\n",
    "        self.save_interval = save_interval\n",
    "        self.batch_size = batch_size\n",
    "        self.init_kwargs = kwargs\n",
    "        self.experiment_desc = kwargs.get(\"experiment_desc\", \"\")\n",
    "        self.post_op = kwargs.get(\"post_op\", None)\n",
    "        self.load_checkpoint = load_checkpoint\n",
    "        self.snapshot_path = kwargs.get(\"snapshot_path\", Path(\".\"))\n",
    "        self.snapshot_name = kwargs.get(\"snapshot_name\", Path(\"latest-snapshot\"))\n",
    "        self.final_epoch = kwargs.get('final_epoch', False)\n",
    "        self.max_epochs = kwargs.get(\"max_epochs\", 300)\n",
    "        self.results_dir = kwargs.get(\"results_dir\", self.get_results_dir())\n",
    "        self.start_epoch = 0\n",
    "        self.epoch = 0\n",
    "        self.corruption_masks = {}\n",
    "        self.augment_translate_cache = {}\n",
    "        self.train_loader = None\n",
    "        self.valid_loader = None\n",
    "        self.training_test_path = self.results_dir / \"Training Tests\"\n",
    "        self.validation_test_path = self.results_dir / \"Post Training Validation Tests\"\n",
    "        self.evaluation_test_path = self.results_dir / \"Evaluation Tests\"\n",
    "        # Make Required Directories\n",
    "        self.training_test_path.mkdir(parents=True, exist_ok=True)\n",
    "        self.validation_test_path.mkdir(parents=True, exist_ok=True)\n",
    "        self.evaluation_test_path.mkdir(parents=True, exist_ok=True)\n",
    "        if str(self.snapshot_path) == \".\":\n",
    "            self.snapshot_path = self.results_dir / \"Snapshots\"\n",
    "        if self.load_checkpoint:\n",
    "            self._load_snapshot()\n",
    "        # Logging Setup\n",
    "        self.writer = SummaryWriter(log_dir=str(self.results_dir))\n",
    "        self.logger = self.Logger(str(self.results_dir / \"log.txt\"))\n",
    "    \n",
    "    class Logger(object):\n",
    "        '''\n",
    "        A Logger class that directs all the calls to standard output stream to a log file.\n",
    "        '''\n",
    "        def __init__(self, filepath):\n",
    "            self.terminal = sys.stdout\n",
    "            self.log = open(filepath, \"a\", buffering=1)  # Line-buffered\n",
    "\n",
    "        def __enter__(self):\n",
    "            sys.stdout = self\n",
    "            return self\n",
    "\n",
    "        def __exit__(self, exception_type, exception_value, exception_traceback):\n",
    "            if self.log:\n",
    "                self.log.close()\n",
    "            sys.stdout = sys.__stdout__\n",
    "\n",
    "        def __del__(self):\n",
    "            \"\"\"Ensure log file is closed when Logger object is deleted.\"\"\"\n",
    "            if self.log:\n",
    "                self.log.close()\n",
    "        \n",
    "        def write(self, message):\n",
    "            self.terminal.write(message)\n",
    "            self.log.write(message)\n",
    "        \n",
    "        def flush(self):\n",
    "            self.terminal.flush()\n",
    "            self.log.flush()\n",
    "\n",
    "        def start(self):\n",
    "            sys.stdout = self\n",
    "        \n",
    "        def stop(self):\n",
    "            if self.log:\n",
    "                self.log.close()\n",
    "            sys.stdout = sys.__stdout__\n",
    "    \n",
    "    def get_results_dir(self, idx=0):\n",
    "        '''\n",
    "        Generates a unique address path for results directory for a new run.\n",
    "        \n",
    "        Args:\n",
    "            [Optional] idx (int): Starting index for the counting.\n",
    "        \n",
    "        Returns:\n",
    "            results_dir (Path): Path object with a uniquely indexed path.\n",
    "        '''\n",
    "        root = Path(\"results\")\n",
    "        if self.experiment_desc != \"\": \n",
    "            root /= f\"{self.experiment_id:03d}-{self.experiment_desc}\"\n",
    "        else:\n",
    "            root /= f\"{self.experiment_id:03d}\"\n",
    "\n",
    "        chk_dir = root / f\"run-{idx}_{dt.now().strftime('%Y-%m-%d')}\"\n",
    "        \n",
    "        while chk_dir.is_dir():\n",
    "            idx += 1\n",
    "            chk_dir = root / f\"run-{idx}_{dt.now().strftime('%Y-%m-%d')}\"\n",
    "        return chk_dir\n",
    "    \n",
    "    def _save_snapshot(self):\n",
    "        \"\"\"\n",
    "        This function saves a snapshot of current training model and optimizer dict parameters along with the current epoch.\n",
    "        \"\"\"\n",
    "        self.snapshot_path.mkdir(parents=True, exist_ok=True)\n",
    "        snapshot = {}\n",
    "        snapshot[\"STATE_DICT\"] = self.model.state_dict()\n",
    "        snapshot[\"CURR_EPOCH\"] = self.epoch\n",
    "        snapshot[\"OPTIMIZER_DICT\"] = self.optimizer.state_dict()\n",
    "        torch.save(snapshot, self.snapshot_path / \"latest-snapshot.pth\")\n",
    "        torch.save(snapshot, self.snapshot_path / f\"snapshot-{self.epoch:03d}.pth\")\n",
    "        print(f\"Epoch {self.epoch}:\\n\\t Training Snapshot Saved at as [snapshot-{self.epoch:03d}.pth] at {self.snapshot_path} \\n\\t Latest Snapshot Updated!\")\n",
    "        \n",
    "    def _load_snapshot(self):\n",
    "        '''\n",
    "        This function loads a snapshot of the model with a given snapshot_name from the provided snapshot_path.\n",
    "        Loads the latest-snapshot.pth from default location if no snapshot_name is provided.\n",
    "        '''\n",
    "        path = self.snapshot_path / (str(self.snapshot_name) + \".pth\")\n",
    "        assert path.exists()\n",
    "        \n",
    "        snapshot = torch.load(path, weights_only=True)\n",
    "        self.model.load_state_dict(snapshot[\"STATE_DICT\"])\n",
    "        self.start_epoch = snapshot[\"CURR_EPOCH\"]\n",
    "        self.optimizer.load_state_dict(snapshot[\"OPTIMIZER_DICT\"])\n",
    "        print(f\"Loading Snapshot: %s.pth | Current Epoch: %d\"%(self.snapshot_name, self.start_epoch))\n",
    "    \n",
    "    def _post_op(self, op_type, denoised, spec_value, spec_mask):\n",
    "        '''\n",
    "        Performs the post-operation procedure of forcing known frequencies before the training.\n",
    "\n",
    "        Args:\n",
    "            op_type (str): Type of post-op requested.\n",
    "            denoised (Tensor: float): The image to perform post-op on.\n",
    "            spec_value (Tensor: complex): The spectral representation of the image.\n",
    "            spec_mask (Tensor: float): The mask used for post-op in spectral domain.\n",
    "            \n",
    "        Returns:\n",
    "            denoised (Tensor: float): The image after post-op is performed.\n",
    "        '''\n",
    "        if op_type =='fspec':\n",
    "            # print(\"Force denoised spectrum to known values.\")\n",
    "            # FFT\n",
    "            denoised_spec = torch.fft.fft2(denoised)     \n",
    "            # FFT shift\n",
    "            denoised_spec = torch.fft.fftshift(denoised_spec)\n",
    "            # Ensure correct dtypes and device\n",
    "            spec_value = spec_value.to(denoised_spec.dtype).to(denoised_spec.device)\n",
    "            spec_mask = spec_mask.to(denoised_spec.dtype).to(denoised_spec.device)\n",
    "            # Force known frequencies using mask\n",
    "            denoised_spec = spec_value * spec_mask + denoised_spec * (1. - spec_mask)\n",
    "            # Shift back and IFFT\n",
    "            denoised = torch.fft.ifft2(torch.fft.ifftshift(denoised_spec)).real\n",
    "        elif op_type =='fspec_old':\n",
    "            def fftshift3d(x, ifft=False):\n",
    "                '''\n",
    "                Performs a mannual Fast Fourier Shift over a 3D tensor.\n",
    "                '''\n",
    "                assert len(x.shape) == 3\n",
    "                s0 = (x.shape[-2] // 2) + (0 if ifft else 1)\n",
    "                s1 = (x.shape[-1] // 2) + (0 if ifft else 1)\n",
    "                x = torch.cat([x[:, s0:, :], x[:, :s0, :]], dim=1)\n",
    "                x = torch.cat([x[:, :, s1:], x[:, :, :s1]], dim=2)\n",
    "                return x\n",
    "            \n",
    "            # print(\"Force denoised spectrum to known values.\")\n",
    "            # FFT\n",
    "            denoised_spec = torch.fft.fft2(denoised)     \n",
    "            # FFT shift\n",
    "            denoised_spec = fftshift3d(denoised_spec, ifft=False)\n",
    "            # Ensure correct dtypes and device\n",
    "            spec_value = spec_value.to(denoised_spec.dtype).to(denoised_spec.device)\n",
    "            spec_mask = spec_mask.to(denoised_spec.dtype).to(denoised_spec.device)\n",
    "            # Force known frequencies using mask\n",
    "            denoised_spec = spec_value * spec_mask + denoised_spec * (1. - spec_mask)\n",
    "            # Shift back and IFFT\n",
    "            denoised = torch.fft.ifft2(fftshift3d(denoised_spec, ifft=True)).real\n",
    "        else:\n",
    "            warnings.warn(\"Invalid Post-Op requested. No Post-Op performed.\")\n",
    "        return denoised\n",
    "    \n",
    "    def _compute_spectral(self, image, ifft=False, magnitude=False, normalize=True):\n",
    "        \"\"\"\n",
    "        Computes the spectral image using the magnitude of the 2D Fourier Transform.\n",
    "        \n",
    "        Args:\n",
    "            image (Tensor): A single CT scan patch (grayscale).\n",
    "            ifft (bool): Boolean for if it's an inverse fast fourier shift.\n",
    "            magnitude (bool): Boolean to get log of magnitude of the spectral representation.\n",
    "            normalize (bool): Boolean to normalize the magnitude to the range [0, 1]\n",
    "            \n",
    "        Returns:\n",
    "            spectral_image (Tensor): The spectral representation.\n",
    "            magnitude (Tensor: float): Log of the magnitude of the spectral representation.\n",
    "        \"\"\"\n",
    "        fft_shift = None\n",
    "        if ifft:\n",
    "            fft_shift = torch.fft.ifftshift(image, dim=(-2, -1))  # Shift zero frequency to center\n",
    "        else:\n",
    "            fft_image = torch.fft.fft2(image)  # Apply 2D Fourier Transform\n",
    "            fft_shift = torch.fft.fftshift(fft_image, dim=(-2, -1))  # Shift zero frequency to center\n",
    "        \n",
    "        if magnitude:\n",
    "            magnitude_spectrum = torch.abs(fft_shift)  # Get magnitude\n",
    "            # Normalize the spectrum for consistency\n",
    "            magnitude_spectrum = torch.log1p(magnitude_spectrum)  # Log scaling\n",
    "            \n",
    "            if normalize:\n",
    "                magnitude_spectrum = (magnitude_spectrum - magnitude_spectrum.min()) / (magnitude_spectrum.max() - magnitude_spectrum.min())\n",
    "                # magnitude_spectrum /= magnitude_spectrum.max()  # Normalize [0,1]\n",
    "                \n",
    "            return fft_shift.to(torch.complex64), magnitude_spectrum\n",
    "        else: \n",
    "            return fft_shift.to(torch.complex64)\n",
    "        \n",
    "    def _psnr_scores(self, image, target, max_pixel_value=1.0):\n",
    "        '''\n",
    "        Computed PSNR scores for given image and target pair.\n",
    "\n",
    "        Args:\n",
    "            image (Tensor): Image to calculate the score for.\n",
    "            target (Tensor): Image as a reference target.\n",
    "            max_pixel_value (float): Max value of \n",
    "            \n",
    "        Returns:\n",
    "            spectral_image (Tensor): The spectral representation.\n",
    "        '''\n",
    "        # max_pixel_value = 1.0 as the input is in range [-0.5, 0.5], making the amplitude/range of values to be 1.0 \n",
    "        assert len(image.shape) == 3 and len(target.shape) == 3\n",
    "        image = torch.clip(image, -0.5, 0.5).add(0.5)\n",
    "        target = torch.clip(target, -0.5, 0.5).add(0.5)\n",
    "        \n",
    "        mse = torch.clip(torch.mean((target - image)**2, dim=(-2, -1)), min=1e-8)\n",
    "        psnr = 10.0 * torch.log10(max_pixel_value**2 / mse)\n",
    "        return psnr\n",
    "    \n",
    "    def _augment_data(self, imgs, specs, augment_params):\n",
    "        '''\n",
    "        This function performs augmentation operations like translation.\n",
    "        \n",
    "        Args:\n",
    "            images (Tensor): Tensor of images to augment.\n",
    "            specs (Tensor: complex): Tensor of spectral representations of the images.\n",
    "            augment_params (dict()): Dictionary of augmentation parameters.\n",
    "        \n",
    "        Returns:\n",
    "            augmented_images (Tensor): Tensor of the augmented images.\n",
    "            augmented_spectrals (Tensor): Tensor of the spectral representations of the augmented images.\n",
    "        '''\n",
    "        t = augment_params.get('translate', 0)\n",
    "        if t <= 0:\n",
    "            return imgs, specs\n",
    "        else:\n",
    "            trans = torch.randint(-t, t + 1, size=(2, ))\n",
    "            cache_key = (int(trans[0].item()), int(trans[1].item()))\n",
    "            if cache_key not in self.augment_translate_cache:\n",
    "                # Create delta image with a shifted impulse\n",
    "                x = torch.zeros(imgs[0].shape, dtype=torch.float32)\n",
    "                y_idx = (trans[0].item() + imgs[0].shape[0]) % imgs[0].shape[0]\n",
    "                x_idx = (trans[1].item() + imgs[0].shape[1]) % imgs[0].shape[1]\n",
    "                x[y_idx, x_idx] = 1.0\n",
    "                kernel_spec = self._compute_spectral(x)\n",
    "                augment_translate_cache[cache_key] = kernel_spec\n",
    "                kernel_spec = kernel_spec.to(self.device)\n",
    "            else:\n",
    "                kernel_spec = augment_translate_cache[cache_key].to(self.device)\n",
    "            new_imgs = torch.roll(imgs, shifts=(cache_key[0], cache_key[1]), dims=(1, 2))\n",
    "            new_specs = specs * kernel_spec[None, :, :]\n",
    "            return new_imgs, new_specs\n",
    "    \n",
    "    def _inject_noise(self, imgs, specs, corruption_type: Optional[str]=\"\", noise_injection_factor=1.0, **kwargs):\n",
    "        '''\n",
    "        Injects images with artificial noise values.\n",
    "        \n",
    "        Args:\n",
    "            images (Tensor): Source image tensor\n",
    "            specs (Tensor): Spectral representation of the input images.\n",
    "            corruption_type (str): Corruption type to add.\n",
    "            **kwargs: keyword arguments for respective corruption type.\n",
    "        \n",
    "        Returns:\n",
    "            corrupted_images (Tensor): Images after adding the noise values.\n",
    "            corrupted_spectrals (Tensor): The spectral representation of noisy images.\n",
    "            corruption_mask (Tensor: float): The mask used to inject noise.\n",
    "        '''\n",
    "        _, H, W = imgs.shape\n",
    "        unique_key_freq = 1\n",
    "        noise_injection_factor = kwargs.get(\"noise_injection_factor\", 1.0)\n",
    "        # Choose to corrupt or not, and choose the corruption type.\n",
    "        if corruption_type == \"\":\n",
    "            return imgs, specs, torch.zeros_like(imgs)\n",
    "            \n",
    "        elif corruption_type == \"bspec\":\n",
    "            if \"p_edge\" not in kwargs[\"corruption_params\"]:\n",
    "                warnings.warn(\"Missing Parameter Warning: Using default values for - corruption_params:{\\\"p_edge\\\" = 0.025}\")\n",
    "            p_edge = np.clip(kwargs[\"corruption_params\"].get(\"p_edge\", 0.025) * (2.0 - noise_injection_factor), 0.0, 1.0)\n",
    "            \n",
    "            cache_key = (self.epoch%unique_key_freq, \"bernoulli\", p_edge)\n",
    "            if cache_key not in self.corruption_masks:\n",
    "                # Create a corruption mask\n",
    "                y = torch.arange(H, dtype=torch.float32, device=self.device) - H // 2\n",
    "                x = torch.arange(W, dtype=torch.float32, device=self.device) - W // 2\n",
    "                yy, xx = torch.meshgrid(y**2, x**2, indexing='ij')\n",
    "                r_dist = torch.sqrt(xx + yy)\n",
    "                prob_mask = (p_edge ** (2.0 / W)) ** r_dist\n",
    "                \n",
    "                keep = (torch.rand(size=(H, W), device=self.device, dtype=torch.float32) ** 2) < prob_mask\n",
    "                keep = keep & torch.flip(keep, dims=[0, 1])\n",
    "                \n",
    "                self.corruption_masks[cache_key] = (keep, prob_mask)\n",
    "                \n",
    "            else:    \n",
    "                keep, prob_mask = self.corruption_masks[cache_key]\n",
    "            \n",
    "            # Apply Mask\n",
    "            mskd_specs = specs * keep\n",
    "            spec_msk = keep.to(torch.float32)\n",
    "            new_specs = self._compute_spectral(mskd_specs / torch.where(keep, prob_mask, 1e-8), ifft=True)\n",
    "            new_imgs = torch.fft.ifft2(new_specs).real.float()\n",
    "            \n",
    "            spec_msk *= -1\n",
    "            \n",
    "            return new_imgs, new_specs, spec_msk\n",
    "\n",
    "        elif corruption_type == \"poisson\":\n",
    "            if \"poisson_strength\" not in kwargs[\"corruption_params\"]:\n",
    "                warnings.warn(\"Missing Parameter Warning: Using default values for - corruption_params:{\\\"poisson_strength\\\" = 0.102}\")\n",
    "            corruption_strength = kwargs[\"corruption_params\"].get(\"poisson_strength\", 0.102) * noise_injection_factor\n",
    "        \n",
    "            if \"distribution\" not in kwargs[\"corruption_params\"]:\n",
    "                warnings.warn(\"Missing Parameter Warning: Using default values for - corruption_params:{\\\"distribution\\\" = \\\"uniform\\\"}\")\n",
    "            distribution = kwargs[\"corruption_params\"].get(\"distribution\", \"uniform\")\n",
    "        \n",
    "            cache_key = (self.epoch % unique_key_freq, \"poisson_spectral\", corruption_strength, distribution)\n",
    "            if cache_key not in self.corruption_masks:\n",
    "                if distribution == \"uniform\":\n",
    "                    if \"mask_ratio\" not in kwargs[\"corruption_params\"]:\n",
    "                        warnings.warn(\"Missing Parameter Warning: Using default values for - corruption_params:{\\\"mask_ratio\\\" = 0.05}\")\n",
    "                    criterion = kwargs[\"corruption_params\"].get(\"mask_ratio\", 0.05)\n",
    "                elif distribution == \"gaussian\":\n",
    "                    if \"poisson_sigma\" not in kwargs[\"corruption_params\"]:\n",
    "                        raise ValueError(\"Missing 'poisson_sigma' in corruption_params.\")\n",
    "                    sigma = kwargs[\"corruption_params\"].get(\"poisson_sigma\", 1.0)\n",
    "                    y = torch.arange(H, dtype=torch.float32, device=self.device) - H // 2\n",
    "                    x = torch.arange(W, dtype=torch.float32, device=self.device) - W // 2\n",
    "                    yy, xx = torch.meshgrid(y, x, indexing=\"ij\")\n",
    "                    criterion = torch.exp(-(xx**2 + yy**2) / (2 * sigma**2))\n",
    "                else:\n",
    "                    criterion = 0.05\n",
    "        \n",
    "                mask = (torch.rand((H, W), device=self.device) < criterion).float()\n",
    "                self.corruption_masks[cache_key] = mask\n",
    "            else:\n",
    "                mask = self.corruption_masks[cache_key]\n",
    "        \n",
    "            # === Spectral Poisson Injection ===\n",
    "            specs_shifted = self._compute_spectral(imgs)\n",
    "            magnitude = torch.abs(specs_shifted)\n",
    "            phase = torch.angle(specs_shifted)\n",
    "        \n",
    "            noise = torch.poisson((magnitude + 1e-5) * corruption_strength) / corruption_strength\n",
    "            new_magnitude = torch.where(mask.bool(), noise, magnitude)\n",
    "        \n",
    "            # Reconstruct corrupted complex spectrum\n",
    "            new_specs = new_magnitude * torch.exp(1j * phase)\n",
    "        \n",
    "            # Enforce Hermitian symmetry\n",
    "            new_specs = self._compute_spectral(new_specs, ifft=True)\n",
    "            new_imgs = torch.fft.ifft2(new_specs).real.float()\n",
    "        \n",
    "            # Generate spectral-domain mask (normalized log-magnitude diff)\n",
    "            mask_spec = torch.log1p(torch.abs(magnitude - new_magnitude))\n",
    "            mask_spec = (mask_spec - mask_spec.min()) / torch.max((mask_spec.max() - mask_spec.min()), torch.tensor(1e-8, device=mask_spec.device))\n",
    "            mask_spec *= -1  # Consistent with your negative corruption convention\n",
    "            \n",
    "            return new_imgs, new_specs, mask_spec\n",
    "\n",
    "        elif corruption_type == \"gaussian\":\n",
    "            if \"gaussian_std\" not in kwargs[\"corruption_params\"]:\n",
    "                warnings.warn(\"Missing Parameter Warning: Using default values for - corruption_params:{\\\"Gaussian Standard Deviation\\\" = 0.1}\")\n",
    "            std = kwargs[\"corruption_params\"].get(\"gaussian_std\", 0.1) * noise_injection_factor\n",
    "        \n",
    "            cache_key = (self.epoch % unique_key_freq, \"gaussian_spectral\", std)\n",
    "            if cache_key not in self.corruption_masks:\n",
    "                mask = torch.normal(mean=0.0, std=std, size=imgs[0].shape, device=self.device)\n",
    "        \n",
    "                self.corruption_masks[cache_key] = mask\n",
    "            else:\n",
    "                mask = self.corruption_masks[cache_key]\n",
    "        \n",
    "            # === Spectral Gaussian Injection ===\n",
    "            specs_shifted = self._compute_spectral(imgs)\n",
    "            magnitude = torch.abs(specs_shifted)\n",
    "            phase = torch.angle(specs_shifted)\n",
    "        \n",
    "            # Add Gaussian noise to magnitude (keeping the phase intact)\n",
    "            noise = mask  # Using the pre-generated Gaussian mask for added noise\n",
    "            new_magnitude = magnitude + noise\n",
    "        \n",
    "            # Reconstruct the corrupted complex spectrum\n",
    "            new_specs = new_magnitude * torch.exp(1j * phase)\n",
    "        \n",
    "            # Enforce Hermitian symmetry\n",
    "            new_specs = self._compute_spectral(new_specs, ifft=True)\n",
    "            new_imgs = torch.fft.ifft2(new_specs).real.float()\n",
    "        \n",
    "            # Generate spectral-domain mask (log-magnitude diff)\n",
    "            mask_spec = torch.log1p(torch.abs(magnitude - new_magnitude))\n",
    "            mask_spec = (mask_spec - mask_spec.min()) / torch.max(mask_spec.max() - mask_spec.min(), torch.tensor(1e-8, device=mask_spec.device))\n",
    "            mask_spec *= -1  # Consistent with your negative corruption convention\n",
    "        \n",
    "            return new_imgs, new_specs, mask_spec\n",
    "\n",
    "        elif corruption_type == \"poisson0\":\n",
    "            if \"poisson_strength\" not in kwargs[\"corruption_params\"]:\n",
    "                warnings.warn(\"Missing Parameter Warning: Using default values for - corruption_params:{\\\"poisson_strength\\\" = 0.102}\")\n",
    "            lam_min = 10\n",
    "            lam_max = kwargs[\"corruption_params\"].get(\"poisson_strength\", 30) * (2.0 - noise_injection_factor)\n",
    "            corruption_strength = torch.empty(1).uniform_(lam_min, lam_max).item()\n",
    "            \n",
    "            if \"distribution\" not in kwargs[\"corruption_params\"]:\n",
    "                warnings.warn(\"Missing Parameter Warning: Using default values for - corruption_params:{\\\"distribution\\\" = \\\"uniform\\\"}\")\n",
    "            distribution = kwargs[\"corruption_params\"].get(\"distribution\", \"uniform\")\n",
    "\n",
    "            mask = None\n",
    "            cache_key = (self.epoch%unique_key_freq, \"poisson\", corruption_strength, distribution)\n",
    "            if cache_key not in self.corruption_masks:\n",
    "                # Create a corruption mask\n",
    "                if distribution == \"uniform\":\n",
    "                    if \"mask_ratio\" not in kwargs[\"corruption_params\"]:\n",
    "                        warnings.warn(\"Missing Parameter Warning: Using default values for - corruption_params:{\\\"mask_ratio\\\" = 0.05}\")\n",
    "                    criterion = kwargs[\"corruption_params\"].get(\"mask_ratio\", 0.05)\n",
    "                    \n",
    "                elif distribution == \"gaussian\":\n",
    "                    if \"poisson_sigma\" not in kwargs[\"corruption_params\"]:\n",
    "                        raise ValueError(\"Missing 'poisson_sigma' in corruption_params.\")\n",
    "                        \n",
    "                    sigma = kwargs[\"corruption_params\"].get(\"poisson_sigma\", 1.0)\n",
    "                    y = torch.arange(H, dtype=torch.float32, device=device) - H // 2\n",
    "                    x = torch.arange(W, dtype=torch.float32, device=device) - W // 2\n",
    "                    yy, xx = torch.meshgrid(y, x, indexing=\"ij\")\n",
    "                    criterion = torch.exp(-(xx**2 + yy**2) / (2 * sigma**2))\n",
    "                    \n",
    "                else:\n",
    "                    # Default to uniform distribution with mask_ratio = 0.05\n",
    "                    criterion = 0.05\n",
    "                    \n",
    "                mask = (torch.rand((H, W), device=self.device) < criterion).float()\n",
    "                self.corruption_masks[cache_key] = mask\n",
    "            else:\n",
    "                mask = self.corruption_masks[cache_key]\n",
    "            \n",
    "            poisson_noise = torch.poisson(torch.clamp(torch.abs(imgs + 0.5), 0, 1) * corruption_strength) / corruption_strength - 0.5\n",
    "            batch_mask = mask.unsqueeze(0)\n",
    "            new_imgs = torch.where(batch_mask.bool(), poisson_noise, imgs)\n",
    "            new_specs = self._compute_spectral(new_imgs)\n",
    "            \n",
    "            mask = torch.log1p(self._compute_spectral(mask).abs())\n",
    "            mask = (mask - mask.min())/(mask.max() - mask.min())\n",
    "            mask *= -1\n",
    "            return new_imgs, new_specs, mask\n",
    "        \n",
    "        elif corruption_type == \"gaussian0\":\n",
    "            if \"gaussian_std\" not in kwargs[\"corruption_params\"]:\n",
    "                warnings.warn(\"Missing Parameter Warning: Using default values for - corruption_params:{\\\"Daussian Standard Deviation\\\" = 25}\")\n",
    "            std = kwargs[\"corruption_params\"].get(\"gaussian_std\", 25) * noise_injection_factor\n",
    "            std /= 255.0\n",
    "            cache_key = (self.epoch%unique_key_freq, \"gaussian\", std)\n",
    "            if cache_key not in self.corruption_masks:\n",
    "                mask = torch.normal(mean=0.0, std=std, size=imgs[0].shape, device=self.device)\n",
    "                \n",
    "            new_imgs = imgs + mask\n",
    "            new_specs = self._compute_spectral(new_imgs)\n",
    "            \n",
    "            mask = torch.log1p(self._compute_spectral(mask).abs())\n",
    "            mask = (mask - mask.min())/(mask.max() - mask.min())\n",
    "            mask *= -1\n",
    "            return new_imgs, new_specs, mask\n",
    "            \n",
    "        elif corruption_type == \"blur\":\n",
    "            if \"blur_kernel\" not in kwargs[\"corruption_params\"]:\n",
    "                warnings.warn(\"Missing Parameter Warning: Using default values for - corruption_params:{\\\"Blur Kernel\\\" = 19}\")\n",
    "            kernel = kwargs[\"corruption_params\"].get(\"blur_kernel\", 19)\n",
    "            \n",
    "            if \"blur_sigma\" not in kwargs[\"corruption_params\"]:\n",
    "                warnings.warn(\"Missing Parameter Warning: Using default values for - corruption_params:{\\\"Blur Sigma\\\" = 2.5}\")\n",
    "            sigma = kwargs[\"corruption_params\"].get(\"blur_sigma\", 2.5) * noise_injection_factor\n",
    "            \n",
    "            sigma = random.uniform(0.5, sigma)\n",
    "            rec_kernel = int(2*np.ceil(sigma*3)) + 1\n",
    "            kernel_size = random.choice([k for k in range(rec_kernel, min(kernel, 2*rec_kernel + 1), 2)])\n",
    "            \n",
    "            new_imgs = gaussian_blur(img=imgs, kernel_size=kernel_size, sigma=sigma)\n",
    "            \n",
    "            # cache_key = (self.epoch%unique_key_freq, \"blur\", kernel, sigma)\n",
    "            # if cache_key not in self.corruption_masks:\n",
    "            #     new_imgs = gaussian_blur(img=imgs, kernel_size=kernel, sigma=sigma)\n",
    "            #     mask = new_imgs[0] - imgs[0]\n",
    "            #     # print(mask.shape, imgs.shape, new_imgs.shape)\n",
    "            #     self.corruption_masks[cache_key] = mask\n",
    "            # else:\n",
    "            #     mask = self.corruption_masks[cache_key]\n",
    "            #     new_imgs = imgs + mask\n",
    "                \n",
    "            new_specs = self._compute_spectral(new_imgs)\n",
    "            \n",
    "            # mask = torch.log1p(self._compute_spectral(mask).abs())\n",
    "            # mask = (mask - mask.min())/(mask.max() - mask.min())\n",
    "            # mask *= -1\n",
    "            return new_imgs, new_specs, torch.zeros_like(new_imgs)\n",
    "            \n",
    "        elif corruption_type == \"mixed\":\n",
    "\n",
    "            # Apply Gaussian\n",
    "            gaussian_imgs, gaussian_specs, gaussian_mask = self._inject_noise(imgs, specs, corruption_type=\"gaussian\", corruption_params=kwargs[\"corruption_params\"])\n",
    "            # Apply Blur\n",
    "            #  blur_imgs, blur_specs, blur_mask = self._inject_noise(gaussian_imgs, gaussian_specs, corruption_type=\"blur\", corruption_params=kwargs[\"corruption_params\"])\n",
    "            # Apply Poisson\n",
    "            poisson_imgs, poisson_specs, poisson_mask = self._inject_noise(gaussian_imgs, gaussian_specs, corruption_type=\"poisson\", corruption_params=kwargs[\"corruption_params\"])\n",
    "            \n",
    "            # Apply bspec\n",
    "            # bspec_imgs, bspec_specs, bspec_mask= self._inject_noise(gaussian_imgs, gaussian_specs, corruption_type=\"bspec\", corruption_params=kwargs[\"corruption_params\"])\n",
    "            \n",
    "            corrupted_imgs, corrupted_specs = poisson_imgs, poisson_specs\n",
    "\n",
    "            # combi_mask = gaussian_mask + poisson_mask\n",
    "            # combi_mask = torch.log1p(self._compute_spectral(combi_mask).abs())\n",
    "            # combi_mask = (combi_mask - combi_mask.min())/(combi_mask.max() - combi_mask.min())\n",
    "            \n",
    "            # gaussian_mask = torch.log1p(self._compute_spectral(gaussian_mask).abs())\n",
    "            # gaussian_mask = (gaussian_mask - gaussian_mask.min())/(gaussian_mask.max() - gaussian_mask.min())\n",
    "\n",
    "            # poisson_mask = torch.log1p(self._compute_spectral(poisson_mask).abs())\n",
    "            # poisson_mask = (poisson_mask - poisson_mask.min())/(poisson_mask.max() - poisson_mask.min())\n",
    "\n",
    "            corrupted_mask = gaussian_mask + poisson_mask\n",
    "            return corrupted_imgs, corrupted_specs, corrupted_mask\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"Requested \\\"{corruption_type}\\\" which is an invalid corruption type!\")\n",
    "    \n",
    "    def _noise_injector(self, imgs, specs, corruption_type: Optional[List[str]]=None, noise_injection_factor=1.0, **kwargs):\n",
    "        '''\n",
    "        This function sequentially injects noise to a tensor of images.\n",
    "\n",
    "        Args:\n",
    "            imgs (Tensor): Images to add noise to.\n",
    "            specs (Tensor): Spectral representation of the images.\n",
    "            corruption_type (List[str]): List of corruptions to add in sequence.\n",
    "            **kwargs: Keyword arguments for respective noise types.\n",
    "        \n",
    "        Returns:\n",
    "            corrupted_images (Tensor): Corrupted images.\n",
    "            corrupted_spectrals (Tensor): The spectral representation.\n",
    "            corruption_mask (Tensor): The effective corruption mask for the sequence of noise patterns.\n",
    "        '''\n",
    "        output_imgs, output_specs, output_masks = imgs, specs, torch.zeros_like(imgs)\n",
    "        if corruption_type:\n",
    "            for corruption in corruption_type:\n",
    "                output_imgs, output_specs, masks = self._inject_noise(output_imgs, output_specs, corruption_type=corruption, noise_injection_factor=noise_injection_factor, **kwargs)\n",
    "                if corruption == 'bspec':\n",
    "                    # To avoid removing other image masks during the post-op process.\n",
    "                    output_masks += torch.ones_like(imgs) + masks\n",
    "        \n",
    "        return output_imgs, output_specs, output_masks\n",
    "    \n",
    "    def _preprocessbatch(self, imgs, specs, noisy_targets=True, inject_noise=True, **kwargs):\n",
    "        '''\n",
    "        This function performs preprocessing on a batch of images.\n",
    "\n",
    "        Args:\n",
    "            imgs (Tensor): Batch of images to process.\n",
    "            specs (Tensor): Spectral representation of images.\n",
    "            noisy_targets (bool): Boolean to select noisy or clean targets.\n",
    "            inject_noise (bool): Boolean to add noise to images or not.\n",
    "            **kwargs: keyword arguments for respective processes.\n",
    "        \n",
    "        Returns:\n",
    "            processed_images (Tensor): Images after processing.\n",
    "            processed_targets (Tensor): Targets for training.\n",
    "            processed_spectrals (Tensor): The spectral representation.\n",
    "            corruption_mask (Tensor: float): The effective mask used for injecting noise values.\n",
    "            original_images (Tensor): Original images before any preprocessing.\n",
    "        '''\n",
    "        augmented_imgs, augmented_specs = self._augment_data(imgs, specs, augment_params=kwargs.get(\"augment_params\", dict()))\n",
    "        if inject_noise:\n",
    "            new_imgs, new_specs, corruption_mask = self._noise_injector(augmented_imgs, augmented_specs, corruption_type=kwargs.get(\"corruption_type\", None), corruption_params=kwargs.get(\"corruption_params\"))\n",
    "        else:\n",
    "            new_imgs, new_specs, corruption_mask = augmented_imgs, augmented_specs, []\n",
    "        \n",
    "        if noisy_targets:\n",
    "            c_type = kwargs.get(\"corruption_type\", None)\n",
    "            if 'blur' in c_type:\n",
    "                c_type.remove('blur')\n",
    "            targets, _, _ = self._noise_injector(augmented_imgs, augmented_specs, corruption_type=c_type, corruption_params=kwargs.get(\"corruption_params\"), noise_injection_factor=kwargs.get(\"target_noise_injection_factor\", 1.0))\n",
    "        else:\n",
    "            targets = augmented_imgs\n",
    "\n",
    "        return new_imgs, targets, new_specs, corruption_mask, imgs\n",
    "    \n",
    "    def _save_config(self, **kwargs):\n",
    "        '''\n",
    "        This function saves the parameters and hyperparameters used for the current run of the experiment to 'run-config.txt'.\n",
    "        '''\n",
    "        logger = self.Logger(str(self.results_dir / \"run-config.txt\"))\n",
    "        kwargs = {**self.init_kwargs, **kwargs}\n",
    "        config = {\n",
    "            'loss': str(self.loss_fn),\n",
    "            'learning_rate': self.optimizer.param_groups[0]['lr'],\n",
    "            'post_op': self.post_op,\n",
    "            'max_epochs': self.max_epochs,\n",
    "            'start_epoch': self.start_epoch,\n",
    "            'results_dir': str(self.results_dir),\n",
    "            'corrupt_targets': kwargs.get(\"n2n\", True),\n",
    "            'batch_size': self.batch_size,\n",
    "            'checkpoint_save_interval': self.save_interval,\n",
    "            'augmentation_params': kwargs.get(\"augment_params\", dict()),\n",
    "            'corruption_type': kwargs.get(\"corruption_type\", None),\n",
    "            'noisy_target_factor': kwargs.get(\"target_noise_injection_factor\", 1.0), \n",
    "            'corruption_params': kwargs.get(\"corruption_params\", dict())\n",
    "        }\n",
    "        \n",
    "        logger.start()\n",
    "        print(\"############ Config #############\")\n",
    "        print(json.dumps({'config': config}, indent=4))\n",
    "        print(\"#################################\")\n",
    "        logger.stop()\n",
    "    \n",
    "    def _train_phase(self, train_loss=0.0, train_n=0.0, inject_noise=True, **kwargs):\n",
    "        '''\n",
    "        This function executes the training phase of the training epoch.\n",
    "\n",
    "        Args:\n",
    "            train_loss (float): Average training loss from the previous epoch.\n",
    "            train_n (float): Number of image samples in the previous batch.\n",
    "            inject_noise (bool): Boolean for corrupting images.\n",
    "        \n",
    "        Returns:\n",
    "            train_loss (float): Average training loss from the current epoch.\n",
    "            train_n (float): Number of image samples in the batch.\n",
    "        '''\n",
    "        # Do Data Minibatching \n",
    "        for idx, batch in tqdm(enumerate(self.train_loader), desc=\"Training Batch\", total=len(self.train_loader), position=0, leave=True):\n",
    "            imgs, specs = batch\n",
    "            imgs, specs = imgs.to(self.device), specs.to(self.device)\n",
    "            \n",
    "            inps, targs, _, spec_mask, _= self._preprocessbatch(imgs, specs,\n",
    "                                                                noisy_targets=kwargs.get(\"n2n\", True), \n",
    "                                                                inject_noise=inject_noise, \n",
    "                                                                **kwargs)\n",
    "            \n",
    "            outputs = self.model(inps)\n",
    "\n",
    "            if self.post_op:\n",
    "                outputs = self._post_op(self.post_op, outputs, specs, spec_mask)\n",
    "            \n",
    "            loss = self.loss_fn(outputs, targs)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "    \n",
    "            train_loss += loss.item() * inps.size(0)\n",
    "            train_n += inps.size(0)\n",
    "        \n",
    "        train_loss = (train_loss / train_n) if train_n > 0 else 0.0\n",
    "        return train_loss, train_n\n",
    "    \n",
    "    def _valid_phase(self, valid_loss=0.0, valid_n=0.0, inject_noise=True, **kwargs):\n",
    "        '''\n",
    "        This function executes the Validation phase of the training epoch.\n",
    "\n",
    "        Args:\n",
    "            valid_loss (float): Average training loss from the previous epoch.\n",
    "            valid_n (float): Number of image samples in the previous batch.\n",
    "            inject_noise (bool): Boolean for corrupting images.\n",
    "        \n",
    "        Returns:\n",
    "            valid_loss (float): Average training loss from the current epoch.\n",
    "            valid_n (float): Number of image samples in the batch.\n",
    "            average_psnr (float): Average PSNR score of the batch.\n",
    "        '''\n",
    "        # Validation Process\n",
    "        self.model.eval()\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            for idx, batch in tqdm(enumerate(self.valid_loader), desc=\"Validation Batch\", total=len(self.valid_loader), leave=True):\n",
    "                # inps, targs, _, _, origs = batch\n",
    "                # inps, targs, origs = inps.to(self.device), targs.to(self.device), origs.to(self.device)\n",
    "                imgs, specs = batch\n",
    "                imgs, specs = imgs.to(self.device), specs.to(self.device)\n",
    "                inps, targs, _, _, origs = self._preprocessbatch(imgs, specs, \n",
    "                                                                 noisy_targets=False, \n",
    "                                                                 inject_noise=inject_noise, \n",
    "                                                                 **kwargs)\n",
    "                \n",
    "                outputs = self.model(inps)\n",
    "\n",
    "                # if self.post_op == 'fspec':\n",
    "                #     outputs = self._post_op(outputs, specs, spec_mask)\n",
    "                \n",
    "                loss = self.loss_fn(outputs, targs)\n",
    "    \n",
    "                valid_loss += loss.item() * inps.size(0)\n",
    "                valid_n += inps.size(0)\n",
    "\n",
    "                # Calculate PSNR scores\n",
    "                avg_psnr = torch.mean(self._psnr_scores(outputs, targs))\n",
    "                \n",
    "                if idx == 0:\n",
    "                    # 4-in-1 image + spectrum\n",
    "                    assert inps.shape[0] >= 1, \"Batch size too small. Minimum permitted size = 1\"\n",
    "                    if inps.shape[0] >= 7:\n",
    "                        prim = [x.squeeze(0) for x in [origs[6], inps[6], outputs[6], targs[6]]]\n",
    "                    else:\n",
    "                        prim = [x.squeeze(0) for x in [origs[0], inps[0], outputs[0], targs[0]]]\n",
    "                        \n",
    "                    spec = [v for _, v in (self._compute_spectral(x, magnitude=True, normalize=False) for x in prim)]\n",
    "                    pimg = torch.cat(prim, dim=1).add(0.5)\n",
    "                    simg = torch.cat(spec, dim=1).mul(0.05)\n",
    "                    img = torch.cat([pimg, simg], dim=0)\n",
    "\n",
    "                    # Saving the Outputs.\n",
    "                    save_image(img, self.training_test_path / f\"img{self.epoch:03d}.png\", normalize=False)\n",
    "                    \n",
    "        valid_loss = (valid_loss / valid_n) if valid_n > 0 else 0.0\n",
    "        return valid_loss, valid_n, avg_psnr.item()\n",
    "     \n",
    "    def _final_epoch(self, inject_noise=True, **kwargs):\n",
    "        '''\n",
    "        This function executes the Final Epoch phase of the training epoch.\n",
    "        '''\n",
    "        print(\"Final Epoch: \\n\")\n",
    "        # Do a full Validation set testing with result saving.\n",
    "        loader = DataLoader(Subset(self.valid_data, indices=range(min(10, len(self.valid_data)))), batch_size=1, shuffle=False, pin_memory=True, pin_memory_device=\"cuda\")\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.inference_mode():\n",
    "            psnr_file = self.validation_test_path / \"PSNR.txt\"\n",
    "            with psnr_file.open('wt') as fout:\n",
    "                fout.write(f'Sr.no.:\\tOriginal\\tInput\\t\\tOutput\\t\\tGains\\n' +\n",
    "                           '-'*70 + '\\n')\n",
    "                for idx, batch in tqdm(enumerate(loader), desc=\"Validation Testing\", total=len(loader), leave=True):\n",
    "                    imgs, specs = batch\n",
    "                    imgs, specs = imgs.to(self.device), specs.to(self.device)\n",
    "                    inp, targ, _, _, orig = self._preprocessbatch(imgs, specs,\n",
    "                                                                 noisy_targets=False,\n",
    "                                                                 inject_noise=inject_noise,\n",
    "                                                                 **kwargs)\n",
    "                    denoised_op = self.model(inp)\n",
    "                    \n",
    "                    # 4-in-1 image + spectrum\n",
    "                    prim = [x.squeeze(0) for x in [orig, inp, denoised_op, targ]]\n",
    "                    spec = [v for _, v in (self._compute_spectral(x, magnitude=True, normalize=False) for x in prim)]\n",
    "                    pimg = torch.cat(prim, dim=1).add(0.5)\n",
    "                    simg = torch.cat(spec, dim=1).mul(0.05)\n",
    "                    img = torch.cat([pimg, simg], dim=0)\n",
    "\n",
    "                    # Saving the Outputs.\n",
    "                    save_image(img, self.validation_test_path / f\"final{idx:03d}.png\", normalize=False)\n",
    "                    # save_image((torch.clip(orig, -0.5, 0.5) + 0.5).cpu(), self.validation_test_path / f\"original{idx:03d}.png\")\n",
    "                    save_image((torch.clip(denoised_op, -0.5, 0.5).add(0.5)).cpu(), self.validation_test_path / f\"output{idx:03d}.png\")\n",
    "                    save_image((torch.clip(targ, -0.5, 0.5).add(0.5)).cpu(), self.validation_test_path / f\"target{idx:03d}.png\")\n",
    "                    save_image((torch.clip(inp, -0.5, 0.5).add(0.5)).cpu(), self.validation_test_path / f\"input{idx:03d}.png\")\n",
    "                    \n",
    "                    # PSNR Scores\n",
    "                    orig_vs_targ = self._psnr_scores(imgs, targ).item()\n",
    "                    op_vs_targ = self._psnr_scores(denoised_op, targ).item()\n",
    "                    inp_vs_targ = self._psnr_scores(inp, targ).item()\n",
    "                    \n",
    "                    fout.write(f'{idx:02d}:\\t{orig_vs_targ:0.5f}\\t{inp_vs_targ:0.5f}\\t{op_vs_targ:0.5f}\\t{(op_vs_targ - inp_vs_targ):0.5f}\\n')\n",
    "    \n",
    "    def _generate_example(self, inject_noise=True, **kwargs):\n",
    "        '''\n",
    "        This function generates an example sample pair of the noisy input and target images for the active training experiment.\n",
    "        It also saves a labeled and an unlabeled versions of the sample for the report.\n",
    "        \n",
    "        Args:\n",
    "            inject_noise (bool) : Boolean to inject noise onto images.\n",
    "            **kwargs: Keyword arguments for respective noise types.\n",
    "        \n",
    "        Returns:\n",
    "            corrupted_image (Tensor): Sample of the corrupted image.\n",
    "        '''\n",
    "        # Save image sample\n",
    "        imgs, specs = next(iter(self.train_loader))\n",
    "        assert imgs.shape[0] >= 1, \"Batch size too small. Minimum permitted size = 1\"\n",
    "        if imgs.shape[0] >= 10:\n",
    "            imgs, specs = torch.narrow(imgs, 0, 9, 1), torch.narrow(specs, 0, 9, 1)\n",
    "        else:\n",
    "            imgs, specs = torch.narrow(imgs, 0, 0, 1), torch.narrow(specs, 0, 0, 1)\n",
    "            \n",
    "        imgs, specs = imgs.to(self.device), specs.to(self.device)\n",
    "        dummy_ip, t, s, s_m, o= self._preprocessbatch(imgs, specs, \n",
    "                                                     noisy_targets=kwargs.get(\"n2n\", True), \n",
    "                                                     inject_noise=inject_noise, \n",
    "                                                     **kwargs)\n",
    "\n",
    "        prim = [x.squeeze(0) for x in [dummy_ip, t]]\n",
    "        spec = [v for _, v in (self._compute_spectral(x, magnitude=True, normalize=False) for x in prim)]\n",
    "        pimg = torch.cat(prim, dim=1).add(0.5)\n",
    "        simg = torch.cat(spec, dim=1).mul(0.05)\n",
    "        img = torch.cat([pimg, simg], dim=0)\n",
    "        save_image(img.cpu(), self.results_dir / \"2x2_example.png\", normalize=False)\n",
    "\n",
    "        imgs = [np.clip(x.squeeze(0).add(0.5).cpu().numpy().astype(np.float32), 0.0, 1.0) for x in prim]\n",
    "        specs = [np.clip(x.squeeze(0).mul(0.05).cpu().numpy().astype(np.float32), 0.0, 1.0) for x in spec]\n",
    "        fig, axes = plt.subplots(2, 2)\n",
    "\n",
    "        # Titles for columns\n",
    "        axes[0, 0].set_title(\"Noisy\", fontsize=12)\n",
    "        axes[0, 1].set_title(\"Target\", fontsize=12)\n",
    "        \n",
    "        # Plot images\n",
    "        axes[0, 0].imshow(imgs[0], cmap='gray')\n",
    "        axes[0, 1].imshow(imgs[1], cmap='gray')\n",
    "        axes[1, 0].imshow(specs[0], cmap='gray')\n",
    "        axes[1, 1].imshow(specs[1], cmap='gray')\n",
    "        \n",
    "        # Clean up axes\n",
    "        for ax in axes.ravel():\n",
    "            ax.axis('off')\n",
    "\n",
    "        # Add row labels using fig.text\n",
    "        fig.text(0.08, 0.75, \"Spatial\", va='center', ha='left', fontsize=12, rotation='vertical')\n",
    "        fig.text(0.08, 0.28, \"Spectral\", va='center', ha='left', fontsize=12, rotation='vertical')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(self.results_dir / \"2x2_example_labled.png\", dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        return dummy_ip\n",
    "    \n",
    "    def train(self, inject_noise=True, **kwargs):\n",
    "        '''\n",
    "        This function implements the training loop.\n",
    "        \n",
    "        Args:\n",
    "            inject_noise (bool): Boolean for corrupting images.\n",
    "        '''\n",
    "        # Save config\n",
    "        self._save_config(**kwargs)\n",
    "        \n",
    "        # Start Logging\n",
    "        self.logger.start()\n",
    "        \n",
    "        print(\"Training Started...\")\n",
    "        print(f\"Total Epochs: {self.max_epochs} \\nBatch Size: {self.train_loader.batch_size} \\nInitial Learning Rate: {self.optimizer.param_groups[0]['lr']}\\n\")\n",
    "\n",
    "        # Generate a sample of training input-target pairs.\n",
    "        dummy_ip = self._generate_example(**kwargs)\n",
    "        \n",
    "        # Add Model graph to the Tensorboard.\n",
    "        self.writer.add_graph(model=self.model, input_to_model=dummy_ip.to(self.device), verbose=False)\n",
    "\n",
    "        # Clock Training start time.\n",
    "        train_start_time = time.time()\n",
    "\n",
    "        # Training Loop\n",
    "        for epoch in range(self.start_epoch, self.max_epochs):\n",
    "            self.epoch = epoch\n",
    "            # Clocking Epoch start time\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Training Phase\n",
    "            train_loss, train_n = self._train_phase(**kwargs)\n",
    "            \n",
    "            # Validation Phase\n",
    "            valid_loss, valid_n, avg_psnr = self._valid_phase(**kwargs)\n",
    "\n",
    "            # Update LR Scheduler step\n",
    "            self.scheduler.step()\n",
    "\n",
    "            # Calculating time elapsed for the current epoch.\n",
    "            epoch_time = time.time() - start_time\n",
    "            # Update Tensorboard Summary\n",
    "            self.writer.add_scalar(\"Training/Loss\", train_loss, global_step=epoch, new_style=True)\n",
    "            self.writer.add_scalar(\"Validation/Loss\", valid_loss, global_step=epoch, new_style=True)\n",
    "            self.writer.add_scalar(\"Validation/Average_PSNR\", avg_psnr, global_step=epoch, new_style=True)\n",
    "            self.writer.add_scalar(\"Learning_rate\", self.optimizer.param_groups[0][\"lr\"], global_step=epoch, new_style=True)\n",
    "            self.writer.add_scalar(\"Training/time-per-epoch\", epoch_time, global_step=epoch, new_style=True)\n",
    "            print(f'[{self.device}]Epoch [{epoch+1}/{self.max_epochs}] | Time: {epoch_time: 0.2f} | Train Loss: {train_loss: 0.6f} | Validation Loss: {valid_loss: 0.6f} | Avg. PSNR: {avg_psnr: 0.6f} | Learning Rate: {self.optimizer.param_groups[0][\"lr\"]: 0.10f}')\n",
    "            \n",
    "             # Final Epoch\n",
    "            if epoch == self.max_epochs-1:\n",
    "                # Last Epoch Phase\n",
    "                self.final_epoch = True\n",
    "                self._final_epoch(**kwargs)\n",
    "\n",
    "            # Save Snapshot\n",
    "            if (epoch%self.save_interval == self.save_interval-1 or self.final_epoch) and self.device == 0:\n",
    "                self._save_snapshot()\n",
    "        \n",
    "        # Close the Tensorboard Summary Writer\n",
    "        self.writer.close()\n",
    "        \n",
    "        # Calculate the Elapsed Time for the Training Loop\n",
    "        total_seconds = time.time() - train_start_time\n",
    "        print(f\"Time Elapsed: {int(total_seconds // 3600)}hrs : {int((total_seconds % 3600) // 60)}mins : {int(total_seconds % 60)}secs.\\n\" )\n",
    "        \n",
    "        # Stop with the logging\n",
    "        self.logger.stop()\n",
    "    \n",
    "    def _setup_training(self):\n",
    "        # Dataset exists\n",
    "        if not hasattr(self, 'train_data') or not hasattr(self, 'valid_data'):\n",
    "            raise ValueError(\"Training or validation data not loaded!\")\n",
    "        \n",
    "        self.train_loader = DataLoader(self.train_data, batch_size=self.batch_size, shuffle=True, pin_memory=True, pin_memory_device=\"cuda\")\n",
    "        self.valid_loader = DataLoader(self.valid_data, batch_size=self.batch_size, shuffle=False, pin_memory=True, pin_memory_device=\"cuda\")\n",
    "        \n",
    "        # Set Seed for reproducibility.\n",
    "        torch.manual_seed(42)\n",
    "        torch.cuda.manual_seed(42)\n",
    "        # print(train_batch[0].shape)\n",
    "        \n",
    "        # Define starting conditions\n",
    "        # Fresh start from 0 or load snapshot\n",
    "        if self.load_checkpoint:\n",
    "            # self._load_snapshot()\n",
    "            # Update the snapshot dir for the active run\n",
    "            self.snapshot_path = self.results_dir / \"Snapshots\"\n",
    "            self.snapshot_name = \"\"\n",
    "        else:\n",
    "            self.epoch = 0\n",
    "            self.start_epoch = 0\n",
    "    \n",
    "    def eval(self, data_loader: DataLoader, output_dir: Path = Path(\"\"), inject_noise=False, **kwargs):\n",
    "\n",
    "        def save_labeled_image(img, spec, img_idx):\n",
    "            # Preprocess the values for matplotlib.\n",
    "            imgs = [torch.clip(x.add(0.5), 0.0, 1.0).cpu().numpy().astype(np.float32) for x in img]\n",
    "            specs = [torch.clip(x.mul(0.05), 0.0, 1.0).cpu().numpy().astype(np.float32) for x in spec]\n",
    "            \n",
    "            fig, axes = plt.subplots(2, 4, figsize=(22, 11), gridspec_kw={'left': 0.04, 'right': 0.97, 'top': 0.97, 'bottom': 0.03, 'wspace': 0.01, 'hspace': 0.01})\n",
    "            \n",
    "            # Clean up axes\n",
    "            for ax in axes.ravel():\n",
    "                ax.axis('off')\n",
    "            \n",
    "            # fig.subplots_adjust(0.04, 0.03, 0.03, 0.03, hspace=0.01, wspace=0.01)\n",
    "            \n",
    "            # Titles for columns\n",
    "            axes[0, 0].set_title(\"Original\", fontsize=12)\n",
    "            axes[0, 1].set_title(\"Noisy Input\", fontsize=12)\n",
    "            axes[0, 2].set_title(\"Output\", fontsize=12)\n",
    "            axes[0, 3].set_title(\"Target\", fontsize=12)\n",
    "            \n",
    "            # Plot Original\n",
    "            axes[0, 0].imshow(imgs[0], cmap='gray')\n",
    "            axes[1, 0].imshow(specs[0], cmap='inferno')\n",
    "            # Plot Noisy Input\n",
    "            axes[0, 1].imshow(imgs[1], cmap='gray')\n",
    "            axes[1, 1].imshow(specs[1], cmap='inferno')\n",
    "            # Plot Output\n",
    "            axes[0, 2].imshow(imgs[2], cmap='gray')\n",
    "            axes[1, 2].imshow(specs[2], cmap='inferno')\n",
    "            # Plot Target\n",
    "            axes[0, 3].imshow(imgs[3], cmap='gray')\n",
    "            axes[1, 3].imshow(specs[3], cmap='inferno')\n",
    "\n",
    "            \n",
    "    \n",
    "            # Add row labels using fig.text\n",
    "            fig.text(0.01, 0.75, \"Spatial\", va='center', ha='left', fontsize=12, rotation='vertical')\n",
    "            fig.text(0.01, 0.28, \"Spectral\", va='center', ha='left', fontsize=12, rotation='vertical')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(output_dir / f\"final_labeled{img_idx:03d}.png\", dpi=300, bbox_inches='tight')\n",
    "            # plt.show()\n",
    "            \n",
    "        patch_size = kwargs.get(\"patch_size\", 255)\n",
    "        original_img_size = kwargs.get(\"image_size\", 2570)\n",
    "        overlap = kwargs.get(\"overlap\", 0.5)\n",
    "        step = int(patch_size * (1 - overlap))\n",
    "    \n",
    "        if str(output_dir) == '.':\n",
    "            output_dir = self.evaluation_test_path\n",
    "        else:\n",
    "            output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "        def blank():\n",
    "            return torch.zeros((1, original_img_size, original_img_size), dtype=torch.float32, device=self.device)\n",
    "        \n",
    "        # Buffers for reconstruction\n",
    "        original_reconst = blank()\n",
    "        denoised_reconst = blank()\n",
    "        target_reconst = blank()\n",
    "        input_reconst = blank()\n",
    "        mod_count = blank()\n",
    "    \n",
    "        # Generate patch positions exactly like extract_patches()\n",
    "        coords = []\n",
    "        h = w = original_img_size\n",
    "        for i in range(0, h - patch_size + 1, step):\n",
    "            for j in range(0, w - patch_size + 1, step):\n",
    "                coords.append((i, j))\n",
    "            if (w - patch_size) % step != 0:\n",
    "                j = w - patch_size\n",
    "                coords.append((i, j))\n",
    "                \n",
    "        if (h - patch_size) % step != 0:\n",
    "            i = h - patch_size\n",
    "            for j in range(0, w - patch_size + 1, step):\n",
    "                coords.append((i, j))\n",
    "            if (w - patch_size) % step != 0:\n",
    "                j = w - patch_size\n",
    "                coords.append((i, j))\n",
    "                \n",
    "        n_patches = len(coords)\n",
    "        \n",
    "        patch_idx = 0\n",
    "        img_idx = 1\n",
    "        \n",
    "        self.model.eval()\n",
    "    \n",
    "        with torch.inference_mode():\n",
    "            psnr_file = output_dir / \"PSNR.txt\"\n",
    "            with psnr_file.open('wt') as fout:\n",
    "                fout.write(f'Sr.no.:\\tOriginal\\tInput\\t\\tOutput\\t\\tGains\\n' +\n",
    "                           '-'*80 + '\\n')\n",
    "    \n",
    "                for _, batch in tqdm(enumerate(data_loader), desc=\"Evaluation Dataset\", total=len(data_loader), position=0, leave=True):\n",
    "                    imgs, specs = batch\n",
    "                    imgs, specs = imgs.to(self.device), specs.to(self.device)\n",
    "    \n",
    "                    inp, targ, _, _, orig = self._preprocessbatch(imgs, specs, \n",
    "                                                                  noisy_targets=False, \n",
    "                                                                  inject_noise=inject_noise, \n",
    "                                                                  **kwargs)\n",
    "                    # Predict\n",
    "                    denoised_op = self.model(inp)\n",
    "                    r, c = coords[patch_idx]\n",
    "                    original_reconst[:, r:r+patch_size, c:c+patch_size] += orig\n",
    "                    denoised_reconst[:, r:r+patch_size, c:c+patch_size] += denoised_op\n",
    "                    target_reconst[:, r:r+patch_size, c:c+patch_size] += targ\n",
    "                    input_reconst[:, r:r+patch_size, c:c+patch_size] += inp\n",
    "                    mod_count[:, r:r+patch_size, c:c+patch_size] += 1\n",
    "                    patch_idx += 1\n",
    "    \n",
    "                    if patch_idx == n_patches:\n",
    "                        # Normalize\n",
    "                        mod_count[mod_count == 0] = 1\n",
    "                        original_reconst /= mod_count\n",
    "                        denoised_reconst /= mod_count\n",
    "                        target_reconst /= mod_count\n",
    "                        input_reconst /= mod_count\n",
    "    \n",
    "                        # Generate images\n",
    "                        prim = [x.squeeze(0) for x in [original_reconst, input_reconst, denoised_reconst, target_reconst]]\n",
    "                        spec = [v for _, v in (self._compute_spectral(x, magnitude=True, normalize=False) for x in prim)]\n",
    "    \n",
    "                        pimg = torch.cat(prim, dim=1).add(0.5)\n",
    "                        simg = torch.cat(spec, dim=1).mul(0.05)\n",
    "                        img = torch.cat([pimg, simg], dim=0)\n",
    "    \n",
    "                        # Save\n",
    "                        save_image(img, output_dir / f\"final{img_idx:03d}.png\", normalize=False)\n",
    "                        save_image((torch.clip(original_reconst, -0.5, 0.5) + 0.5).cpu(), output_dir / f\"original{img_idx:03d}.png\")\n",
    "                        save_image((torch.clip(denoised_reconst, -0.5, 0.5) + 0.5).cpu(), output_dir / f\"output{img_idx:03d}.png\")\n",
    "                        save_image((torch.clip(target_reconst, -0.5, 0.5) + 0.5).cpu(), output_dir / f\"target{img_idx:03d}.png\")\n",
    "                        save_image((torch.clip(input_reconst, -0.5, 0.5) + 0.5).cpu(), output_dir / f\"input{img_idx:03d}.png\")\n",
    "\n",
    "                        # Saved a labled version.\n",
    "                        save_labeled_image(prim, spec, img_idx)\n",
    "    \n",
    "                        # Metrics\n",
    "                        psnr_orig_vs_targ = self._psnr_scores(original_reconst, target_reconst).item()\n",
    "                        psnr_denoise_vs_targ = self._psnr_scores(denoised_reconst, target_reconst).item()\n",
    "                        psnr_input_vs_targ = self._psnr_scores(input_reconst, target_reconst).item()\n",
    "                        fout.write(f'{img_idx:03d}:\\t{psnr_orig_vs_targ:0.5f}\\t{psnr_input_vs_targ:0.5f}\\t{psnr_denoise_vs_targ:0.5f}\\t{(psnr_denoise_vs_targ - psnr_input_vs_targ):0.5f}\\n')\n",
    "    \n",
    "                        # Reset\n",
    "                        for buf in [original_reconst, denoised_reconst, target_reconst, input_reconst, mod_count]:\n",
    "                            buf.zero_()\n",
    "                        patch_idx = 0\n",
    "                        img_idx += 1\n",
    "    \n",
    "    def _train(self, **kwargs):\n",
    "        self._save_config(**kwargs)\n",
    "\n",
    "        self.logger.start()\n",
    "        \n",
    "        inject_noise = True\n",
    "        noisy_targets = kwargs.get(\"n2n\", True)\n",
    "        \n",
    "        print(\"Training Started...\")\n",
    "        print(f\"Total Epochs: {self.max_epochs} \\nBatch Size: {self.train_loader.batch_size} \\nInitial Learning Rate: {optimizer.param_groups[0]['lr']}\\n\")\n",
    "        # Setup Tensorboard Summary\n",
    "        # dummy_ip, _, _, _, _ = next(iter(self.train_loader))\n",
    "        imgs, specs = next(iter(self.train_loader))\n",
    "        imgs, specs = imgs.to(self.device), specs.to(self.device)\n",
    "        dummy_ip, t, s, s_m, o= self._preprocessbatch(imgs, specs, \n",
    "                                                     noisy_targets=noisy_targets, \n",
    "                                                     inject_noise=inject_noise, \n",
    "                                                     **kwargs)\n",
    "\n",
    "        save_image((torch.clip(dummy_ip[9], -0.5, 0.5) + 0.5).cpu(), self.results_dir / f\"example.png\")\n",
    "        # save_image((torch.clip(t[9], -0.5, 0.5) + 0.5).cpu(), self.validation_test_path / f\"t{0}.png\")\n",
    "        # save_image((torch.clip(o[9], -0.5, 0.5) + 0.5).cpu(), self.validation_test_path / f\"o{0}.png\")\n",
    "        \n",
    "        self.writer.add_graph(model=self.model, input_to_model=dummy_ip.to(self.device), verbose=False)\n",
    "        train_start_time = time.time()\n",
    "        for epoch in range(self.start_epoch, self.max_epochs):\n",
    "            self.epoch = epoch\n",
    "            \n",
    "            # Training Process\n",
    "            self.model.train()\n",
    "            if epoch == self.max_epochs-1:\n",
    "                print(f\"Final Epoch\")\n",
    "                self.final_epoch = True\n",
    "            else:\n",
    "                self.final_epoch = False\n",
    "            \n",
    "            start_time = time.time()\n",
    "            train_loss, train_n = 0.0, 0.0\n",
    "\n",
    "            # Do Data Minibatching \n",
    "            for idx, batch in tqdm(enumerate(self.train_loader), desc=\"Training Batch\", total=len(self.train_loader), position=0, leave=True):\n",
    "                # inps, targs, _, _, _ = batch\n",
    "                # inps, targs = imgs.to(self.device), targs.to(self.device)\n",
    "                imgs, specs = batch\n",
    "                imgs, specs = imgs.to(self.device), specs.to(self.device)\n",
    "                # params will be passed instead of hardcoded.\n",
    "                inps, targs, _, spec_mask, _= self._preprocessbatch(imgs, specs,\n",
    "                                                                    noisy_targets=noisy_targets, \n",
    "                                                                    inject_noise=inject_noise, \n",
    "                                                                    **kwargs)\n",
    "                \n",
    "                outputs = self.model(inps)\n",
    "\n",
    "                if self.post_op:\n",
    "                    outputs = self._post_op(self.post_op, outputs, specs, spec_mask)\n",
    "                \n",
    "                loss = self.loss_fn(outputs, targs)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "        \n",
    "                train_loss += loss.item() * inps.size(0)\n",
    "                train_n += inps.size(0)\n",
    "            \n",
    "            train_loss = (train_loss / train_n) if train_n > 0 else 0.0\n",
    "\n",
    "            # Validation Process\n",
    "            self.model.eval()\n",
    "            valid_loss, valid_n = 0.0, 0.0\n",
    "            \n",
    "            with torch.inference_mode():\n",
    "                for idx, batch in tqdm(enumerate(self.valid_loader), desc=\"Validation Batch\", total=len(self.valid_loader), leave=True):\n",
    "                    # inps, targs, _, _, origs = batch\n",
    "                    # inps, targs, origs = inps.to(self.device), targs.to(self.device), origs.to(self.device)\n",
    "                    imgs, specs = batch\n",
    "                    imgs, specs = imgs.to(self.device), specs.to(self.device)\n",
    "                    inps, targs, _, _, origs = self._preprocessbatch(imgs, specs, \n",
    "                                                                     noisy_targets=False, \n",
    "                                                                     inject_noise=inject_noise, \n",
    "                                                                     **kwargs)\n",
    "                    \n",
    "                    outputs = self.model(inps)\n",
    "\n",
    "                    # if self.post_op == 'fspec':\n",
    "                    #     outputs = self._post_op(outputs, specs, spec_mask)\n",
    "                    \n",
    "                    loss = self.loss_fn(outputs, targs)\n",
    "        \n",
    "                    valid_loss += loss.item() * inps.size(0)\n",
    "                    valid_n += inps.size(0)\n",
    "\n",
    "                    # Calculate PSNR scores\n",
    "                    avg_psnr = torch.mean(self._psnr_scores(outputs, targs))\n",
    "                    \n",
    "                    if idx == 0:\n",
    "                        \"\"\"\n",
    "                        # Save 4-in-1 Image\n",
    "                        # prim = [x.squeeze(0).detach().cpu().numpy() for x in [val_origs[0], val_imgs[0], outputs[0], val_targs[0]]]\n",
    "                        # spec = [v for _, v in (compute_spectral_image(x, magnitude=True) for x in prim)]\n",
    "                        # pimg = np.concatenate(prim, axis=1) + 0.5\n",
    "                        # simg = np.concatenate(spec, axis=1) * 0.05\n",
    "                        # img = np.clip(np.concatenate([pimg, simg], axis=0), 0.0, 1.0) * 255\n",
    "                        # Image.fromarray(img.astype(np.uint8)).save(self.training_test_path / f'img{epoch:03d}.png')\n",
    "                        \"\"\"\n",
    "                        # 4-in-1 image + spectrum\n",
    "                        prim = [x.squeeze(0) for x in [origs[6], inps[6], outputs[6], targs[6]]]\n",
    "                        spec = [v for _, v in (self._compute_spectral(x, magnitude=True, normalize=False) for x in prim)]\n",
    "                        pimg = torch.cat(prim, dim=1).add(0.5)\n",
    "                        simg = torch.cat(spec, dim=1).mul(0.05)\n",
    "                        img = torch.cat([pimg, simg], dim=0)\n",
    "\n",
    "                        # Saving the Outputs.\n",
    "                        save_image(img, self.training_test_path / f\"img{epoch:03d}.png\", normalize=False)\n",
    "                        \n",
    "            valid_loss = (valid_loss / valid_n) if valid_n > 0 else 0.0\n",
    "            epoch_time = time.time() - start_time\n",
    "\n",
    "            # Update the Summary\n",
    "            self.writer.add_scalar(\"Training/Loss\", train_loss, global_step=epoch, new_style=True)\n",
    "            self.writer.add_scalar(\"Validation/Loss\", valid_loss, global_step=epoch, new_style=True)\n",
    "            self.writer.add_scalar(\"Validation/Average_PSNR\", avg_psnr.item(), global_step=epoch, new_style=True)\n",
    "            self.writer.add_scalar(\"Learning_rate\", self.optimizer.param_groups[0][\"lr\"], global_step=epoch, new_style=True)\n",
    "            self.writer.add_scalar(\"Training/time-per-epoch\", epoch_time, global_step=epoch, new_style=True)\n",
    "            \n",
    "            print(f'[{self.device}]Epoch [{epoch+1}/{self.max_epochs}] | Time: {epoch_time: 0.2f} | Train Loss: {train_loss: 0.6f} | Validation Loss: {valid_loss: 0.6f} | Avg. PSNR: {avg_psnr.item()} | Learning Rate: {self.optimizer.param_groups[0][\"lr\"]: 0.6f}')\n",
    "    \n",
    "            if epoch%self.save_interval == self.save_interval-1 and not self.final_epoch and self.device == 0:\n",
    "                self._save_snapshot()\n",
    "\n",
    "            if self.final_epoch:\n",
    "                if self.device == 0:\n",
    "                    # Save the snapshot\n",
    "                    self._save_snapshot()\n",
    "                \n",
    "                # Do a full Validation set testing with result saving.\n",
    "                loader = DataLoader(self.valid_data, batch_size=1, shuffle=False, pin_memory=True, pin_memory_device=\"cuda\")\n",
    "\n",
    "                self.model.eval()\n",
    "                with torch.inference_mode():\n",
    "                    psnr_file = self.validation_test_path / \"00_PSNR.txt\"\n",
    "                    with psnr_file.open('wt') as fout:\n",
    "                        fout.write(f'Index:\\tOriginal\\tInput\\t\\tOutput\\t\\tGains\\n---------------------------------------------------------------------------------\\n')\n",
    "                        for idx, batch in tqdm(enumerate(loader), desc=\"Validation Testing\", total=10, leave=True):\n",
    "                            if idx == 10:    break\n",
    "                            \n",
    "                            # inp, targ, _, _, orig = batch\n",
    "                            # inp, targ, orig = inp.to(self.device), targ.to(self.device), orig.to(self.device)\n",
    "                            imgs, specs = batch\n",
    "                            imgs, specs = imgs.to(self.device), specs.to(self.device)\n",
    "                            inp, targ, _, _, orig = self._preprocessbatch(imgs, specs,\n",
    "                                                                         noisy_targets=False,\n",
    "                                                                         inject_noise=inject_noise,\n",
    "                                                                         **kwargs)\n",
    "                            denoised_op = self.model(inp)\n",
    "\n",
    "                            # if self.post_op == 'fspec':\n",
    "                            #     denoised_op = self._post_op(denoised_op, specs, spec_mask)\n",
    "                            \n",
    "                            # 4-in-1 image + spectrum\n",
    "                            prim = [x.squeeze(0) for x in [orig, inp, denoised_op, targ]]\n",
    "                            spec = [v for _, v in (self._compute_spectral(x, magnitude=True, normalize=False) for x in prim)]\n",
    "                            pimg = torch.cat(prim, dim=1) + 0.5\n",
    "                            simg = torch.cat(spec, dim=1) * 0.05\n",
    "                            img = torch.cat([pimg, simg], dim=0)\n",
    "\n",
    "                            # Saving the Outputs.\n",
    "                            save_image(img, self.validation_test_path / f\"final{idx:03d}.png\", normalize=False)\n",
    "                            # save_image((torch.clip(orig, -0.5, 0.5) + 0.5).cpu(), self.validation_test_path / f\"original{idx:03d}.png\")\n",
    "                            save_image((torch.clip(denoised_op, -0.5, 0.5) + 0.5).cpu(), self.validation_test_path / f\"output{idx:03d}.png\")\n",
    "                            save_image((torch.clip(targ, -0.5, 0.5) + 0.5).cpu(), self.validation_test_path / f\"target{idx:03d}.png\")\n",
    "                            save_image((torch.clip(inp, -0.5, 0.5) + 0.5).cpu(), self.validation_test_path / f\"input{idx:03d}.png\")\n",
    "                            \n",
    "                            '''\n",
    "                            # # Saving the Outputs.\n",
    "                            # prim = [x.squeeze(0).detach().cpu().numpy() for x in [orig[0], inp[0], denoised_op[0], targ[0]]]\n",
    "                            # spec = [v for _, v in (compute_spectral_image(x, magnitude=True) for x in prim)]\n",
    "                            # pimg = np.concatenate(prim, axis=1) + 0.5\n",
    "                            # simg = np.concatenate(spec, axis=1) * 0.03\n",
    "                            # img = (np.clip(np.concatenate([pimg, simg], axis=0), 0.0, 1.0) * 255).astype(np.uint8)\n",
    "                            # # 4-in-1 image + spectrum\n",
    "                            # Image.fromarray(img).save(self.validation_test_path / f'final{idx:03d}.png')\n",
    "\n",
    "                            # inp_img = (np.clip((inp[0].squeeze(0).detach().cpu().numpy() + 0.5), 0.0, 1.0) * 255).astype(np.uint8)\n",
    "                            # targ_img = (np.clip((targ[0].squeeze(0).detach().cpu().numpy() + 0.5), 0.0, 1.0) * 255).astype(np.uint8)\n",
    "                            # denoised_img = (np.clip(denoised_op[0].squeeze(0).detach().cpu().numpy() + 0.5, 0.0, 1.0) * 255).astype(np.uint8)\n",
    "\n",
    "                            # Image.fromarray(inp_img).save(self.validation_test_path / f'input{idx:03d}.png')\n",
    "                            # Image.fromarray(targ_img).save(self.validation_test_path / f'target{idx:03d}.png')\n",
    "                            # Image.fromarray(denoised_img).save(self.validation_test_path / f'output{idx:03d}.png')\n",
    "                            '''\n",
    "                            # PSNR Scores\n",
    "                            orig_vs_targ = self._psnr_scores(orig, targ).item()\n",
    "                            op_vs_targ = self._psnr_scores(denoised_op, targ).item()\n",
    "                            inp_vs_targ = self._psnr_scores(inp, targ).item()\n",
    "                            \n",
    "                            fout.write(f'{idx:02d}:\\t{orig_vs_targ:0.5f}\\t\\t{inp_vs_targ:0.5f}\\t\\t{op_vs_targ:0.5f}\\t\\t{(op_vs_targ - orig_vs_targ):0.5f}\\n')\n",
    "        \n",
    "        self.writer.close()\n",
    "        total_seconds = time.time() - train_start_time\n",
    "        print(f\"Time Elapsed: {int(total_seconds // 3600)}hrs : {int((total_seconds % 3600) // 60)}mins : {int(total_seconds % 60)}secs.\" )\n",
    "        # Stop with the logging\n",
    "        self.logger.stop()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774d10c6-de26-4553-ad1f-120988429374",
   "metadata": {},
   "source": [
    "## Initialize Trainer Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723812a0-5f96-4ebc-a85c-6407365ea34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = 1\n",
    "experiment_desc = \"\"\n",
    "batch_size = 32\n",
    "max_epochs = 250\n",
    "learning_rate = 0.0005\n",
    "loss_fn = nn.MSELoss()\n",
    "model = Noise2Noise()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "# Rampup-plateau-rampdown\n",
    "# scheduler = lr_sch.SequentialLR(optimizer=optimizer, \n",
    "#                                 schedulers=[lr_sch.LinearLR(optimizer=optimizer, start_factor=0.001, total_iters=int(max_epochs * 0.1)),\n",
    "#                                             lr_sch.ConstantLR(optimizer=optimizer, factor=1.0, total_iters=int(max_epochs * 0.6)), \n",
    "#                                             lr_sch.LinearLR(optimizer=optimizer, start_factor=1.0, end_factor=0.001, total_iters=int(max_epochs * 0.3))], \n",
    "#                                 milestones=[int(max_epochs * 0.1), int(max_epochs * 0.7)])\n",
    "\n",
    "# Constant LR\n",
    "scheduler = lr_sch.ConstantLR(optimizer=optimizer, factor=1.0, total_iters=int(max_epochs))\n",
    "\n",
    "results_dir = Path(\"results/001\")\n",
    "\n",
    "trainer = Trainer(gpu_id=0, model=model, \n",
    "                  train_data=train_dataset, \n",
    "                  valid_data=valid_dataset, \n",
    "                  optimizer=optimizer, \n",
    "                  scheduler=scheduler,\n",
    "                  loss_fn=loss_fn,\n",
    "                  experiment_id=experiment_id,\n",
    "                  experiment_desc=experiment_desc,\n",
    "                  batch_size=batch_size,\n",
    "                  post_op='fspec',\n",
    "                  max_epochs=max_epochs,\n",
    "                  # results_dir=results_dir,\n",
    "                  load_checkpoint=False,\n",
    "                  snapshot_name=\"latest-snapshot\"\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb4e6e3-93e9-44f2-a2de-934b213fcf9d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Setup and Start the Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a8c9da-3c08-4b47-9330-8ebda6717026",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setup the parameters and datasets\n",
    "trainer._setup_training()\n",
    "\n",
    "# Train the model\n",
    "trainer.train(n2n=False,\n",
    "              target_noise_injection_factor = 1.0,\n",
    "              corruption_type=['poisson0','gaussian0', 'bspec', 'blur'], \n",
    "              augment_params={\"translate\": 64},\n",
    "              corruption_params={\"p_edge\": 0.95, \n",
    "                                  \"distribution\": \"uniform\", \n",
    "                                 \"poisson_strength\": 50, \n",
    "                                 \"mask_ratio\": 1.0, \n",
    "                                 \"gaussian_std\": 50, \n",
    "                                 \"blur_sigma\": 1.0, \n",
    "                                 \"blur_kernel\": 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0716a801-90cd-43ef-8bd8-1aa98e53c61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# Delete the model from the GPU to avoid restarting the kernel for each execution.\n",
    "\n",
    "# Clear the CUDA Cache and Garbage Collector\n",
    "del model       # Deletes the model from the GPU\n",
    "del optimizer\n",
    "del trainer\n",
    "gc.collect() # GC collects the deleted model and clears the memory.\n",
    "torch.cuda.empty_cache() # Removes any cache data related to the removed model from the GPU.\n",
    "\n",
    "\n",
    "\n",
    "# Example Usage below:\n",
    "\n",
    "# import gc\n",
    "# ex_model = ExampleModel().cuda()\n",
    "# del ex_model # Deletes the model from the GPU\n",
    "# gc.collect() # GC collects the deleted model and clears memory\n",
    "# torch.cuda.empty_cache() # Removes any cache data related to the removed model from the GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2f2df1-ef4c-4312-9fa8-981fd702a05e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Evaluate The Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e17dea-12f5-48b3-a479-aeb566a5ffe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# eval_dataset = torch.load(ds_dir / \"HQ_eval_dataset_10.pth\", weights_only=False)\n",
    "\n",
    "eval_loader = None\n",
    "if eval_loader is None:\n",
    "    eval_loader = DataLoader(eval_dataset, batch_size=1, shuffle=False, pin_memory=True, pin_memory_device=\"cuda\")\n",
    "\n",
    "trainer.eval(eval_loader, \n",
    "             inject_noise=False,\n",
    "             patch_size=512, \n",
    "             image_size=2570, \n",
    "             overlap=0.2, \n",
    "             corruption_type=['poisson0','gaussian0', 'bspec', 'blur'], \n",
    "             corruption_params={\"p_edge\": 0.95, \n",
    "                                \"distribution\": \"uniform\", \n",
    "                                \"poisson_strength\": 50, \n",
    "                                \"mask_ratio\": 1.0, \n",
    "                                \"gaussian_std\": 25, \n",
    "                                \"blur_sigma\": 1.0, \n",
    "                                \"blurr_kernel\": 15}\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33873b72-7666-4ee0-b2e0-b552c28afce9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f343d3ad-5caf-4067-bbce-1b34580e0c38",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## DDP Associated Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da67bf98-c3b6-4e3b-8902-167ccc5930cb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def ddp_setup(rank, world_size):\n",
    "    '''\n",
    "    rank: Unique id for each process\n",
    "    world_size: Total number of processes. (n_gpus)\n",
    "    '''\n",
    "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "    os.environ[\"MASTER_PORT\"] = \"12335\"\n",
    "    init_process_group(backend=\"nccl\", rank=rank, world_size=world_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd709988-fe39-488a-bac1-ac1aaf9408f9",
   "metadata": {},
   "source": [
    "# Report Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2f4993-09f0-4b35-8bd4-b75c8cc6797c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Visualizing Tensorboard Summaries\n",
    "\n",
    "<b><font size=\"4\">Starting Tensorboard Server: </font></b><br>\n",
    "tensorboard --logdir=./results --port=6006\n",
    "\n",
    "<details>\n",
    "    <summary><font size=\"4\">Shut down the Server: </font></summary>\n",
    "    <details>\n",
    "         <summary><b><font size=\"4\">Linux</font></b></summary>\n",
    "    <font color=\"yellow\">1) Kill tensorboard process:<br>\n",
    "    </font>\n",
    "        pkill -f tensorboard\n",
    "    </details>\n",
    "    <details>\n",
    "         <summary><b><font size=\"4\">Windows</font></b></summary>\n",
    "        <font color=\"yellow\">1) Find the Process ID of active tensorboard instance: <br>\n",
    "            Note: Find the PID with port 6006 that is Listening. <br>\n",
    "        </font>\n",
    "            netstat -ano | findstr :6006 \n",
    "            <br>\n",
    "        <font color=\"yellow\">2) Kill the task with PID [!!!!!!!! TAKE EXTREME CAUTION !!!!!!!!!!!!]:<br>\n",
    "            Note: You can add \"/F\" at the end to force the command.<br>\n",
    "        </font>\n",
    "            taskkill /PID ****\n",
    "        <font color=\"yellow\">3) Kill all tensorboard related instances:<br>\n",
    "            Note: You can add \"/F\" at the end to force the command.<br>\n",
    "        </font>\n",
    "            taskkill /IM tensorboard.exe /F\n",
    "    </details>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4455e98d-0d66-4526-a55c-638df0fe3f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor Board\n",
    "# !tensorboard --logdir=./Results_bernoulli_test_0 --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7682a4c-7da5-4529-b43e-988daba9f0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !netstat -ano | findstr :6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c1e075-9acd-4257-9e2c-030b53837f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !taskkill /PID 27464 /F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366c3669-7233-4d8c-9169-020c68eb0a51",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Crop Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e87bfc-b318-4b4b-bb25-1b471c61cec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "src_path = dataset_root_dir / 'evalImgs' #Path('./datasets/CropTests/ToCrop')\n",
    "dst_path = dataset_root_dir / 'evalImgsC' #Path('./datasets/CropTests/Cropped')\n",
    "\n",
    "src_path.mkdir(parents=True, exist_ok=True)\n",
    "dst_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "crop_size = 940\n",
    "crop = 0 # 1: Perform cropping\n",
    "\n",
    "if crop:\n",
    "    for img_path in src_path.glob(\"*.png\"):\n",
    "        with Image.open(img_path) as img:\n",
    "            w, h = img.size\n",
    "            if w>=crop_size and h>= crop_size:\n",
    "                h_crop = crop_size/2\n",
    "                left, top = w//2- h_crop , h//2 - h_crop\n",
    "                right, bottom = left + crop_size, top + crop_size\n",
    "    \n",
    "                cropped = img.crop((left, top, right, bottom))\n",
    "                cropped.save(dst_path / img_path.name)\n",
    "            else:\n",
    "                print(f\"Skipping {img_path.name}: too small ({w}x{h})\")\n",
    "    print(\"Cropping Completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b3689d-584b-4d0b-b0ed-07d73f713825",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Plot NIQE vs PIQE scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88c28c7-2f3c-40eb-83d6-8c3dd42007c6",
   "metadata": {},
   "outputs": [],
     "metadata": {},
   "source": [
    "# Read in a CSV file with PIQE and NIQE scores. (idx, PIQE, NIQE)\n",
    "# Plot datapoints on a graph.\n",
    "# Color-code Original, Noisy and Output datapoints.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "plot_path = Path(\"./results/PlotResults\")\n",
    "plot_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "files_names = ['input_scores', 'output_scores', 'original_scores'] \n",
    "colors = [\"red\", \"blue\", \"green\"] \n",
    "labels = ['Noisy', 'Denoised', 'Original']\n",
    "\n",
    "# files_names = ['input_scores', 'output_scores'] \n",
    "# colors = [\"red\", \"blue\"] \n",
    "# labels = ['Noisy', 'Denoised']\n",
    "\n",
    "niq_piq = 0\n",
    "saveImage = 0\n",
    "\n",
    "if niq_piq:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    for file_name, color, label in zip(files_names, colors, labels):\n",
    "        df = pd.read_csv(plot_path / (file_name +'.csv'))\n",
    "        plt.scatter(df['NIQE'], df['PIQE'], color=color, alpha=0.7, label=label)\n",
    "    \n",
    "    # Labeling axes\n",
    "    plt.xlabel('NIQE')\n",
    "    plt.ylabel('PIQE')\n",
    "    plt.title('Scatter Plot of PIQE vs NIQE')\n",
    "    plt.legend()\n",
    "    # plt.xlim([3, 9])\n",
    "    # plt.ylim([10, 60])\n",
    "    plt.grid(True)\n",
    "    if saveImage:\n",
    "        plt.savefig(plot_path / \"NIQE_PIQE.png\", dpi=300)\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dc7025-ba1b-4d5a-81b7-7889704c9ef1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # Create Dummy CSV files\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# # Sample data\n",
    "# data = {\n",
    "#     'idx': range(1, 11),\n",
    "#     'PIQE': np.random.uniform(15, 20, size=10).round(3),\n",
    "#     'NIQE': np.random.uniform(3, 4, size=10).round(3)\n",
    "# }\n",
    "\n",
    "# # Create DataFrame\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# # Save to CSV\n",
    "# df.to_csv( Path(\"datasets/PlotTests\") / 'csv2.csv', index=False)\n",
    "\n",
    "# print(\"CSV file 'csv1.csv' created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40822451-9dda-4218-9cb6-3942eb61f88c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Plot Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa09090-81eb-40ff-a628-39b3a8166380",
   "metadata": {},
   "outputs": [],
     "output_type": "display_data"
    }
   "source": [
    "# Read 2 Images and plot PDF histogram for original, noisy and output images.\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define paths for the images\n",
    "histo_dir = Path(\"./results/PlotResults\")\n",
    "histo_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "img_names = [\"input001\", \"original001\", \"output001\"]\n",
    "colors = [\"red\", \"green\", \"blue\"]\n",
    "labels = ['Noisy', 'Original', 'Denoised']\n",
    "\n",
    "# img_names = ['input001', 'output001'] \n",
    "# colors = [\"red\", \"blue\"] \n",
    "# labels = ['Noisy', 'Denoised']\n",
    "\n",
    "\n",
    "density = True  # For PDF (Probability Density Function)\n",
    "alpha = 0.4\n",
    "histtype_set = {0:\"bar\", 1:\"barstacked\", 2:\"step\", 3:\"stepfilled\"}\n",
    "histtype = histtype_set.get(0)\n",
    "bins = 256\n",
    "\n",
    "histo = 0\n",
    "saveImage = 0\n",
    "\n",
    "if histo:\n",
    "    # Plot the PDFs\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Histogram\n",
    "    for img_name, color, label in zip(img_names, colors, labels):\n",
    "        img = np.array(Image.open(histo_dir/(img_name+\".png\")).convert('L'))\n",
    "        plt.hist(img.ravel(), bins=bins, range=(0, 255), color=color, alpha=alpha, density=density, label=label, histtype=histtype)\n",
    "        \n",
    "    # # Line Plot\n",
    "    # for img_name, color, label in zip(img_names, colors, labels):\n",
    "    #     img = np.array(Image.open(histo_dir/(img_name+\".png\")).convert('L'))\n",
    "    #     plt.plot(np.arange(bins), np.bincount(img.ravel(), minlength=256), color=color, label=label)\n",
    "    \n",
    "    plt.title('Image Histogram')\n",
    "    plt.xlabel('Pixel Values (0-255)')\n",
    "    plt.ylabel('Frequency Density')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    if saveImage:\n",
    "        plt.savefig(histo_dir / \"image_histogram_comparison.png\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7299360-fb22-401b-b55f-551af6f478c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Experimentation Sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07bebb4-8ff0-48a0-bc66-e0d9d18b039f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Testing Different Noise and Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef11487-03ed-40ad-b0ea-6981ffbc9af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#    Poisson Noise\n",
    "#\n",
    "import numpy as np\n",
    "import imageio.v3 as iio\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.exposure import rescale_intensity\n",
    "\n",
    "def add_poisson_noise(image, amplification=0.102):\n",
    "    \"\"\"Apply Poisson noise to an image.\"\"\"\n",
    "    noisy_image = np.random.poisson(image * amplification) / amplification\n",
    "    return np.clip(noisy_image, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Load the image\n",
    "image_path = \"D:\\\\CAPSTONE\\\\Results Backup\\\\HQ_evalImgs\\\\00000390.png\"\n",
    "image = iio.imread(image_path)\n",
    "\n",
    "# Convert to grayscale if necessary\n",
    "if len(image.shape) == 3:\n",
    "    grayscale_image = np.mean(image, axis=-1).astype(np.uint8)\n",
    "else:\n",
    "    grayscale_image = image\n",
    "\n",
    "# Enhance contrast by stretching pixel values\n",
    "contrast_enhanced_image = rescale_intensity(grayscale_image, in_range='image', out_range=(0, 255)).astype(np.uint8)\n",
    "\n",
    "# Apply uniform Poisson noise with amplification factor of 0.05\n",
    "noisy_contrast_image = add_poisson_noise(contrast_enhanced_image, amplification=0.102)\n",
    "# noisy_contrast_image = add_poisson_noise(grayscale_image, amplification=0.102)\n",
    "\n",
    "# Save the output image\n",
    "output_contrast_path = \"D:\\\\CAPSTONE\\\\Results Backup\\\\HQ_evalImgs\\\\noisy_0.102.png\"\n",
    "iio.imwrite(output_contrast_path, noisy_contrast_image)\n",
    "\n",
    "# Display the processed image\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.imshow(noisy_contrast_image, cmap='gray')\n",
    "plt.title(\"Contrast Enhanced + Poisson Noise (0.05)\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Output the file path\n",
    "print(f\"Processed image saved at: {output_contrast_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d357fb-666f-48ae-b3a4-767c1e975554",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "#    Gaussian Noise\n",
    "#\n",
    "import numpy as np\n",
    "import imageio.v3 as iio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def add_gaussian_noise(image, mean=0, std=10):\n",
    "    \"\"\"\n",
    "    Adds Gaussian noise to an image.\n",
    "    :param image: Input grayscale image (NumPy array)\n",
    "    :param mean: Mean of the Gaussian noise\n",
    "    :param std: Standard deviation of the Gaussian noise\n",
    "    :return: Noisy image (NumPy array)\n",
    "    \"\"\"\n",
    "    noise = np.random.normal(mean, std, image.shape)  # Generate Gaussian noise\n",
    "    noisy_image = image + noise  # Add noise to the image\n",
    "    return np.clip(noisy_image, 0, 255).astype(np.uint8)  # Clip and convert to uint8\n",
    "\n",
    "# Load the original uploaded image\n",
    "image_path = \"D:\\\\CAPSTONE\\\\Results Backup\\\\HQ_evalImgs\\\\gaussian_noisy_blur_image.png\"  # Use the original uploaded file\n",
    "original_image = iio.imread(image_path, mode='L')  # Load as grayscale\n",
    "\n",
    "# Define Gaussian noise parameters\n",
    "mean = 0       # Mean of the Gaussian noise\n",
    "std = 30       # Standard deviation of the Gaussian noise (adjustable)\n",
    "\n",
    "# Apply Gaussian noise\n",
    "noisy_image = add_gaussian_noise(original_image, mean, std)\n",
    "\n",
    "# Save and display the noisy image\n",
    "output_path = \"D:\\\\CAPSTONE\\\\Results Backup\\\\HQ_evalImgs\\\\gaussian_noisy_blur_then_poisson_image.png\"\n",
    "iio.imwrite(output_path, noisy_image)\n",
    "\n",
    "# Show original and noisy images side by side\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(original_image, cmap='gray')\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(noisy_image, cmap='gray')\n",
    "plt.title(f\"Gaussian Noise (mean={mean}, std={std})\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Noisy image saved at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e508f934-eba4-4393-9df0-a8aad6610ad8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "#    Gaussian Blur\n",
    "#\n",
    "import numpy as np\n",
    "import imageio.v3 as iio\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "def apply_gaussian_blur(image, sigma=1):\n",
    "    \"\"\"\n",
    "    Applies Gaussian blur to an image.\n",
    "    :param image: Input grayscale image (NumPy array)\n",
    "    :param sigma: Standard deviation for Gaussian kernel\n",
    "    :return: Blurred image (NumPy array)\n",
    "    \"\"\"\n",
    "    blurred_image = gaussian_filter(image, sigma=sigma)  # Apply Gaussian blur\n",
    "    return np.clip(blurred_image, 0, 255).astype(np.uint8)  # Clip and convert to uint8\n",
    "\n",
    "# Load the original uploaded image\n",
    "image_path = \"D:\\\\CAPSTONE\\\\Results Backup\\\\HQ_evalImgs\\\\noisy_0.102.png\"  # Use the original uploaded file\n",
    "original_image = iio.imread(image_path, mode='L')  # Load as grayscale\n",
    "\n",
    "# Define Gaussian blur parameter\n",
    "sigma = 1.5  # Standard deviation for Gaussian blur (adjustable)\n",
    "\n",
    "# Apply Gaussian blur\n",
    "blurred_image = apply_gaussian_blur(original_image, sigma)\n",
    "\n",
    "# Save and display the blurred image\n",
    "output_path = \"D:\\\\CAPSTONE\\\\Results Backup\\\\HQ_evalImgs\\\\poisson_noisy_then_blur_image.png\"\n",
    "# iio.imwrite(output_path, blurred_image)\n",
    "\n",
    "# print(original_image.dtype)\n",
    "\n",
    "# Show original and blurred images side by side\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(original_image, cmap='gray')\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(blurred_image, cmap='gray')\n",
    "plt.title(f\"Gaussian Blur (sigma={sigma})\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Blurred image saved at: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7793a2f9-3838-4960-8189-31a8d8be3ebe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## PyTorch Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79cae14-f6fd-4855-aa58-005cb74b4a1c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.transforms.functional import gaussian_blur\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6bb4ff-1ebf-4d73-b8eb-f15bd7761fef",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def compute_spectral(image, ifft=False, magnitude=False, normalize=True):\n",
    "        fft_shift = None\n",
    "        if ifft:\n",
    "            fft_shift = torch.fft.ifftshift(image, dim=(-2, -1))  # Shift zero frequency to center\n",
    "        else:\n",
    "            fft_image = torch.fft.fft2(image)  # Apply 2D Fourier Transform\n",
    "            fft_shift = torch.fft.fftshift(fft_image, dim=(-2, -1))  # Shift zero frequency to center\n",
    "        \n",
    "        if magnitude:\n",
    "            magnitude_spectrum = torch.abs(fft_shift)  # Get magnitude\n",
    "            # Normalize the spectrum for consistency\n",
    "            magnitude_spectrum = torch.log1p(magnitude_spectrum)  # Log scaling\n",
    "            \n",
    "            if normalize:\n",
    "                magnitude_spectrum = (magnitude_spectrum - magnitude_spectrum.min()) / (magnitude_spectrum.max() - magnitude_spectrum.min())\n",
    "                # magnitude_spectrum /= magnitude_spectrum.max()  # Normalize [0,1]\n",
    "                \n",
    "            return fft_shift.to(torch.complex64), magnitude_spectrum\n",
    "        else: \n",
    "            return fft_shift.to(torch.complex64)\n",
    "    \n",
    "def apply_poisson(imgs, criterion=0.1, corruption_strength=0.102, device=\"cpu\"):\n",
    "    _, H, W = imgs.shape\n",
    "    mask = (torch.rand((H, W), device=device) < criterion).float()\n",
    "    \n",
    "    poisson_noise = torch.poisson(torch.abs(imgs) * corruption_strength) / corruption_strength\n",
    "    batch_mask = mask.unsqueeze(0)\n",
    "    new_imgs = torch.where(batch_mask.bool(), poisson_noise, imgs)\n",
    "    # print(f\"Value Range of output: [{torch.min(new_imgs)}, {torch.max(new_imgs)}]\")\n",
    "    return torch.clip(new_imgs, -0.5, 0.5)\n",
    "    \n",
    "def apply_gaussian(imgs, mean=0.0, std= 0.1, device=\"cpu\"):\n",
    "    mask = torch.normal(mean=mean, std=std, size=imgs[0].shape, device=device)\n",
    "    # print(f\"Mask Shape: {mask.shape}\")\n",
    "    new_imgs = imgs + mask\n",
    "    return torch.clip(new_imgs, -0.5, 0.5)\n",
    "\n",
    "def apply_blur(imgs, kernel_size=3, sigma=1):\n",
    "    # imgs.unsqueeze(1)\n",
    "    return torch.clip(gaussian_blur(img=imgs, kernel_size=kernel_size, sigma=sigma), -0.5, 0.5)\n",
    "    \n",
    "def apply_bernoulli(imgs, p_edge=0.025, device=\"cpu\"):\n",
    "    _, H, W = imgs.shape\n",
    "    y = torch.arange(H, dtype=torch.float32, device=device) - H // 2\n",
    "    x = torch.arange(W, dtype=torch.float32, device=device) - W // 2\n",
    "    yy, xx = torch.meshgrid(y**2, x**2, indexing='ij')\n",
    "    r_dist = torch.sqrt(xx + yy)\n",
    "    prob_mask = (p_edge ** (2.0 / W)) ** r_dist\n",
    "    \n",
    "    keep = (torch.rand(size=(H, W), device=device, dtype=torch.float32) ** 2) < prob_mask\n",
    "    keep = keep & torch.flip(keep, dims=[0, 1])\n",
    "    # Apply Mask\n",
    "    mskd_specs = specs * keep\n",
    "    spec_msk = keep.to(torch.float32)\n",
    "    new_specs = compute_spectral(mskd_specs / torch.where(keep, prob_mask, 1e-8), ifft=True)\n",
    "    new_imgs = torch.fft.ifft2(new_specs).real.float()\n",
    "    return torch.clip(new_imgs, -0.5, 0.5), new_specs, spec_msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0b2021-671f-49ea-9d6a-f8dc0a492596",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "ds_dir = Path(\"PyTorchDatasets\")\n",
    "poisson_criterion = 0.1\n",
    "poisson_strength = 0.0002\n",
    "\n",
    "gaussian_mean = 0.0\n",
    "gaussian_std = 0.1\n",
    "\n",
    "blur_sigma = 1.0\n",
    "blur_kernel = 15\n",
    "\n",
    "bernoulli_probability_at_edge = 0.025\n",
    "\n",
    "# (kernel = 17, sigm = 1.99, standdiv= 0.06, loss = 0.0126)\n",
    "# (kernel = 15, sigm = 1.98, standdiv= 0.01, crit=0.1, strength=0.0002)\n",
    "\n",
    "\n",
    "# Load Dataset\n",
    "img_dataset = torch.load(ds_dir / \"HQ_train_full_img.pth\", weights_only=False)\n",
    "loader = DataLoader(img_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "img_size = (10,10)\n",
    "img_size = (15,15)\n",
    "batch_size = loader.batch_size\n",
    "n_col = 2\n",
    "n_row = math.ceil(batch_size/n_col)\n",
    "\n",
    "plt.figure(figsize=(n_col * img_size[0], n_row * img_size[1])) # fig_size=(W, H)\n",
    "# Read image from dataset\n",
    "for idx, batch in tqdm(enumerate(loader), total=len(loader), desc=\"Processed Images\"):\n",
    "    imgs, specs = batch\n",
    "    # print(imgs.shape)\n",
    "    \n",
    "    imgs = apply_gaussian(imgs, gaussian_mean, gaussian_std)\n",
    "    imgs = apply_blur(imgs, kernel_size=blur_kernel, sigma=blur_sigma)\n",
    "    imgs = apply_poisson(imgs, criterion=poisson_criterion, corruption_strength=poisson_strength)\n",
    "    # imgs, _, _ = apply_bernoulli(imgs, p_edge=bernoulli_probability_at_edge) \n",
    "    \n",
    "    imgs = imgs.add(0.5).mul(255).to(torch.uint8).to(\"cpu\")\n",
    "    plt.figure(figsize=(n_col * img_size[0], n_row * img_size[1])) # fig_size=(W, H)\n",
    "    for idx2, img in enumerate(imgs):\n",
    "        plt.subplot(n_row, n_col, idx2+1)\n",
    "        plt.imshow(img.numpy(), cmap='gray')\n",
    "        plt.title(f\"Image-{idx2+1}\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    \n",
    "    time.sleep(1)\n",
    "    if idx == 10:\n",
    "        break\n",
    "\n",
    "# batch = next(iter(loader))\n",
    "# imgs, specs = batch\n",
    "# imgs = imgs[:, 1000:-1000, 1000:-1000]\n",
    "# best_params = (15, 0.98, 0.01,0.1, 0.0002)\n",
    "# best_score = 0.012798348441720009 # float(\"inf\")\n",
    "# # kernels = [x for x in range(1, 24, 2)]\n",
    "# sigmas = [round(x, 2) for x in np.arange(0.40, 2.0, 0.02)]\n",
    "# stds = [round(x, 2) for x in np.arange(0.01, 0.15, 0.01)]\n",
    "# kernels = [15, 17]\n",
    "# # sigmas = [1.9, 1.99]\n",
    "# # stds = [0.19, 1.99]\n",
    "# poisson_crits = [round(x, 2) for x in np.arange(0.1, 0.2, 0.01)]\n",
    "# poisson_strs = [round(x, 6) for x in np.arange(0.0001, 0.0005, 0.0001)]\n",
    "\n",
    "# LQ_img = ToTensor()(Image.open(Path(\"Datasets/Mphase_3/Images/00000000.png\")).convert(\"L\"))[:, 1010:-1010, 1010:-1010] - 0.5\n",
    "# print(imgs.shape, LQ_img.shape)\n",
    "# assert imgs.shape == LQ_img.shape\n",
    "\n",
    "# idx = 0\n",
    "# for k in tqdm(kernels, position=0, leave=True, desc=f\"Kernels\", ncols=100):\n",
    "#     for s in tqdm(sigmas, position=1, leave=True, desc=f\"Sigmas\", ncols=100):\n",
    "#         for std in tqdm(stds, desc=f\"STDs\", leave=False, position=2, ncols=100):\n",
    "#             for crit in poisson_crits: \n",
    "#                 for strength in poisson_strs:\n",
    "#                     idx += 1\n",
    "#                     img = apply_gaussian(imgs, mean=0.0, std=std)\n",
    "#                     blu = apply_blur(img, kernel_size=k, sigma=s)\n",
    "#                     output = apply_poisson(blu, criterion=crit, corruption_strength=strength)\n",
    "                    \n",
    "#                     score = torch.mean((output - LQ_img)**2)\n",
    "#                     if score < best_score:\n",
    "#                         best_score = score\n",
    "#                         best_params = (k, s, std, crit, strength)\n",
    "#                         print(f\"New Loss:{best_score} | Kernel size: {k} | Sigma: {s} | Gaussian STD: {std} | Criterion: {crit} | Strength: {strength}\")\n",
    "            \n",
    "# print(f\"FINAL:\\nMinimum Loss:{best_score} | Kernel size: {best_params[0]} | Sigma: {best_params[1]} | Gaussian STD: {best_params[2]} | Criterion: {best_params[3]} | Strength {best_params[4]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b3abfb-06a3-4ab3-8058-1e0d91d2c852",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08f88e2-ad07-484c-89cb-c4041f708cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc3deb2-c9db-46ad-a972-8282343d1ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
